{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning - Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the optional watermark extension is a small IPython notebook plugin that I developed to make the code reproducible. You can just skip the following line(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2019-02-03 \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.15.4\n",
      "tensorflow 2.0.0-preview\n",
      "matplotlib 3.0.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -v -p numpy,tensorflow,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The use of `watermark` is optional. You can install this IPython extension via \"`pip install watermark`\". For more information, please see: https://github.com/rasbt/watermark.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14 - Going Deeper: The Mechanics of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to get the rank and shape of a tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크기: () (4,) (2, 2)\n",
      "랭크: 0 1 2\n"
     ]
    }
   ],
   "source": [
    "## t1, t2, t3 텐서를 정의합니다.\n",
    "t1 = tf.constant(np.pi)\n",
    "t2 = tf.constant([1, 2, 3, 4])\n",
    "t3 = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "## 랭크를 구합니다.\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)\n",
    "\n",
    "## 크기를 구합니다\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "print('크기:', s1, s2, s3)\n",
    "\n",
    "print('랭크:', \n",
    "      r1.numpy(), \n",
    "      r2.numpy(), \n",
    "      r3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding TensorFlow's computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2) \n",
    "c = tf.constant(3) \n",
    "\n",
    "z = 2*(a-b) + c\n",
    "\n",
    "print('2*(a-b)+c => ', z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "## 텐서플로 1.x 방식\n",
    "g = tf.Graph()\n",
    " \n",
    "## 그래프에 노드를 추가합니다.\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    \n",
    "## 그래프를 실행합니다.\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c => ', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_func():\n",
    "    a = tf.constant(1)\n",
    "    b = tf.constant(2) \n",
    "    c = tf.constant(3) \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "print('2*(a-b)+c => ', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.eager.def_function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(simple_func.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "def simple_func():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "simple_func = tf.function(simple_func)\n",
    "\n",
    "print('2*(a-b)+c => ', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func = simple_func.get_concrete_function()\n",
    "con_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"add\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with TensorFlow’s variables, and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables in TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w1:0' shape=(2, 4) dtype=int64>\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w1')\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'w1/Initializer/initial_value' type=Const>,\n",
       " <tf.Operation 'w1' type=VarHandleOp>,\n",
       " <tf.Operation 'w1/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'w1/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'w1/Read/ReadVariableOp' type=ReadVariableOp>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^w1/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    print(init.node_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2, 4), dtype=int64)\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    w1 = w1 + 1\n",
    "    print(w1)\n",
    "    \n",
    "with tf.compat.v1.Session(graph=g1) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w1')\n",
    "    w1 = w1.assign(w1 + 1)\n",
    "\n",
    "with tf.compat.v1.Session(graph=g2) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "w2 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                          [5, 6, 7, 8]]), name='w2')\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())\n",
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[ 3,  4,  5,  6],\n",
      "       [ 7,  8,  9, 10]])>\n"
     ]
    }
   ],
   "source": [
    "print(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 API 자세히 배우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create a random toy dataset for regression\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, \n",
    "                             scale=(0.5 + t*t/3), \n",
    "                             size=None)\n",
    "        y.append(r)\n",
    "    return  x, 1.726*x -0.84 + np.array(y)\n",
    "\n",
    "\n",
    "x, y = make_random_data() \n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "# plt.savefig('images/14_03.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 649us/sample - loss: 2.9895 - val_loss: 2.0497\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.9448 - val_loss: 2.0258\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.9010 - val_loss: 2.0015\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.8565 - val_loss: 1.9777\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.8134 - val_loss: 1.9544\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.7707 - val_loss: 1.9333\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.7328 - val_loss: 1.9126\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.6940 - val_loss: 1.8916\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.6553 - val_loss: 1.8706\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 2.6168 - val_loss: 1.8499\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.5789 - val_loss: 1.8305\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.5437 - val_loss: 1.8114\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.5083 - val_loss: 1.7927\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.4731 - val_loss: 1.7719\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.4348 - val_loss: 1.7505\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.3964 - val_loss: 1.7343\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.3662 - val_loss: 1.7162\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.3333 - val_loss: 1.6992\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.3019 - val_loss: 1.6822\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.2706 - val_loss: 1.6646\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.2382 - val_loss: 1.6478\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.2073 - val_loss: 1.6316\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.1779 - val_loss: 1.6184\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.1533 - val_loss: 1.6033\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.1257 - val_loss: 1.5878\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.0976 - val_loss: 1.5738\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.0721 - val_loss: 1.5597\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.0468 - val_loss: 1.5467\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.0226 - val_loss: 1.5341\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.9990 - val_loss: 1.5192\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.9718 - val_loss: 1.5049\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.9455 - val_loss: 1.4919\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.9222 - val_loss: 1.4806\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.9016 - val_loss: 1.4700\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.8814 - val_loss: 1.4586\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.8608 - val_loss: 1.4477\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.8406 - val_loss: 1.4369\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.8209 - val_loss: 1.4271\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.8021 - val_loss: 1.4168\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.7828 - val_loss: 1.4045\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.7604 - val_loss: 1.3944\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.7413 - val_loss: 1.3849\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.7236 - val_loss: 1.3752\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 1.7059 - val_loss: 1.3652\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.6874 - val_loss: 1.3556\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.6697 - val_loss: 1.3461\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.6523 - val_loss: 1.3359\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.6341 - val_loss: 1.3266\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.6165 - val_loss: 1.3165\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.5979 - val_loss: 1.3062\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.5790 - val_loss: 1.2969\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5623 - val_loss: 1.2888\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.5472 - val_loss: 1.2805\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.5318 - val_loss: 1.2725\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.5173 - val_loss: 1.2632\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.5003 - val_loss: 1.2545\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.4840 - val_loss: 1.2463\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.4696 - val_loss: 1.2400\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.4570 - val_loss: 1.2324\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.4429 - val_loss: 1.2253\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.4299 - val_loss: 1.2183\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.4164 - val_loss: 1.2096\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.4011 - val_loss: 1.2045\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.3905 - val_loss: 1.1977\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3782 - val_loss: 1.1914\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.3664 - val_loss: 1.1855\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.3553 - val_loss: 1.1787\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.3425 - val_loss: 1.1725\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.3314 - val_loss: 1.1667\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.3203 - val_loss: 1.1611\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.3097 - val_loss: 1.1552\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2990 - val_loss: 1.1498\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.2888 - val_loss: 1.1435\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.2773 - val_loss: 1.1381\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.2676 - val_loss: 1.1329\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2577 - val_loss: 1.1275\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2476 - val_loss: 1.1227\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2383 - val_loss: 1.1171\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.2281 - val_loss: 1.1122\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 36us/sample - loss: 1.2188 - val_loss: 1.1070\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.2091 - val_loss: 1.1022\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2002 - val_loss: 1.0980\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.1921 - val_loss: 1.0936\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.1840 - val_loss: 1.0898\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1765 - val_loss: 1.0845\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1670 - val_loss: 1.0805\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1597 - val_loss: 1.0767\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1524 - val_loss: 1.0729\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.1453 - val_loss: 1.0686\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.1375 - val_loss: 1.0641\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.1291 - val_loss: 1.0602\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.1218 - val_loss: 1.0567\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.1151 - val_loss: 1.0533\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1084 - val_loss: 1.0495\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1013 - val_loss: 1.0457\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0942 - val_loss: 1.0418\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0872 - val_loss: 1.0375\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 90us/sample - loss: 1.0794 - val_loss: 1.0346\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0737 - val_loss: 1.0314\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0674 - val_loss: 1.0283\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0616 - val_loss: 1.0255\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0559 - val_loss: 1.0214\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0483 - val_loss: 1.0188\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0432 - val_loss: 1.0153\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0368 - val_loss: 1.0126\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0318 - val_loss: 1.0098\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.0268 - val_loss: 1.0074\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0218 - val_loss: 1.0048\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.0168 - val_loss: 1.0016\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0110 - val_loss: 0.9988\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0056 - val_loss: 0.9960\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0005 - val_loss: 0.9932\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9953 - val_loss: 0.9905\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9901 - val_loss: 0.9891\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9866 - val_loss: 0.9867\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9824 - val_loss: 0.9837\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9767 - val_loss: 0.9822\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9731 - val_loss: 0.9796\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9687 - val_loss: 0.9774\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9645 - val_loss: 0.9753\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9604 - val_loss: 0.9734\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.9570 - val_loss: 0.9718\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9536 - val_loss: 0.9698\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.9498 - val_loss: 0.9673\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9459 - val_loss: 0.9657\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9428 - val_loss: 0.9637\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9390 - val_loss: 0.9620\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9355 - val_loss: 0.9603\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9321 - val_loss: 0.9585\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9288 - val_loss: 0.9570\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9260 - val_loss: 0.9553\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.9227 - val_loss: 0.9534\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9193 - val_loss: 0.9519\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9159 - val_loss: 0.9496\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9122 - val_loss: 0.9480\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9089 - val_loss: 0.9461\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.9057 - val_loss: 0.9445\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9027 - val_loss: 0.9432\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8999 - val_loss: 0.9417\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8971 - val_loss: 0.9403\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8944 - val_loss: 0.9393\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8924 - val_loss: 0.9384\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8898 - val_loss: 0.9363\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8864 - val_loss: 0.9352\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8839 - val_loss: 0.9339\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8813 - val_loss: 0.9329\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8794 - val_loss: 0.9322\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8771 - val_loss: 0.9311\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8752 - val_loss: 0.9300\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8731 - val_loss: 0.9287\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8707 - val_loss: 0.9283\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8687 - val_loss: 0.9267\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8659 - val_loss: 0.9255\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8635 - val_loss: 0.9248\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8620 - val_loss: 0.9239\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8602 - val_loss: 0.9231\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8586 - val_loss: 0.9220\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8562 - val_loss: 0.9210\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 37us/sample - loss: 0.8542 - val_loss: 0.9200\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8522 - val_loss: 0.9188\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8503 - val_loss: 0.9180\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8484 - val_loss: 0.9171\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8461 - val_loss: 0.9157\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8437 - val_loss: 0.9149\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8424 - val_loss: 0.9141\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8402 - val_loss: 0.9131\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8387 - val_loss: 0.9123\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8371 - val_loss: 0.9119\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8359 - val_loss: 0.9111\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8343 - val_loss: 0.9109\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8332 - val_loss: 0.9098\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8312 - val_loss: 0.9092\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8299 - val_loss: 0.9083\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8283 - val_loss: 0.9077\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.8271 - val_loss: 0.9072\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8259 - val_loss: 0.9067\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8248 - val_loss: 0.9065\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8236 - val_loss: 0.9061\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8225 - val_loss: 0.9057\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8215 - val_loss: 0.9053\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8204 - val_loss: 0.9048\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8192 - val_loss: 0.9042\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8181 - val_loss: 0.9039\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8170 - val_loss: 0.9036\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8157 - val_loss: 0.9031\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8148 - val_loss: 0.9025\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8135 - val_loss: 0.9016\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8124 - val_loss: 0.9013\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8115 - val_loss: 0.9006\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8105 - val_loss: 0.9004\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8096 - val_loss: 0.9003\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8086 - val_loss: 0.9001\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8077 - val_loss: 0.8997\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8068 - val_loss: 0.8993\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8059 - val_loss: 0.8990\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8052 - val_loss: 0.8986\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8041 - val_loss: 0.8975\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8026 - val_loss: 0.8971\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8015 - val_loss: 0.8965\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8009 - val_loss: 0.8964\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8003 - val_loss: 0.8960\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7997 - val_loss: 0.8957\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7990 - val_loss: 0.8955\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7984 - val_loss: 0.8949\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7975 - val_loss: 0.8947\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7967 - val_loss: 0.8942\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7958 - val_loss: 0.8941\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7951 - val_loss: 0.8936\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7941 - val_loss: 0.8935\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7935 - val_loss: 0.8932\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7930 - val_loss: 0.8936\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7924 - val_loss: 0.8934\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7916 - val_loss: 0.8931\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7910 - val_loss: 0.8929\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7906 - val_loss: 0.8931\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7905 - val_loss: 0.8930\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7898 - val_loss: 0.8927\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7892 - val_loss: 0.8924\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7886 - val_loss: 0.8923\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7882 - val_loss: 0.8919\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7874 - val_loss: 0.8916\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7868 - val_loss: 0.8915\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7868 - val_loss: 0.8913\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7858 - val_loss: 0.8912\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7852 - val_loss: 0.8905\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7843 - val_loss: 0.8896\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7836 - val_loss: 0.8895\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7832 - val_loss: 0.8894\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7827 - val_loss: 0.8888\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7821 - val_loss: 0.8888\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7816 - val_loss: 0.8887\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7813 - val_loss: 0.8889\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7810 - val_loss: 0.8887\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7808 - val_loss: 0.8891\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7802 - val_loss: 0.8889\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7797 - val_loss: 0.8887\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7793 - val_loss: 0.8886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7790 - val_loss: 0.8889\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7785 - val_loss: 0.8889\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7782 - val_loss: 0.8889\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7776 - val_loss: 0.8890\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7771 - val_loss: 0.8888\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7768 - val_loss: 0.8890\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7766 - val_loss: 0.8888\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7761 - val_loss: 0.8885\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7761 - val_loss: 0.8884\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7753 - val_loss: 0.8882\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7752 - val_loss: 0.8881\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7748 - val_loss: 0.8880\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7745 - val_loss: 0.8884\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7741 - val_loss: 0.8881\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7737 - val_loss: 0.8881\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7734 - val_loss: 0.8879\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7732 - val_loss: 0.8878\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7730 - val_loss: 0.8875\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7726 - val_loss: 0.8879\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7722 - val_loss: 0.8877\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7717 - val_loss: 0.8881\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7715 - val_loss: 0.8883\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7712 - val_loss: 0.8879\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7709 - val_loss: 0.8879\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7705 - val_loss: 0.8878\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7701 - val_loss: 0.8882\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7697 - val_loss: 0.8880\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7695 - val_loss: 0.8878\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7692 - val_loss: 0.8879\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7689 - val_loss: 0.8878\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7687 - val_loss: 0.8878\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7686 - val_loss: 0.8881\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7685 - val_loss: 0.8884\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7683 - val_loss: 0.8883\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7682 - val_loss: 0.8884\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7680 - val_loss: 0.8882\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7678 - val_loss: 0.8884\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7676 - val_loss: 0.8886\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7673 - val_loss: 0.8890\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7674 - val_loss: 0.8889\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7669 - val_loss: 0.8888\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7668 - val_loss: 0.8894\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7665 - val_loss: 0.8895\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7664 - val_loss: 0.8894\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7661 - val_loss: 0.8892\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7658 - val_loss: 0.8892\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7656 - val_loss: 0.8891\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7657 - val_loss: 0.8888\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7654 - val_loss: 0.8888\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7653 - val_loss: 0.8891\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7652 - val_loss: 0.8896\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7650 - val_loss: 0.8890\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7648 - val_loss: 0.8891\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7645 - val_loss: 0.8890\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7643 - val_loss: 0.8892\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7642 - val_loss: 0.8892\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7639 - val_loss: 0.8899\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7638 - val_loss: 0.8898\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7635 - val_loss: 0.8895\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7634 - val_loss: 0.8895\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7633 - val_loss: 0.8899\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7632 - val_loss: 0.8899\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7630 - val_loss: 0.8899\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7626 - val_loss: 0.8900\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7626 - val_loss: 0.8905\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7625 - val_loss: 0.8906\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7623 - val_loss: 0.8905\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7623 - val_loss: 0.8909\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7623 - val_loss: 0.8908\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7623 - val_loss: 0.8909\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7618 - val_loss: 0.8907\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7618 - val_loss: 0.8906\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7616 - val_loss: 0.8905\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7615 - val_loss: 0.8906\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7612 - val_loss: 0.8906\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7612 - val_loss: 0.8909\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7611 - val_loss: 0.8904\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7609 - val_loss: 0.8904\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7608 - val_loss: 0.8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7606 - val_loss: 0.8903\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7605 - val_loss: 0.8905\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7605 - val_loss: 0.8906\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7605 - val_loss: 0.8905\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7603 - val_loss: 0.8904\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7601 - val_loss: 0.8906\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7601 - val_loss: 0.8906\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7600 - val_loss: 0.8907\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7599 - val_loss: 0.8904\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7599 - val_loss: 0.8905\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7598 - val_loss: 0.8907\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7599 - val_loss: 0.8908\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7597 - val_loss: 0.8913\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7596 - val_loss: 0.8909\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7596 - val_loss: 0.8915\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7595 - val_loss: 0.8916\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7594 - val_loss: 0.8919\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7593 - val_loss: 0.8919\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7593 - val_loss: 0.8915\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7591 - val_loss: 0.8911\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7592 - val_loss: 0.8907\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7591 - val_loss: 0.8912\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7591 - val_loss: 0.8914\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7591 - val_loss: 0.8915\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7591 - val_loss: 0.8915\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7589 - val_loss: 0.8915\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7589 - val_loss: 0.8914\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7588 - val_loss: 0.8914\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7588 - val_loss: 0.8912\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7587 - val_loss: 0.8913\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7588 - val_loss: 0.8911\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7587 - val_loss: 0.8907\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7586 - val_loss: 0.8909\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7588 - val_loss: 0.8908\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7584 - val_loss: 0.8912\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7584 - val_loss: 0.8912\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7584 - val_loss: 0.8911\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7584 - val_loss: 0.8912\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7585 - val_loss: 0.8911\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7583 - val_loss: 0.8913\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7583 - val_loss: 0.8914\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7582 - val_loss: 0.8917\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7581 - val_loss: 0.8920\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7581 - val_loss: 0.8920\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7581 - val_loss: 0.8919\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7581 - val_loss: 0.8922\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7580 - val_loss: 0.8925\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7580 - val_loss: 0.8925\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7579 - val_loss: 0.8927\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7579 - val_loss: 0.8926\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7579 - val_loss: 0.8923\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7579 - val_loss: 0.8927\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7579 - val_loss: 0.8934\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7578 - val_loss: 0.8934\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7578 - val_loss: 0.8933\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7578 - val_loss: 0.8931\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7578 - val_loss: 0.8931\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7577 - val_loss: 0.8929\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7576 - val_loss: 0.8930\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7579 - val_loss: 0.8930\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7577 - val_loss: 0.8928\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7576 - val_loss: 0.8929\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7576 - val_loss: 0.8929\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7576 - val_loss: 0.8932\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7575 - val_loss: 0.8929\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7574 - val_loss: 0.8934\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7574 - val_loss: 0.8933\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7575 - val_loss: 0.8934\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7574 - val_loss: 0.8938\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7572 - val_loss: 0.8938\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7571 - val_loss: 0.8938\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7573 - val_loss: 0.8943\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7570 - val_loss: 0.8942\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7571 - val_loss: 0.8942\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7570 - val_loss: 0.8942\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7570 - val_loss: 0.8940\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7571 - val_loss: 0.8940\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7570 - val_loss: 0.8940\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7570 - val_loss: 0.8940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7569 - val_loss: 0.8941\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7570 - val_loss: 0.8940\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7568 - val_loss: 0.8940\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7568 - val_loss: 0.8941\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7567 - val_loss: 0.8943\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7566 - val_loss: 0.8943\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7566 - val_loss: 0.8947\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7566 - val_loss: 0.8947\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7566 - val_loss: 0.8948\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7565 - val_loss: 0.8949\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7566 - val_loss: 0.8948\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7565 - val_loss: 0.8949\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7565 - val_loss: 0.8951\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7565 - val_loss: 0.8954\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7565 - val_loss: 0.8958\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7566 - val_loss: 0.8958\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7564 - val_loss: 0.8963\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7563 - val_loss: 0.8964\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7563 - val_loss: 0.8969\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7562 - val_loss: 0.8967\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7563 - val_loss: 0.8964\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7563 - val_loss: 0.8964\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7562 - val_loss: 0.8964\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7562 - val_loss: 0.8962\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7562 - val_loss: 0.8965\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7564 - val_loss: 0.8966\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.8966\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7561 - val_loss: 0.8968\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7563 - val_loss: 0.8970\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.8968\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7561 - val_loss: 0.8969\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.8968\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.8965\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7561 - val_loss: 0.8964\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7566 - val_loss: 0.8972\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7562 - val_loss: 0.8972\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7562 - val_loss: 0.8975\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7560 - val_loss: 0.8975\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.8976\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.8976\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7561 - val_loss: 0.8981\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.8984\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7560 - val_loss: 0.8984\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.8991\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7561 - val_loss: 0.8988\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7562 - val_loss: 0.8984\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7560 - val_loss: 0.8986\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7560 - val_loss: 0.8986\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7563 - val_loss: 0.8986\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7561 - val_loss: 0.8986\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7563 - val_loss: 0.8984\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.8982\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7560 - val_loss: 0.8981\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.8982\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7560 - val_loss: 0.8983\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7560 - val_loss: 0.8979\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7559 - val_loss: 0.8979\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7560 - val_loss: 0.8977\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7560 - val_loss: 0.8980\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.8981\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7559 - val_loss: 0.8987\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7560 - val_loss: 0.8989\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7560 - val_loss: 0.8990\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.8990\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7559 - val_loss: 0.8991\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7559 - val_loss: 0.8991\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7559 - val_loss: 0.8988\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7559 - val_loss: 0.8987\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.8990\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.8993\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7558 - val_loss: 0.8993\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7559 - val_loss: 0.8993\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7559 - val_loss: 0.8992\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7560 - val_loss: 0.8994\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9000\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.8999\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7559 - val_loss: 0.8998\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7558 - val_loss: 0.8996\n",
      "Epoch 474/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7559 - val_loss: 0.8995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7559 - val_loss: 0.8995\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7558 - val_loss: 0.8999\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7558 - val_loss: 0.8995\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7559 - val_loss: 0.8996\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7558 - val_loss: 0.8997\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9003\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7559 - val_loss: 0.9001\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7558 - val_loss: 0.8998\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7558 - val_loss: 0.9000\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7557 - val_loss: 0.9001\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9003\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7558 - val_loss: 0.9008\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7557 - val_loss: 0.9007\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7558 - val_loss: 0.9013\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7559 - val_loss: 0.9012\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7557 - val_loss: 0.9009\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7556 - val_loss: 0.9009\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7558 - val_loss: 0.9013\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7558 - val_loss: 0.9013\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7558 - val_loss: 0.9016\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7559 - val_loss: 0.9014\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7558 - val_loss: 0.9014\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7556 - val_loss: 0.9014\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7557 - val_loss: 0.9016\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7557 - val_loss: 0.9014\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7557 - val_loss: 0.9012\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl81fWd7/HX5+RkIytkYQsYNpFFlhgVK1MFbUfr0tbltlprr7Xy0HFaO21ndDq97dTpvaPTedRW7YzVqTpWqm3HpY7X9VpcqAqyCoJAQJDIkhC2BEjIST73j/MjxBBIhJz8knPez8fjPM7v/H7f8zufbwh5n9/3t5m7IyIiAhAJuwAREek7FAoiItJGoSAiIm0UCiIi0kahICIibRQKIiLSRqEgIiJtFAoiItJGoSAiIm2iYRfwSRUXF3t5eXnYZYiI9CuLFy/e4e4lXbXrd6FQXl7OokWLwi5DRKRfMbNN3Wmn4SMREWmjUBARkTYKBRERadPv9imISN/T3NxMdXU1jY2NYZeS8rKysigrKyM9Pf243p+wUDCzLOB1IDP4nP9y9x91aJMJPAKcBtQBX3L3jYmqSUQSo7q6mry8PMrLyzGzsMtJWe5OXV0d1dXVjBo16rjWkcjhoyZgtrtPBaYBF5jZjA5trgd2uftY4C7gzgTWIyIJ0tjYSFFRkQIhZGZGUVHRCW2xJSwUPK4heJkePDre5u3zwH8G0/8FnGf6rRLpl/Rft2840X+HhO5oNrM0M1sG1AAvu/uCDk2GA5sB3D0G7AGKOlnPHDNbZGaLamtrj6uWNdvqueP599nb2Hxc7xcRSQUJDQV3b3H3aUAZcIaZTe7QpLNIO+Km0e5+v7tXuntlSUmXJ+R1avPO/dz32nqqahq6biwi/UpdXR3Tpk1j2rRpDBkyhOHDh7e9PnjwYLfWcd1117FmzZpjtvnlL3/J3Llze6JkZs6cybJly3pkXT2pV44+cvfdZvYqcAGwst2iamAEUG1mUaAA2JmIGsaU5gKwvqaBipEDE/ERIhKSoqKitj+w//iP/0hubi7f+973PtbG3XF3IpHOvws/9NBDXX7OzTfffOLF9nEJ21IwsxIzKwyms4Hzgfc7NHsG+FowfQXwJ3c/YkuhJ4wYmE1GWoT1tfsSsXoR6YOqqqqYPHkyN954IxUVFWzdupU5c+ZQWVnJpEmTuP3229vaHvrmHovFKCws5LbbbmPq1KmcddZZ1NTUAPCDH/yAn//8523tb7vtNs444wzGjx/Pm2++CcC+ffu4/PLLmTp1KldddRWVlZVdbhE8+uijnHrqqUyePJnvf//7AMRiMb761a+2zb/77rsBuOuuu5g4cSJTp07lmmuu6fGfWSK3FIYC/2lmacTD5/fu/qyZ3Q4scvdngF8DvzGzKuJbCF9OVDHRtAjlxQM0fCSSYD/+7/dYtWVvj65z4rB8fnTJpON676pVq3jooYe47777ALjjjjsYNGgQsViMWbNmccUVVzBx4sSPvWfPnj2cc8453HHHHXznO9/hwQcf5Lbbbjti3e7OwoULeeaZZ7j99tt54YUXuOeeexgyZAhPPPEEy5cvp6Ki4pj1VVdX84Mf/IBFixZRUFDA+eefz7PPPktJSQk7duxgxYoVAOzevRuAf/mXf2HTpk1kZGS0zetJiTz66F13n+7uU9x9srvfHsz/YRAIuHuju1/p7mPd/Qx335CoegDGlOSyoVahIJJKxowZw+mnn972+rHHHqOiooKKigpWr17NqlWrjnhPdnY2F154IQCnnXYaGzdu7HTdl1122RFt5s+fz5e/HP9+O3XqVCZNOnaYLViwgNmzZ1NcXEx6ejpXX301r7/+OmPHjmXNmjXccsstvPjiixQUFAAwadIkrrnmGubOnXvcJ6gdS0qd0TymJJeXVm3nYKyVjKiu8CGSCMf7jT5RcnJy2qbXrVvHL37xCxYuXEhhYSHXXHNNp8f0Z2RktE2npaURi8U6XXdmZuYRbT7pCPjR2hcVFfHuu+/y/PPPc/fdd/PEE09w//338+KLL/Laa6/xxz/+kZ/85CesXLmStLS0T/SZx5JSfxnHlubS0upsqtN+BZFUtHfvXvLy8sjPz2fr1q28+OKLPf4ZM2fO5Pe//z0AK1as6HRLpL0ZM2Ywb9486urqiMViPP7445xzzjnU1tbi7lx55ZX8+Mc/ZsmSJbS0tFBdXc3s2bP56U9/Sm1tLfv37+/R+lNuSwFgfW0D4wbnhVyNiPS2iooKJk6cyOTJkxk9ejRnn312j3/GN7/5Ta699lqmTJlCRUUFkydPbhv66UxZWRm333475557Lu7OJZdcwkUXXcSSJUu4/vrrcXfMjDvvvJNYLMbVV19NfX09ra2t3HrrreTl9ezfMkvQwT4JU1lZ6cd7k519TTEm/ehF/vYvx3PzrLE9XJlI6lq9ejUTJkwIu4w+IRaLEYvFyMrKYt26dXz2s59l3bp1RKO99x28s38PM1vs7pVdvTelthRyMqMMK8hivY5AEpEEaWho4LzzziMWi+Hu/OpXv+rVQDhR/afSHjKmNJcqHYEkIglSWFjI4sWLwy7juKXUjmaI71dYX9PwiY8QEJFj0/+pvuFE/x1SLxRKc9l3sIXte5vCLkUkaWRlZVFXV6dgCNmh+ylkZWUd9zpSb/ioJH7MclVNA0MKjv8HJyKHlZWVUV1dzfFexVh6zqE7rx2vlAuFsaWHD0udOa445GpEkkN6evpx3+lL+paUGz4qyc0kLyvKeu1sFhE5QsqFgpkxpiRXF8YTEelEyoUCxIeQtKUgInKklAyFMSW5bN/bRL1uzSki8jEpGgqHj0ASEZHDUjIUJgzNB+D9bfUhVyIi0rekZCiUDcwmLzPK6q09e3coEZH+LiVDwcw4ZWhej98yUESkv0vJUID4ENL72+ppbdVp+SIih6R0KDQ0xajedSDsUkRE+oyUDgWAVdqvICLSJmVDYfzgPCKGdjaLiLSTsqGQnZFGeXGOQkFEpJ2UDQWIDyGt3qZQEBE5JKVDYeLQfDbvPMBeXe5CRARQKADw/lad2SwiAikeCoeOQNJ+BRGRuJQOhcH5mQwckK5QEBEJpHQomFl8Z7NCQUQESPFQgPgQ0prt9bTochciIgqFCUPzaWxu5YMd+8IuRUQkdAqFoXmAdjaLiIBCgXGleaSnmUJBRASFAhnRCGNKcnVhPBERFApA/CQ2bSmIiCQwFMxshJnNM7PVZvaemd3SSZtzzWyPmS0LHj9MVD3HMmFoPtv3NrFz38EwPl5EpM+IJnDdMeC77r7EzPKAxWb2sruv6tDuDXe/OIF1dKn9mc1njy0OsxQRkVAlbEvB3be6+5Jguh5YDQxP1OedCB2BJCIS1yv7FMysHJgOLOhk8VlmttzMnjezSb1RT0dFuZmU5mVqZ7OIpLxEDh8BYGa5wBPAt92941/dJcBJ7t5gZp8DngbGdbKOOcAcgJEjRyakzvjlLnS1VBFJbQndUjCzdOKBMNfdn+y43N33untDMP0ckG5mRwzqu/v97l7p7pUlJSUJqXXisHyqauo5GGtNyPpFRPqDRB59ZMCvgdXu/rOjtBkStMPMzgjqqUtUTccyYWg+zS1OVU1DGB8vItInJHL46Gzgq8AKM1sWzPs+MBLA3e8DrgBuMrMYcAD4sruHcmW6ie12Nk8clh9GCSIioUtYKLj7fMC6aHMvcG+iavgkyotyyIxGdASSiKQ0ndEciKZFGD8kj9XbFAoikroUCu1MGBI/AimkESwRkdApFNqZMDSPnfsOUlPfFHYpIiKhUCi0M3FYAQCrtmgISURSk0KhnUnD8okYLNu8O+xSRERCoVBoJyczyvgh+SxVKIhIilIodDB9ZCFLP9xFa6t2NotI6lEodDB9RCH1jTE27NCZzSKSehQKHUwfORCAJR9qCElEUo9CoYPRxTnkZ0VZqlAQkRSkUOggEjGmjRzI0g93hV2KiEivUyh0YvqIQtZur6ehKRZ2KSIivUqh0InpIwtpdXi3WkNIIpJaFAqdmDaiEED7FUQk5SgUOlE4IIPRJTnaryAiKUehcBQVIwey5MPdumKqiKQUhcJRVIwcyM59B9lUtz/sUkREeo1C4SgqTorvV1iiISQRSSEKhaMYV5pHbmZUoSAiKUWhcBRpEWPaiEIWb9IRSCKSOhQKx1Bx0kDWbNurk9hEJGUoFI6h4tBJbLq/goikCIXCMUwfceiKqdqvICKpQaFwDAUD0hk/OI8FH+wMuxQRkV6hUOjC2WOLWfjBThqbW8IuRUQk4RQKXTh7bBFNsVYNIYlISlAodOHM0UWkRYw/V+0IuxQRkYRTKHQhNzPKtBGFzK+qC7sUEZGEUyh0w9ljilhRvZs9B5rDLkVEJKEUCt3wqbHFtDos2KCtBRFJbgqFbpg+spCs9AhvrlcoiEhyUyh0Q2Y0jdPLB2lns4gkPYVCN80cW8y6mgZq9jaGXYqISMIoFLrp7LHFABpCEpGkplDopolD8ykckM4b6zSEJCLJK2GhYGYjzGyema02s/fM7JZO2piZ3W1mVWb2rplVJKqeExWJGH8xroTX1tbS2qr7NotIckrklkIM+K67TwBmADeb2cQObS4ExgWPOcC/J7CeEzZrfAk7GppYuWVP2KWIiCREwkLB3be6+5Jguh5YDQzv0OzzwCMe9zZQaGZDE1XTiTrn5BLM4E/v14RdiohIQvTKPgUzKwemAws6LBoObG73upojg6PPKMrNZNqIQuYpFEQkSSU8FMwsF3gC+La77+24uJO3HDFgb2ZzzGyRmS2qra1NRJndNmt8Kcur91Bb3xRqHSIiiZDQUDCzdOKBMNfdn+ykSTUwot3rMmBLx0bufr+7V7p7ZUlJSWKK7abZp5QC8NracMNJRCQRuhUKZjbGzDKD6XPN7FtmVtjFewz4NbDa3X92lGbPANcGRyHNAPa4+9ZPUH+vmzQsn9K8TA0hiUhS6u6WwhNAi5mNJf6HfhTw2y7eczbwVWC2mS0LHp8zsxvN7MagzXPABqAKeAD4q0/cg15mZswaX8rr62ppbmkNuxwRkR4V7Wa7VnePmdkXgZ+7+z1mtvRYb3D3+XS+z6B9Gwdu7mYNfcasU0r43aLNLN60ixmji8IuR0Skx3R3S6HZzK4CvgY8G8xLT0xJfd/McSWkp5mGkEQk6XQ3FK4DzgL+t7t/YGajgEcTV1bflpsZ5YxRg5i3RqEgIsmlW6Hg7qvc/Vvu/piZDQTy3P2OBNfWp80aX8ra7Q1U79ofdikiIj2mu0cfvWpm+WY2CFgOPGRmRzuiKCXMCg5N1RCSiCST7g4fFQQnnl0GPOTupwHnJ66svm90cQ4nFQ3QJS9EJKl0NxSiwTWJ/geHdzSnNDNj9iml/Hl9HXsbm8MuR0SkR3Q3FG4HXgTWu/s7ZjYaWJe4svqHi6cM42CslZfe2x52KSIiPaK7O5r/4O5T3P2m4PUGd788saX1fRUjCykbmM0zy4+4MoeISL/U3R3NZWb2lJnVmNl2M3vCzMoSXVxfZ2ZcMnUYf67aQV2DLpAnIv1fd4ePHiJ+naJhxC9t/d/BvJR36dRhtLQ6z63o05dsEhHplu6GQom7P+TuseDxMBDu5Ur7iFOG5DGuNFdDSCKSFLobCjvM7BozSwse1wB1iSysvzAzLp06jHc27uKj3QfCLkdE5IR0NxS+Tvxw1G3AVuAK4pe+EODSacMAeGaZthZEpH/r7tFHH7r7pe5e4u6l7v4F4ieyCXBSUQ4VIwt5amk18Qu/ioj0Tydy57Xv9FgVSeCyijLWbm/gvS0d7zgqItJ/nEgoHPNeCanm4ilDyUiL8NTSj8IuRUTkuJ1IKGicpJ3CARnMOqWEPy7bQkx3ZBORfuqYoWBm9Wa2t5NHPfFzFqSdyyrK2NHQxBtVO8IuRUTkuBwzFNw9z93zO3nkuXt3b+WZMmaNL6VwQDpPLdEQkoj0TycyfCQdZEQjXDxlKC+t2kZDUyzsckREPjGFQg+7rKKMxuZWntdlL0SkH1Io9LDpIwoZVZzDkxpCEpF+SKHQw8yML0wbztsf1LFFl70QkX5GoZAAX5w+HHd0zoKI9DsKhQQYWTSAM8oH8cRiXfZCRPoXhUKCXFlZxoYd+1i8aVfYpYiIdJtCIUEumjKUnIw0fvfO5rBLERHpNoVCggzIiHLJ1GH83xVbdc6CiPQbCoUEurJyBPsPtvDcuzpnQUT6B4VCAlWMLGRMSQ6/W6QhJBHpHxQKCWRmfOn0ESzetIuqmvqwyxER6ZJCIcG+OL2MaMT4/aLqsEsREemSQiHBSvIyOW9CKU8uqaZZ91kQkT5OodALvnT6CHY0HOSFldvCLkVE5JgUCr3gnJNLGV2cw/2vb9AZziLSpyUsFMzsQTOrMbOVR1l+rpntMbNlweOHiaolbGkRY86nR7Pioz28tb4u7HJERI4qkVsKDwMXdNHmDXefFjxuT2AtofvC9OGU5GVy3+sbwi5FROSoEhYK7v46sDNR6+9vstLTuO7scl5fW8uqLXvDLkdEpFNh71M4y8yWm9nzZjYp5FoS7itnnkRORhq/en192KWIiHQqzFBYApzk7lOBe4Cnj9bQzOaY2SIzW1RbW9trBfa0gux0rj5zJM++u5XNO/eHXY6IyBFCCwV33+vuDcH0c0C6mRUfpe397l7p7pUlJSW9WmdP+/rMUUQMfj3/g7BLERE5QmihYGZDzMyC6TOCWpL+0JyhBdl8ftpwfvfOZnbtOxh2OSIiH5PIQ1IfA94CxptZtZldb2Y3mtmNQZMrgJVmthy4G/iyp8hB/HM+PZoDzS385u1NYZciIvIx0USt2N2v6mL5vcC9ifr8vuzkwXmcd0opD7+5kRv+YjTZGWlhlyQiAoR/9FHK+qtZY9i57yAP/ln7FkSk71AohOS0kwZx/oTB3Pfqeu1bEJE+Q6EQolsvGM++gzHunVcVdikiIoBCIVTjBudx5Wkj+M1bm3Tegoj0CQqFkH37M+Mwg5+9vDbsUkREFAphG1qQzddnjuLpZR/x3pY9YZcjIilOodAH3HjOGPKz0vnn597X/RZEJFQKhT6gIDud73zmZOZX7eCZ5VvCLkdEUphCoY+4ZsZJTC0r4J+eXcXu/TpEVUTCoVDoI9Iixv+57FR27W/mzhfeD7scEUlRCoU+ZNKwAq6fOYrHFm5m4Qe6P5GI9D6FQh/z7fPHMbwwm+8/tYKmWEvY5YhIilEo9DEDMqL85AuTqapp4Fev6X7OItK7FAp90KxTSrloylDunVfFhtqGsMsRkRSiUOijfnTxRDKjEf7hqZU6d0FEeo1CoY8qzc/i1gtO4a0NdTy2cHPY5YhIilAo9GFXnzGSmWOL+adnV2kYSUR6hUKhD4tEjH+9ciqZ6RH+5nfLaG5pDbskEUlyCoU+bkhBFv/8xVNZXr2HX/y/dWGXIyJJTqHQD1x46lCuPK2Mf3u1inc26qQ2EUkchUI/8aNLJzFi0AC+/fgy6hqawi5HRJKUQqGfyM2Mcs9V06ltaOKmuUs4GNP+BRHpeQqFfmRKWSE/vWIKCz/Yyf96WucviEjPi4ZdgHwyn582nHXbG7h3XhUjBmXz17PHhV2SiCQRhUI/9N3Pnkz1rv3860trGVuaxwWTh4RdkogkCQ0f9UNmxh2XT2HaiEK+9dhS3lhXG3ZJIpIkFAr9VFZ6Gg9fdzqjS3K44ZFFLNhQF3ZJIpIEFAr9WOGADB79xpkML8zm6w+/w9IPd4Vdkoj0cwqFfq44N5Pf3jCD4rxMvvbgQlZ+tCfskkSkH1MoJIHB+VnM/caZ5GZGufbBhazdXh92SSLSTykUkkTZwAH89oYZRCPGV/5jAR/s2Bd2SSLSDykUkkh5cQ5zv3EmLa3O1Q+8zead+8MuSUT6GYVCkhk3OI9Hrz+TfU0xrnrgbd2HQUQ+EYVCEpo4LJ9Hv3Em+w+2cMV9b+moJBHpNoVCkppSVsiTN32K3MwoVz3wNq+s3h52SSLSDygUklh5cQ5P3PQpTh6cxw2PLOI/39yoi+iJyDElLBTM7EEzqzGzlUdZbmZ2t5lVmdm7ZlaRqFpSWUleJo/dMINZ40v50TPv8dePLaW+sTnsskSkj0rklsLDwAXHWH4hMC54zAH+PYG1pLSczCgPXFvJrRecwgsrt3HJPfN5b4tOchORIyUsFNz9deBY9478PPCIx70NFJrZ0ETVk+oiEeOmc8fw+JwZHGhu4Yv/9iZzF2zScJKIfEyY+xSGA5vbva4O5h3BzOaY2SIzW1RbqyuCnojTywfx3Lf+ghmji/iHp1by148tpaa+MeyyRKSPCDMUrJN5nX5tdff73b3S3StLSkoSXFbyK8rN5OH/eTp/d8F4XnpvG7N++ir/tbhaWw0iEmooVAMj2r0uA7aEVEvKiUSMvzp3LC/9zTlMGlbA9/6wnKseeFv7GkRSXJih8AxwbXAU0gxgj7tvDbGelDSqOIff3nAm//SFyazZVs/F98znb/+wnA/rdIkMkVSUsNtxmtljwLlAsZlVAz8C0gHc/T7gOeBzQBWwH7guUbXIsUXTInx1xklcOmUY9/xpHY+8vYknl37E56cN4+ZZYxlTkht2iSLSS6y/jSNXVlb6okWLwi4jqW3f28j9r29g7oJNNMVauejUoXxz9jjGD8kLuzQROU5mttjdK7tsp1CQo9nR0MR/vPEBv3lrI/sOtvCXkwbzzdnjmDy8IOzSROQTUihIj9m17yAPvbmRh/78AfWNMWaNL+Gb542jYuTAsEsTkW5SKEiP29vYzCNvbuTX8z9g1/5mZo4t5tqzTmLWKaWkp+kyWiJ9mUJBEmZfU4y5CzbxwBsfUFvfRHFuJpdXDOfKyhGMLdVOaZG+SKEgCdfc0sqra2r5/aLN/On9GlpancnD8/nMhCGcP7GUiUPzMevsHEUR6W0KBelVNfWNPL30I15YuY2lm3fjDsMLs7l02jD+ctIQTh1eQFpEASESFoWChKa2vol579fw/MqtvLa2llaH/KwoZ40p4tMnl/DpcSWMGDQg7DJFUopCQfqEuoYm/ry+jvnrapm/bgdb9sQvvje6JIdPjyvhnJNLOHP0IAZkJOw8ShFBoSB9kLuzvraB19bu4LW1tSzYUEdTrJVoxBg/JI8pZYVMLStg0rACTh6SS2Y0LeySRZKGQkH6vMbmFhZ+sJO3N9TxbvUellfvpr4xBkDEYOSgAYwtzWVMSfAozWFsSR4FA9JDrlyk/+luKGibXUKTlZ4W38dwcvxy6K2tzqad+3lvyx7WbKtnfW0D62v28fraHRxsaW17X3FuBqODoCgvGsDQwmyGF2YxrDCb0rws7dAWOQEKBekzIhFjVHEOo4pzuHjK4fktrc7mnfvjIREERVVtA8+v3Mru/R+/33RaxBiSn8WwwiyGFmQzLAiMw9PZ5GdHdaisyFEoFKTPS4sY5cU5lBfncN6EwR9btrexma27G9my5wBbdscfW3c38tHuAyzdvIvnV26lueXjQ6RZ6REKszMoHJBOfnY6hdnpFGSnU5yXyZD8LAbnZ1GUm0FeVpS8rHTys6LkZESJaAtEUoBCQfq1/Kx08oekH/UKrq2tzo6GJj7afYCtexrZsvsA2/Y0sudAM3sONLP7QDMf7tzP7v3N7GhoItba+T42M8jNjJKflU5e1uHnvKwoAzKj5GSkMSAjSm5mlAGZafHnjCg5mfH5mdEIGdHI4ee0NDKCaQ13SV+iUJCkFokYpflZlOZnMb2Ltq2tTt2+g2zf28ju/c3sbWymvrGZvQdi8efGWDAvxt4DzWzd08jammYOHGxhX1MLB5pbjqvGaMQ+FhgZ0QgZaREyo4eDI7N9oETTyEiLfGxZRrtl0YgRMTAzIhafjphhwXMkEjy3W27t2kUiR39vWlfr7mR9aZFjL4+YYW01fbzdoXVruK/3KBREApGIUZKXSUle5nG9v6XVOdDcwr6mGA1NMfY3tcSfD8Y4GGvlYEsrTc2tNLW0cjDWSlOsJT4/duh16+F2wbJD8+obY9QFyzq+tynWetQtnGRxOFQ6CZQOgQVBkNAuVDpdZ9dB01mTjvOsk7V3+r5ufP4RczrMuOr0kdzw6dFHrrwHKRREekhaxMjNjA8hDe66eY9qbfW20GlxpzV4uBNMx9u407bcD813p7WVDu3jyw61aWnt0L7jujuuL/i8Yy1396DN4c9uab/u1i7e20ltLcF7If58qMaOOs7p7Mh8P6LVkW/sLIo7O8y/e5/X9XpK84/vC8snoVAQSQKRiJEVSSMrXSf8yYnRRfBFRKSNQkFERNooFEREpI1CQURE2igURESkjUJBRETaKBRERKSNQkFERNr0u5vsmFktsOk4314M7OjBcvoD9Tk1qM+p4UT6fJK7l3TVqN+Fwokws0XdufNQMlGfU4P6nBp6o88aPhIRkTYKBRERaZNqoXB/2AWEQH1ODepzakh4n1Nqn4KIiBxbqm0piIjIMaREKJjZBWa2xsyqzOy2sOvpKWb2oJnVmNnKdvMGmdnLZrYueB4YzDczuzv4GbxrZhXhVX78zGyEmc0zs9Vm9p6Z3RLMT9p+m1mWmS00s+VBn38czB9lZguCPv/OzDKC+ZnB66pgeXmY9Z8IM0szs6Vm9mzwOqn7bGYbzWyFmS0zs0XBvF793U76UDCzNOCXwIXAROAqM5sYblU95mHggg7zbgNecfdxwCvBa4j3f1zwmAP8ey/V2NNiwHfdfQIwA7g5+PdM5n43AbPdfSowDbjAzGYAdwJ3BX3eBVwftL8e2OXuY4G7gnb91S3A6navU6HPs9x9WrtDT3v3d9uDW90l6wM4C3ix3eu/B/4+7Lp6sH/lwMp2r9cAQ4PpocCaYPpXwFWdtevPD+CPwGdSpd/AAGAJcCbxk5iiwfy233PgReCsYDoatLOwaz+OvpYR/yM4G3iW+B2Lk73PG4HiDvN69Xc76bcUgOHA5navq4N5yWqwu28FCJ5Lg/lJ93MIhgimAwtI8n4HwyjLgBrgZWA9sNvdY0GT9v1q63OwfA9Q1LsV94ifA38HtAavi0j+PjvwkpktNrM5wbxe/d1OhXs0WyfzUvGQq6T6OZgC1ORGAAADnklEQVRZLvAE8G1332vWWffiTTuZ1+/67e4twDQzKwSeAiZ01ix47vd9NrOLgRp3X2xm5x6a3UnTpOlz4Gx332JmpcDLZvb+MdompM+psKVQDYxo97oM2BJSLb1hu5kNBQiea4L5SfNzMLN04oEw192fDGYnfb8B3H038Crx/SmFZnboi137frX1OVheAOzs3UpP2NnApWa2EXic+BDSz0nuPuPuW4LnGuLhfwa9/LudCqHwDjAuOGohA/gy8EzINSXSM8DXgumvER9zPzT/2uCIhRnAnkObpP2JxTcJfg2sdveftVuUtP02s5JgCwEzywbOJ77zdR5wRdCsY58P/SyuAP7kwaBzf+Huf+/uZe5eTvz/7J/c/SskcZ/NLMfM8g5NA58FVtLbv9th71jppZ03nwPWEh+H/Yew6+nBfj0GbAWaiX9ruJ74OOorwLrgeVDQ1ogfhbUeWAFUhl3/cfZ5JvFN5HeBZcHjc8ncb2AKsDTo80rgh8H80cBCoAr4A5AZzM8KXlcFy0eH3YcT7P+5wLPJ3uegb8uDx3uH/lb19u+2zmgWEZE2qTB8JCIi3aRQEBGRNgoFERFpo1AQEZE2CgUREWmjUBAJmFlLcHXKQ48eu6KumZVbu6vZivRVqXCZC5HuOuDu08IuQiRM2lIQ6UJwjfs7g3saLDSzscH8k8zsleBa9q+Y2chg/mAzeyq4/8FyM/tUsKo0M3sguCfCS8HZyZjZt8xsVbCex0PqpgigUBBpL7vD8NGX2i3b6+5nAPcSvwYPwfQj7j4FmAvcHcy/G3jN4/c/qCB+dirEr3v/S3efBOwGLg/m3wZMD9ZzY6I6J9IdOqNZJGBmDe6e28n8jcRvcrMhuBjfNncvMrMdxK9f3xzM3+ruxWZWC5S5e1O7dZQDL3v8RimY2a1Aurv/xMxeABqAp4Gn3b0hwV0VOSptKYh0jx9l+mhtOtPUbrqFw/v0LiJ+DZvTgMXtrgIq0usUCiLd86V2z28F028Sv4InwFeA+cH0K8BN0HZznPyjrdTMIsAId59H/IYyhcARWysivUXfSEQOyw7ubnbIC+5+6LDUTDNbQPyL1FXBvG8BD5rZ3wK1wHXB/FuA+83seuJbBDcRv5ptZ9KAR82sgPhVL+/y+D0TREKhfQoiXQj2KVS6+46waxFJNA0fiYhIG20piIhIG20piIhIG4WCiIi0USiIiEgbhYKIiLRRKIiISBuFgoiItPn/vflUjcRFuWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input = Input(shape=(1,))\n",
    "output = Dense(1)(input)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 773us/sample - loss: 9.2841 - val_loss: 6.2274\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 9.0943 - val_loss: 6.1124\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 8.9109 - val_loss: 6.0089\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 8.7440 - val_loss: 5.8910\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 8.5630 - val_loss: 5.7859\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 8.3956 - val_loss: 5.6774\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 8.2235 - val_loss: 5.5782\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 8.0642 - val_loss: 5.4855\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 7.9170 - val_loss: 5.3886\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 7.7642 - val_loss: 5.2898\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 7.6037 - val_loss: 5.1782\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 7.4276 - val_loss: 5.0910\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 7.2918 - val_loss: 5.0047\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 7.1553 - val_loss: 4.9204\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 7.0182 - val_loss: 4.8290\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 6.8704 - val_loss: 4.7464\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 6.7404 - val_loss: 4.6718\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 6.6189 - val_loss: 4.5862\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 6.4813 - val_loss: 4.5036\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 6.3510 - val_loss: 4.4245\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 6.2242 - val_loss: 4.3476\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 6.1008 - val_loss: 4.2790\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 5.9926 - val_loss: 4.2162\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 5.8885 - val_loss: 4.1389\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 5.7685 - val_loss: 4.0733\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 5.6647 - val_loss: 4.0053\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 5.5552 - val_loss: 3.9358\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 5.4458 - val_loss: 3.8674\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 5.3383 - val_loss: 3.8045\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 5.2402 - val_loss: 3.7467\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 5.1462 - val_loss: 3.6938\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 5.0619 - val_loss: 3.6384\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 4.9726 - val_loss: 3.5892\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 4.8924 - val_loss: 3.5240\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 4.7892 - val_loss: 3.4696\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 4.7007 - val_loss: 3.4100\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 4.6077 - val_loss: 3.3592\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 4.5277 - val_loss: 3.3096\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 4.4503 - val_loss: 3.2620\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 4.3746 - val_loss: 3.2147\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 4.2999 - val_loss: 3.1666\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 4.2226 - val_loss: 3.1164\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 4.1422 - val_loss: 3.0736\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 4.0738 - val_loss: 3.0274\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 3.9994 - val_loss: 2.9807\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 3.9270 - val_loss: 2.9376\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 3.8576 - val_loss: 2.8958\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 3.7912 - val_loss: 2.8534\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.7250 - val_loss: 2.8122\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.6584 - val_loss: 2.7732\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.5978 - val_loss: 2.7389\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 3.5424 - val_loss: 2.7004\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.4821 - val_loss: 2.6652\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 3.4257 - val_loss: 2.6274\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.3676 - val_loss: 2.5906\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 3.3091 - val_loss: 2.5510\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.2462 - val_loss: 2.5194\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.1941 - val_loss: 2.4807\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.1329 - val_loss: 2.4451\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.0761 - val_loss: 2.4102\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 3.0241 - val_loss: 2.3744\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 2.9695 - val_loss: 2.3422\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.9189 - val_loss: 2.3127\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 2.8745 - val_loss: 2.2854\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.8316 - val_loss: 2.2585\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.7887 - val_loss: 2.2303\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.7445 - val_loss: 2.2027\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.7016 - val_loss: 2.1780\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.6618 - val_loss: 2.1529\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.6219 - val_loss: 2.1277\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.5839 - val_loss: 2.1060\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.5476 - val_loss: 2.0784\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.5049 - val_loss: 2.0571\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.4710 - val_loss: 2.0334\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.4340 - val_loss: 2.0090\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.3972 - val_loss: 1.9869\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.3615 - val_loss: 1.9633\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.3243 - val_loss: 1.9410\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.2901 - val_loss: 1.9200\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 42us/sample - loss: 2.2568 - val_loss: 1.9008\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.2271 - val_loss: 1.8826\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.1979 - val_loss: 1.8599\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.1653 - val_loss: 1.8418\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.1368 - val_loss: 1.8228\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.1085 - val_loss: 1.8036\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.0776 - val_loss: 1.7830\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.0468 - val_loss: 1.7635\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.0188 - val_loss: 1.7465\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.9931 - val_loss: 1.7295\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.9663 - val_loss: 1.7117\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.9382 - val_loss: 1.6939\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.9112 - val_loss: 1.6766\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.8840 - val_loss: 1.6622\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.8613 - val_loss: 1.6472\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.8381 - val_loss: 1.6312\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.8142 - val_loss: 1.6183\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.7940 - val_loss: 1.6046\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.7730 - val_loss: 1.5912\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.7524 - val_loss: 1.5742\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.7261 - val_loss: 1.5609\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.7056 - val_loss: 1.5470\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.6840 - val_loss: 1.5341\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.6650 - val_loss: 1.5198\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.6438 - val_loss: 1.5079\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.6259 - val_loss: 1.4964\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.6073 - val_loss: 1.4832\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5872 - val_loss: 1.4728\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.5706 - val_loss: 1.4607\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.5525 - val_loss: 1.4492\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.5363 - val_loss: 1.4395\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5212 - val_loss: 1.4281\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.5040 - val_loss: 1.4169\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.4871 - val_loss: 1.4071\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.4724 - val_loss: 1.3971\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.4569 - val_loss: 1.3880\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.4431 - val_loss: 1.3767\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.4261 - val_loss: 1.3675\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.4129 - val_loss: 1.3601\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.4013 - val_loss: 1.3525\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.3893 - val_loss: 1.3433\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.3759 - val_loss: 1.3353\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.3639 - val_loss: 1.3268\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.3513 - val_loss: 1.3167\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.3367 - val_loss: 1.3072\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.3231 - val_loss: 1.3008\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.3120 - val_loss: 1.2917\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.2987 - val_loss: 1.2836\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2873 - val_loss: 1.2755\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2759 - val_loss: 1.2674\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2645 - val_loss: 1.2610\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.2548 - val_loss: 1.2529\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2420 - val_loss: 1.2462\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.2318 - val_loss: 1.2365\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2179 - val_loss: 1.2301\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.2086 - val_loss: 1.2228\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1983 - val_loss: 1.2169\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.1894 - val_loss: 1.2110\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.1799 - val_loss: 1.2028\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1684 - val_loss: 1.1975\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1600 - val_loss: 1.1907\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.1499 - val_loss: 1.1843\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.1408 - val_loss: 1.1779\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1316 - val_loss: 1.1721\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1234 - val_loss: 1.1674\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.1161 - val_loss: 1.1619\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.1080 - val_loss: 1.1570\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.1007 - val_loss: 1.1523\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0938 - val_loss: 1.1474\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0873 - val_loss: 1.1431\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0807 - val_loss: 1.1373\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0720 - val_loss: 1.1338\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0656 - val_loss: 1.1290\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0588 - val_loss: 1.1232\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.0509 - val_loss: 1.1187\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.0447 - val_loss: 1.1145\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0381 - val_loss: 1.1108\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.0325 - val_loss: 1.1062\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0264 - val_loss: 1.1019\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 36us/sample - loss: 1.0203 - val_loss: 1.0982\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.0148 - val_loss: 1.0936\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.0084 - val_loss: 1.0892\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0023 - val_loss: 1.0856\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.9977 - val_loss: 1.0812\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9922 - val_loss: 1.0781\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9877 - val_loss: 1.0756\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9835 - val_loss: 1.0725\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9788 - val_loss: 1.0685\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9739 - val_loss: 1.0656\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9694 - val_loss: 1.0633\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9653 - val_loss: 1.0598\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.9609 - val_loss: 1.0577\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9572 - val_loss: 1.0548\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9525 - val_loss: 1.0518\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9478 - val_loss: 1.0485\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9433 - val_loss: 1.0452\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9384 - val_loss: 1.0426\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9346 - val_loss: 1.0397\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9304 - val_loss: 1.0377\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9273 - val_loss: 1.0360\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.9239 - val_loss: 1.0329\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9202 - val_loss: 1.0305\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9165 - val_loss: 1.0281\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9133 - val_loss: 1.0246\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9089 - val_loss: 1.0224\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9058 - val_loss: 1.0202\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9025 - val_loss: 1.0179\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8994 - val_loss: 1.0151\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8957 - val_loss: 1.0130\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8928 - val_loss: 1.0114\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8899 - val_loss: 1.0086\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8859 - val_loss: 1.0058\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8820 - val_loss: 1.0038\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8790 - val_loss: 1.0013\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8763 - val_loss: 0.9997\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8743 - val_loss: 0.9985\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8717 - val_loss: 0.9972\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8694 - val_loss: 0.9956\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8673 - val_loss: 0.9934\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8647 - val_loss: 0.9923\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8631 - val_loss: 0.9908\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8610 - val_loss: 0.9893\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8592 - val_loss: 0.9887\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8577 - val_loss: 0.9870\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8555 - val_loss: 0.9858\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8538 - val_loss: 0.9840\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8516 - val_loss: 0.9824\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8494 - val_loss: 0.9810\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8475 - val_loss: 0.9797\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8458 - val_loss: 0.9787\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8442 - val_loss: 0.9773\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8425 - val_loss: 0.9753\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8403 - val_loss: 0.9737\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8384 - val_loss: 0.9720\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8365 - val_loss: 0.9706\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8347 - val_loss: 0.9699\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8335 - val_loss: 0.9697\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8324 - val_loss: 0.9678\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8302 - val_loss: 0.9675\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8293 - val_loss: 0.9662\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8275 - val_loss: 0.9645\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8259 - val_loss: 0.9637\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8247 - val_loss: 0.9623\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8231 - val_loss: 0.9612\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8213 - val_loss: 0.9603\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8200 - val_loss: 0.9594\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8188 - val_loss: 0.9591\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8178 - val_loss: 0.9583\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8169 - val_loss: 0.9581\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8157 - val_loss: 0.9574\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8142 - val_loss: 0.9567\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8130 - val_loss: 0.9562\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8122 - val_loss: 0.9553\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8107 - val_loss: 0.9538\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8092 - val_loss: 0.9525\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8076 - val_loss: 0.9517\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8067 - val_loss: 0.9514\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8057 - val_loss: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8044 - val_loss: 0.9495\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8031 - val_loss: 0.9488\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8020 - val_loss: 0.9478\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8009 - val_loss: 0.9472\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7998 - val_loss: 0.9461\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7988 - val_loss: 0.9462\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7979 - val_loss: 0.9455\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7972 - val_loss: 0.9445\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7961 - val_loss: 0.9441\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7951 - val_loss: 0.9434\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7945 - val_loss: 0.9431\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7938 - val_loss: 0.9424\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7929 - val_loss: 0.9421\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7924 - val_loss: 0.9414\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7914 - val_loss: 0.9407\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7905 - val_loss: 0.9400\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7897 - val_loss: 0.9389\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7887 - val_loss: 0.9376\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7875 - val_loss: 0.9371\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7869 - val_loss: 0.9368\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7862 - val_loss: 0.9368\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7857 - val_loss: 0.9364\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7851 - val_loss: 0.9358\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7846 - val_loss: 0.9349\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7837 - val_loss: 0.9350\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7835 - val_loss: 0.9346\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7830 - val_loss: 0.9346\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7826 - val_loss: 0.9337\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7820 - val_loss: 0.9332\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7815 - val_loss: 0.9331\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7811 - val_loss: 0.9327\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7807 - val_loss: 0.9319\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 68us/sample - loss: 0.7799 - val_loss: 0.9314\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7794 - val_loss: 0.9307\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7788 - val_loss: 0.9301\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7781 - val_loss: 0.9297\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7777 - val_loss: 0.9287\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7768 - val_loss: 0.9287\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7764 - val_loss: 0.9279\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7756 - val_loss: 0.9277\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7755 - val_loss: 0.9271\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7752 - val_loss: 0.9270\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7745 - val_loss: 0.9273\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7743 - val_loss: 0.9266\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7740 - val_loss: 0.9273\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7739 - val_loss: 0.9272\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7735 - val_loss: 0.9273\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7731 - val_loss: 0.9269\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7729 - val_loss: 0.9267\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7725 - val_loss: 0.9260\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7720 - val_loss: 0.9255\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7716 - val_loss: 0.9249\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7713 - val_loss: 0.9248\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7709 - val_loss: 0.9246\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7708 - val_loss: 0.9241\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7705 - val_loss: 0.9237\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7698 - val_loss: 0.9234\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7696 - val_loss: 0.9230\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7693 - val_loss: 0.9225\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7690 - val_loss: 0.9224\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7688 - val_loss: 0.9215\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7687 - val_loss: 0.9217\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7683 - val_loss: 0.9207\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7678 - val_loss: 0.9204\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7676 - val_loss: 0.9200\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7674 - val_loss: 0.9196\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7670 - val_loss: 0.9193\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7668 - val_loss: 0.9190\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7664 - val_loss: 0.9183\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7659 - val_loss: 0.9180\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7658 - val_loss: 0.9186\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7659 - val_loss: 0.9185\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7658 - val_loss: 0.9179\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7652 - val_loss: 0.9177\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7649 - val_loss: 0.9173\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7647 - val_loss: 0.9174\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7646 - val_loss: 0.9171\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7643 - val_loss: 0.9169\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7642 - val_loss: 0.9170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7642 - val_loss: 0.9169\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7641 - val_loss: 0.9167\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7639 - val_loss: 0.9166\n",
      "Epoch 320/500\n",
      "105/105==============================] - ETA: 0s - loss: 0.690 - 0s 51us/sample - loss: 0.7636 - val_loss: 0.9164\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7636 - val_loss: 0.9160\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7632 - val_loss: 0.9156\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7633 - val_loss: 0.9152\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7631 - val_loss: 0.9152\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7629 - val_loss: 0.9158\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7628 - val_loss: 0.9151\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7625 - val_loss: 0.9147\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7622 - val_loss: 0.9151\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7622 - val_loss: 0.9147\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7620 - val_loss: 0.9149\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7620 - val_loss: 0.9144\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7617 - val_loss: 0.9142\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7617 - val_loss: 0.9140\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7615 - val_loss: 0.9137\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7613 - val_loss: 0.9135\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7612 - val_loss: 0.9132\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7612 - val_loss: 0.9129\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7609 - val_loss: 0.9128\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7608 - val_loss: 0.9129\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7607 - val_loss: 0.9127\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7607 - val_loss: 0.9125\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7606 - val_loss: 0.9119\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7605 - val_loss: 0.9118\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7603 - val_loss: 0.9119\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7604 - val_loss: 0.9121\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7603 - val_loss: 0.9118\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7601 - val_loss: 0.9116\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7600 - val_loss: 0.9112\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7599 - val_loss: 0.9118\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7599 - val_loss: 0.9114\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7597 - val_loss: 0.9116\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7595 - val_loss: 0.9111\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7597 - val_loss: 0.9109\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7592 - val_loss: 0.9105\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7592 - val_loss: 0.9107\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7590 - val_loss: 0.9110\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7589 - val_loss: 0.9111\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7589 - val_loss: 0.9109\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7588 - val_loss: 0.9107\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7588 - val_loss: 0.9107\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7590 - val_loss: 0.9106\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7588 - val_loss: 0.9102\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7584 - val_loss: 0.9105\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7585 - val_loss: 0.9104\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7586 - val_loss: 0.9101\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7582 - val_loss: 0.9101\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7583 - val_loss: 0.9103\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7582 - val_loss: 0.9104\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7583 - val_loss: 0.9100\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7582 - val_loss: 0.9101\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7581 - val_loss: 0.9099\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7581 - val_loss: 0.9099\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7579 - val_loss: 0.9096\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7578 - val_loss: 0.9093\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7579 - val_loss: 0.9093\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7578 - val_loss: 0.9094\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7577 - val_loss: 0.9097\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7578 - val_loss: 0.9097\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7577 - val_loss: 0.9105\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7577 - val_loss: 0.9103\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7576 - val_loss: 0.9101\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7577 - val_loss: 0.9108\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7577 - val_loss: 0.9104\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7576 - val_loss: 0.9105\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7576 - val_loss: 0.9101\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7574 - val_loss: 0.9099\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7574 - val_loss: 0.9099\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7574 - val_loss: 0.9095\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7574 - val_loss: 0.9102\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7574 - val_loss: 0.9099\n",
      "Epoch 391/500\n",
      "105/105==============================] - ETA: 0s - loss: 0.995 - 0s 50us/sample - loss: 0.7573 - val_loss: 0.9097\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7573 - val_loss: 0.9091\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7572 - val_loss: 0.9089\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7573 - val_loss: 0.9092\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 38us/sample - loss: 0.7573 - val_loss: 0.9096\n",
      "Epoch 396/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7572 - val_loss: 0.9093\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7573 - val_loss: 0.9090\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7571 - val_loss: 0.9090\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7573 - val_loss: 0.9088\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7569 - val_loss: 0.9085\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7569 - val_loss: 0.9083\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7568 - val_loss: 0.9085\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7569 - val_loss: 0.9089\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7568 - val_loss: 0.9085\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7568 - val_loss: 0.9085\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7568 - val_loss: 0.9084\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7567 - val_loss: 0.9081\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7567 - val_loss: 0.9078\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7567 - val_loss: 0.9075\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7566 - val_loss: 0.9079\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7565 - val_loss: 0.9080\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7565 - val_loss: 0.9084\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7566 - val_loss: 0.9083\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7568 - val_loss: 0.9081\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7566 - val_loss: 0.9078\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7565 - val_loss: 0.9083\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7564 - val_loss: 0.9085\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7566 - val_loss: 0.9087\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7565 - val_loss: 0.9090\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7565 - val_loss: 0.9091\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7565 - val_loss: 0.9088\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7564 - val_loss: 0.9093\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7565 - val_loss: 0.9097\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7566 - val_loss: 0.9096\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7566 - val_loss: 0.9101\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7566 - val_loss: 0.9099\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7566 - val_loss: 0.9096\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7566 - val_loss: 0.9096\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7568 - val_loss: 0.9095\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7567 - val_loss: 0.9093\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7566 - val_loss: 0.9095\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7565 - val_loss: 0.9097\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7567 - val_loss: 0.9095\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7566 - val_loss: 0.9097\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7566 - val_loss: 0.9100\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7569 - val_loss: 0.9096\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7565 - val_loss: 0.9095\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7567 - val_loss: 0.9093\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7564 - val_loss: 0.9091\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7564 - val_loss: 0.9092\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7564 - val_loss: 0.9091\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7564 - val_loss: 0.9087\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7566 - val_loss: 0.9084\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7564 - val_loss: 0.9088\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7563 - val_loss: 0.9085\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7564 - val_loss: 0.9083\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7563 - val_loss: 0.9082\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.9083\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7564 - val_loss: 0.9079\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7562 - val_loss: 0.9079\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7562 - val_loss: 0.9077\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7563 - val_loss: 0.9076\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7561 - val_loss: 0.9074\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.9078\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.9081\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9084\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.9080\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7561 - val_loss: 0.9079\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9081\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9082\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9082\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.9087\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7560 - val_loss: 0.9084\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9085\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9082\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.9080\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.9079\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.9083\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7561 - val_loss: 0.9079\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7559 - val_loss: 0.9079\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7560 - val_loss: 0.9078\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9075\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7560 - val_loss: 0.9073\n",
      "Epoch 475/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7559 - val_loss: 0.9070\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7560 - val_loss: 0.9070\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.9069\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7561 - val_loss: 0.9065\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7559 - val_loss: 0.9063\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7558 - val_loss: 0.9065\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7557 - val_loss: 0.9065\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7557 - val_loss: 0.9063\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7557 - val_loss: 0.9063\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9064\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 91us/sample - loss: 0.7556 - val_loss: 0.9067\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7557 - val_loss: 0.9066\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7557 - val_loss: 0.9067\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7557 - val_loss: 0.9071\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7557 - val_loss: 0.9073\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9073\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7557 - val_loss: 0.9072\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7558 - val_loss: 0.9072\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7557 - val_loss: 0.9071\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7557 - val_loss: 0.9069\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9071\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7557 - val_loss: 0.9072\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7557 - val_loss: 0.9070\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7557 - val_loss: 0.9066\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7560 - val_loss: 0.9064\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7556 - val_loss: 0.9067\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과대적합 해결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 1ms/sample - loss: 3.3701 - val_loss: 2.2784\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 3.3146 - val_loss: 2.2501\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 3.2621 - val_loss: 2.2166\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.2034 - val_loss: 2.1913\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 3.1572 - val_loss: 2.1640\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 3.1070 - val_loss: 2.1381\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.0603 - val_loss: 2.1146\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.0176 - val_loss: 2.0887\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.9702 - val_loss: 2.0636\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 2.9249 - val_loss: 2.0389\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.8800 - val_loss: 2.0150\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.8359 - val_loss: 1.9925\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.7952 - val_loss: 1.9721\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.7580 - val_loss: 1.9512\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.7201 - val_loss: 1.9297\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.6812 - val_loss: 1.9097\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.6439 - val_loss: 1.8877\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 2.6040 - val_loss: 1.8670\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.5659 - val_loss: 1.8461\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.5279 - val_loss: 1.8268\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 2.4926 - val_loss: 1.8044\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.4524 - val_loss: 1.7864\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 2.4195 - val_loss: 1.7688\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.3876 - val_loss: 1.7526\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.3577 - val_loss: 1.7358\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.3270 - val_loss: 1.7191\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.2965 - val_loss: 1.7003\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.2627 - val_loss: 1.6836\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 2.2324 - val_loss: 1.6664\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.2014 - val_loss: 1.6509\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 2.1738 - val_loss: 1.6369\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.1477 - val_loss: 1.6232\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 2.1221 - val_loss: 1.6092\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.0964 - val_loss: 1.5957\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.0722 - val_loss: 1.5821\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 2.0471 - val_loss: 1.5687\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.0226 - val_loss: 1.5551\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.9976 - val_loss: 1.5415\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.9734 - val_loss: 1.5305\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 1.9526 - val_loss: 1.5168\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.9273 - val_loss: 1.5037\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.9032 - val_loss: 1.4907\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.8793 - val_loss: 1.4759\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.8525 - val_loss: 1.4638\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.8302 - val_loss: 1.4508\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.8061 - val_loss: 1.4389\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.7850 - val_loss: 1.4274\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.7643 - val_loss: 1.4145\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.7407 - val_loss: 1.4038\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.7209 - val_loss: 1.3939\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.7029 - val_loss: 1.3840\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.6850 - val_loss: 1.3740\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.6668 - val_loss: 1.3648\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 1.6497 - val_loss: 1.3549\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.6317 - val_loss: 1.3461\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.6156 - val_loss: 1.3377\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.5996 - val_loss: 1.3281\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.5821 - val_loss: 1.3190\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.5661 - val_loss: 1.3107\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.5502 - val_loss: 1.3007\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.5321 - val_loss: 1.2927\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.5175 - val_loss: 1.2857\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.5042 - val_loss: 1.2771\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.4890 - val_loss: 1.2689\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.4745 - val_loss: 1.2620\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.4617 - val_loss: 1.2533\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.4460 - val_loss: 1.2459\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.4321 - val_loss: 1.2385\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.4181 - val_loss: 1.2304\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.4038 - val_loss: 1.2234\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.3914 - val_loss: 1.2176\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.3801 - val_loss: 1.2121\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.3698 - val_loss: 1.2060\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.3584 - val_loss: 1.1990\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.3455 - val_loss: 1.1915\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.3318 - val_loss: 1.1848\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.3191 - val_loss: 1.1788\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.3078 - val_loss: 1.1720\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.2952 - val_loss: 1.1662\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 35us/sample - loss: 1.2847 - val_loss: 1.1611\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2749 - val_loss: 1.1551\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.2642 - val_loss: 1.1500\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.2547 - val_loss: 1.1452\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2455 - val_loss: 1.1402\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.2363 - val_loss: 1.1344\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2258 - val_loss: 1.1296\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2172 - val_loss: 1.1245\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.2078 - val_loss: 1.1203\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.2001 - val_loss: 1.1160\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.1926 - val_loss: 1.1112\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.1841 - val_loss: 1.1063\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.1748 - val_loss: 1.1019\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.1670 - val_loss: 1.0977\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1594 - val_loss: 1.0943\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.1528 - val_loss: 1.0904\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1459 - val_loss: 1.0868\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.1395 - val_loss: 1.0833\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.1331 - val_loss: 1.0798\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.1266 - val_loss: 1.0755\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.1188 - val_loss: 1.0710\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.1110 - val_loss: 1.0672\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1043 - val_loss: 1.0643\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0990 - val_loss: 1.0619\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0936 - val_loss: 1.0583\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0869 - val_loss: 1.0558\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0813 - val_loss: 1.0526\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.0751 - val_loss: 1.0493\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0690 - val_loss: 1.0465\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.0632 - val_loss: 1.0435\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0578 - val_loss: 1.0406\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0526 - val_loss: 1.0381\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0474 - val_loss: 1.0355\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0425 - val_loss: 1.0332\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0378 - val_loss: 1.0298\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.0317 - val_loss: 1.0272\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0265 - val_loss: 1.0242\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.0212 - val_loss: 1.0205\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0146 - val_loss: 1.0180\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0097 - val_loss: 1.0147\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0035 - val_loss: 1.0122\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9985 - val_loss: 1.0099\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 0.9939 - val_loss: 1.0074\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9895 - val_loss: 1.0046\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9848 - val_loss: 1.0020\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.9804 - val_loss: 1.0001\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9766 - val_loss: 0.9989\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9735 - val_loss: 0.9974\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 0.9703 - val_loss: 0.9960\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.9668 - val_loss: 0.9944\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 83us/sample - loss: 0.9639 - val_loss: 0.9924\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.9603 - val_loss: 0.9908\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9572 - val_loss: 0.9899\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9545 - val_loss: 0.9885\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9513 - val_loss: 0.9874\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9485 - val_loss: 0.9855\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9447 - val_loss: 0.9843\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9419 - val_loss: 0.9826\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9387 - val_loss: 0.9808\n",
      "Epoch 139/500\n",
      "105/105==============================] - ETA: 0s - loss: 0.623 - 0s 55us/sample - loss: 0.9352 - val_loss: 0.9793\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 79us/sample - loss: 0.9325 - val_loss: 0.9778\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9296 - val_loss: 0.9769\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.9271 - val_loss: 0.9758\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9244 - val_loss: 0.9738\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9214 - val_loss: 0.9720\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9185 - val_loss: 0.9712\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.9166 - val_loss: 0.9697\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9137 - val_loss: 0.9686\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9110 - val_loss: 0.9669\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9079 - val_loss: 0.9655\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9050 - val_loss: 0.9645\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9024 - val_loss: 0.9633\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9000 - val_loss: 0.9620\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8974 - val_loss: 0.9608\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8950 - val_loss: 0.9597\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8927 - val_loss: 0.9593\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8910 - val_loss: 0.9585\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8888 - val_loss: 0.9572\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8863 - val_loss: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8845 - val_loss: 0.9552\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8823 - val_loss: 0.9540\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8804 - val_loss: 0.9530\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8786 - val_loss: 0.9521\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8766 - val_loss: 0.9511\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8749 - val_loss: 0.9501\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8730 - val_loss: 0.9492\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8714 - val_loss: 0.9481\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8693 - val_loss: 0.9479\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8680 - val_loss: 0.9468\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8659 - val_loss: 0.9464\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8643 - val_loss: 0.9456\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8625 - val_loss: 0.9445\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8606 - val_loss: 0.9436\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8589 - val_loss: 0.9434\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8575 - val_loss: 0.9428\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8562 - val_loss: 0.9421\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.8548 - val_loss: 0.9417\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8535 - val_loss: 0.9408\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8521 - val_loss: 0.9400\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8506 - val_loss: 0.9390\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8494 - val_loss: 0.9387\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8483 - val_loss: 0.9384\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8470 - val_loss: 0.9374\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8455 - val_loss: 0.9369\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.8444 - val_loss: 0.9364\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8432 - val_loss: 0.9361\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8422 - val_loss: 0.9354\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8409 - val_loss: 0.9351\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8401 - val_loss: 0.9345\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8388 - val_loss: 0.9342\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8379 - val_loss: 0.9341\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 68us/sample - loss: 0.8371 - val_loss: 0.9335\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.8360 - val_loss: 0.9331\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8347 - val_loss: 0.9326\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8339 - val_loss: 0.9321\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.8330 - val_loss: 0.9319\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8320 - val_loss: 0.9316\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8311 - val_loss: 0.9312\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8299 - val_loss: 0.9309\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8292 - val_loss: 0.9305\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8282 - val_loss: 0.9305\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8274 - val_loss: 0.9298\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.8265 - val_loss: 0.9294\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8256 - val_loss: 0.9291\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.8252 - val_loss: 0.9292\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8246 - val_loss: 0.9290\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8236 - val_loss: 0.9287\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.8230 - val_loss: 0.9284\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8224 - val_loss: 0.9277\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8214 - val_loss: 0.9277\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 0.8207 - val_loss: 0.9273\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8199 - val_loss: 0.9266\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8187 - val_loss: 0.9264\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.8181 - val_loss: 0.9261\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.8170 - val_loss: 0.9258\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8164 - val_loss: 0.9252\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8158 - val_loss: 0.9254\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8151 - val_loss: 0.9251\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8145 - val_loss: 0.9248\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8136 - val_loss: 0.9249\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 68us/sample - loss: 0.8131 - val_loss: 0.9243\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8125 - val_loss: 0.9242\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8119 - val_loss: 0.9239\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8113 - val_loss: 0.9239\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8104 - val_loss: 0.9237\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8099 - val_loss: 0.9234\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8092 - val_loss: 0.9234\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8086 - val_loss: 0.9231\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8078 - val_loss: 0.9230\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8076 - val_loss: 0.9228\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8070 - val_loss: 0.9229\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8065 - val_loss: 0.9224\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8058 - val_loss: 0.9221\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8051 - val_loss: 0.9219\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8047 - val_loss: 0.9222\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8043 - val_loss: 0.9221\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8037 - val_loss: 0.9222\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8034 - val_loss: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8031 - val_loss: 0.9225\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.8025 - val_loss: 0.9222\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8020 - val_loss: 0.9218\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8014 - val_loss: 0.9215\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.8009 - val_loss: 0.9212\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8003 - val_loss: 0.9211\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.8000 - val_loss: 0.9210\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7999 - val_loss: 0.9209\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7993 - val_loss: 0.9206\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7989 - val_loss: 0.9202\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7983 - val_loss: 0.9200\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7979 - val_loss: 0.9202\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7976 - val_loss: 0.9203\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7971 - val_loss: 0.9201\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7965 - val_loss: 0.9202\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7964 - val_loss: 0.9201\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7959 - val_loss: 0.9200\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7956 - val_loss: 0.9200\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7955 - val_loss: 0.9197\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7951 - val_loss: 0.9196\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.7947 - val_loss: 0.9197\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7944 - val_loss: 0.9194\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7942 - val_loss: 0.9188\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7938 - val_loss: 0.9187\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7937 - val_loss: 0.9190\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7934 - val_loss: 0.9186\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7931 - val_loss: 0.9188\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7930 - val_loss: 0.9188\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7927 - val_loss: 0.9192\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7924 - val_loss: 0.9192\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7923 - val_loss: 0.9192\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7920 - val_loss: 0.9198\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7917 - val_loss: 0.9197\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7913 - val_loss: 0.9202\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 0.7913 - val_loss: 0.9199\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7909 - val_loss: 0.9201\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7908 - val_loss: 0.9204\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7905 - val_loss: 0.9202\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7903 - val_loss: 0.9203\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7902 - val_loss: 0.9201\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7898 - val_loss: 0.9200\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7897 - val_loss: 0.9198\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7894 - val_loss: 0.9202\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7893 - val_loss: 0.9200\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7892 - val_loss: 0.9205\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7888 - val_loss: 0.9207\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7887 - val_loss: 0.9214\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7886 - val_loss: 0.9211\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7886 - val_loss: 0.9210\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7885 - val_loss: 0.9214\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7883 - val_loss: 0.9215\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7880 - val_loss: 0.9213\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7879 - val_loss: 0.9214\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.7877 - val_loss: 0.9211\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7874 - val_loss: 0.9206\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.7872 - val_loss: 0.9206\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.7871 - val_loss: 0.9206\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7868 - val_loss: 0.9203\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7867 - val_loss: 0.9203\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7865 - val_loss: 0.9208\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7863 - val_loss: 0.9205\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7861 - val_loss: 0.9201\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7859 - val_loss: 0.9202\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7859 - val_loss: 0.9201\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7857 - val_loss: 0.9199\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7855 - val_loss: 0.9201\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7854 - val_loss: 0.9203\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7853 - val_loss: 0.9205\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7852 - val_loss: 0.9206\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7849 - val_loss: 0.9204\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7848 - val_loss: 0.9205\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7847 - val_loss: 0.9202\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7846 - val_loss: 0.9204\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7847 - val_loss: 0.9205\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7847 - val_loss: 0.9205\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7849 - val_loss: 0.9205\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7845 - val_loss: 0.9206\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7845 - val_loss: 0.9209\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7845 - val_loss: 0.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7845 - val_loss: 0.9217\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7844 - val_loss: 0.9217\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 95us/sample - loss: 0.7844 - val_loss: 0.9211\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7840 - val_loss: 0.9209\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7839 - val_loss: 0.9210\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 73us/sample - loss: 0.7837 - val_loss: 0.9211\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7838 - val_loss: 0.9215\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7836 - val_loss: 0.9216\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7835 - val_loss: 0.9217\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7836 - val_loss: 0.9223\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 79us/sample - loss: 0.7834 - val_loss: 0.9221\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7832 - val_loss: 0.9222\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7831 - val_loss: 0.9221\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7831 - val_loss: 0.9223\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7831 - val_loss: 0.9226\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7831 - val_loss: 0.9228\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7830 - val_loss: 0.9229\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7830 - val_loss: 0.9230\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7828 - val_loss: 0.9229\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7828 - val_loss: 0.9230\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7828 - val_loss: 0.9233\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7828 - val_loss: 0.9233\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7825 - val_loss: 0.9232\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7826 - val_loss: 0.9230\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7825 - val_loss: 0.9230\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7825 - val_loss: 0.9228\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7825 - val_loss: 0.9225\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7824 - val_loss: 0.9229\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7823 - val_loss: 0.9230\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7822 - val_loss: 0.9232\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7821 - val_loss: 0.9233\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7820 - val_loss: 0.9235\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7823 - val_loss: 0.9237\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7821 - val_loss: 0.9241\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7822 - val_loss: 0.9240\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7821 - val_loss: 0.9244\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7820 - val_loss: 0.9244\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7820 - val_loss: 0.9243\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7820 - val_loss: 0.9241\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7818 - val_loss: 0.9243\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7818 - val_loss: 0.9240\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7820 - val_loss: 0.9246\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7818 - val_loss: 0.9249\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7819 - val_loss: 0.9249\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7818 - val_loss: 0.9247\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7819 - val_loss: 0.9243\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.7819 - val_loss: 0.9242\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7817 - val_loss: 0.9238\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7816 - val_loss: 0.9233\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7816 - val_loss: 0.9233\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7816 - val_loss: 0.9232\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7815 - val_loss: 0.9232\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7815 - val_loss: 0.9233\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7815 - val_loss: 0.9235\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7814 - val_loss: 0.9237\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7813 - val_loss: 0.9235\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7815 - val_loss: 0.9237\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7813 - val_loss: 0.9238\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7813 - val_loss: 0.9238\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7812 - val_loss: 0.9237\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7811 - val_loss: 0.9236\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7810 - val_loss: 0.9237\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7811 - val_loss: 0.9237\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7811 - val_loss: 0.9238\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7810 - val_loss: 0.9237\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7810 - val_loss: 0.9237\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7811 - val_loss: 0.9238\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 82us/sample - loss: 0.7810 - val_loss: 0.9239\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7810 - val_loss: 0.9242\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7810 - val_loss: 0.9241\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7809 - val_loss: 0.9243\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7808 - val_loss: 0.9239\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7809 - val_loss: 0.9240\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7810 - val_loss: 0.9242\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7808 - val_loss: 0.9238\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7809 - val_loss: 0.9239\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7807 - val_loss: 0.9239\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7808 - val_loss: 0.9238\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7808 - val_loss: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7808 - val_loss: 0.9238\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7808 - val_loss: 0.9237\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7810 - val_loss: 0.9238\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7808 - val_loss: 0.9241\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7807 - val_loss: 0.9241\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7809 - val_loss: 0.9237\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7808 - val_loss: 0.9238\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7805 - val_loss: 0.9238\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7805 - val_loss: 0.9238\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7807 - val_loss: 0.9239\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7806 - val_loss: 0.9236\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7805 - val_loss: 0.9239\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7805 - val_loss: 0.9240\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7805 - val_loss: 0.9242\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7805 - val_loss: 0.9239\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7805 - val_loss: 0.9242\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7804 - val_loss: 0.9243\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7804 - val_loss: 0.9242\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7805 - val_loss: 0.9240\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7804 - val_loss: 0.9237\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7804 - val_loss: 0.9244\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7804 - val_loss: 0.9244\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7804 - val_loss: 0.9245\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7804 - val_loss: 0.9247\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7803 - val_loss: 0.9249\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7803 - val_loss: 0.9251\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7801 - val_loss: 0.9253\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7803 - val_loss: 0.9256\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.7801 - val_loss: 0.9258\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7801 - val_loss: 0.9259\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7801 - val_loss: 0.9253\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7803 - val_loss: 0.9255\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7801 - val_loss: 0.9252\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7801 - val_loss: 0.9250\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7801 - val_loss: 0.9253\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7801 - val_loss: 0.9255\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7801 - val_loss: 0.9256\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7800 - val_loss: 0.9255\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7801 - val_loss: 0.9258\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7801 - val_loss: 0.9259\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 110us/sample - loss: 0.7799 - val_loss: 0.9262\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7800 - val_loss: 0.9265\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7799 - val_loss: 0.9266\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7799 - val_loss: 0.9262\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7799 - val_loss: 0.9264\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7799 - val_loss: 0.9264\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7799 - val_loss: 0.9268\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7798 - val_loss: 0.9266\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7798 - val_loss: 0.9263\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7798 - val_loss: 0.9264\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7798 - val_loss: 0.9266\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.7797 - val_loss: 0.9269\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7798 - val_loss: 0.9269\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7797 - val_loss: 0.9267\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7801 - val_loss: 0.9265\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7798 - val_loss: 0.9266\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7797 - val_loss: 0.9264\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.7797 - val_loss: 0.9265\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7797 - val_loss: 0.9265\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7798 - val_loss: 0.9269\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7797 - val_loss: 0.9269\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7797 - val_loss: 0.9270\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 74us/sample - loss: 0.7797 - val_loss: 0.9272\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7798 - val_loss: 0.9279\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7797 - val_loss: 0.9279\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7796 - val_loss: 0.9280\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7796 - val_loss: 0.9280\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7797 - val_loss: 0.9281\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9279\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7797 - val_loss: 0.9278\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7797 - val_loss: 0.9277\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7797 - val_loss: 0.9279\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 130us/sample - loss: 0.7796 - val_loss: 0.9279\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7795 - val_loss: 0.9277\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7795 - val_loss: 0.9278\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7796 - val_loss: 0.9280\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.7795 - val_loss: 0.9280\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7796 - val_loss: 0.9278\n",
      "Epoch 474/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7795 - val_loss: 0.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7796 - val_loss: 0.9275\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7796 - val_loss: 0.9274\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7795 - val_loss: 0.9275\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 79us/sample - loss: 0.7797 - val_loss: 0.9275\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 89us/sample - loss: 0.7795 - val_loss: 0.9274\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7795 - val_loss: 0.9276\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7795 - val_loss: 0.9277\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7795 - val_loss: 0.9279\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7796 - val_loss: 0.9275\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7796 - val_loss: 0.9275\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7797 - val_loss: 0.9276\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7795 - val_loss: 0.9277\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7795 - val_loss: 0.9276\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7795 - val_loss: 0.9276\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7795 - val_loss: 0.9275\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7796 - val_loss: 0.9276\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7795 - val_loss: 0.9278\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7795 - val_loss: 0.9282\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7796 - val_loss: 0.9277\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7797 - val_loss: 0.9283\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7797 - val_loss: 0.9282\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7795 - val_loss: 0.9282\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7795 - val_loss: 0.9285\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7797 - val_loss: 0.9289\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7795 - val_loss: 0.9291\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7795 - val_loss: 0.9289\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 1ms/sample - loss: 2.6755 - val_loss: 1.8713\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.6389 - val_loss: 1.8501\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.6007 - val_loss: 1.8329\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.5686 - val_loss: 1.8158\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.5363 - val_loss: 1.7965\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.5011 - val_loss: 1.7801\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.4703 - val_loss: 1.7601\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.4336 - val_loss: 1.7442\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 2.4040 - val_loss: 1.7270\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 2.3722 - val_loss: 1.7109\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.3420 - val_loss: 1.6937\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 2.3102 - val_loss: 1.6767\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.2789 - val_loss: 1.6623\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.2516 - val_loss: 1.6443\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.2185 - val_loss: 1.6280\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.1887 - val_loss: 1.6134\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.1615 - val_loss: 1.5986\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.1341 - val_loss: 1.5850\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.1082 - val_loss: 1.5697\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.0802 - val_loss: 1.5575\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.0573 - val_loss: 1.5447\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.0331 - val_loss: 1.5301\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.0063 - val_loss: 1.5185\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.9846 - val_loss: 1.5062\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.9614 - val_loss: 1.4935\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 1.9379 - val_loss: 1.4815\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.9158 - val_loss: 1.4703\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.8952 - val_loss: 1.4594\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.8744 - val_loss: 1.4472\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.8517 - val_loss: 1.4355\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.8302 - val_loss: 1.4256\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.8120 - val_loss: 1.4145\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.7915 - val_loss: 1.4048\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.7731 - val_loss: 1.3943\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.7535 - val_loss: 1.3837\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.7340 - val_loss: 1.3747\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.7170 - val_loss: 1.3655\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.6992 - val_loss: 1.3553\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.6804 - val_loss: 1.3452\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.6617 - val_loss: 1.3364\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 1.6451 - val_loss: 1.3270\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 1.6276 - val_loss: 1.3180\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.6107 - val_loss: 1.3083\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.5926 - val_loss: 1.2996\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.5766 - val_loss: 1.2915\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.5611 - val_loss: 1.2829\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.5450 - val_loss: 1.2741\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 1.5286 - val_loss: 1.2646\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.5109 - val_loss: 1.2564\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.4955 - val_loss: 1.2483\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.4806 - val_loss: 1.2416\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.4676 - val_loss: 1.2340\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 74us/sample - loss: 1.4536 - val_loss: 1.2268\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.4404 - val_loss: 1.2190\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.4262 - val_loss: 1.2129\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 1.4145 - val_loss: 1.2059\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.4013 - val_loss: 1.1999\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 1.3899 - val_loss: 1.1940\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.3792 - val_loss: 1.1891\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.3690 - val_loss: 1.1832\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.3582 - val_loss: 1.1778\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.3476 - val_loss: 1.1710\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.3349 - val_loss: 1.1640\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3223 - val_loss: 1.1591\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.3127 - val_loss: 1.1545\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.3038 - val_loss: 1.1498\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 1.2948 - val_loss: 1.1452\n",
      "Epoch 68/500\n",
      "105/105==============================] - ETA: 0s - loss: 0.713 - 0s 42us/sample - loss: 1.2858 - val_loss: 1.1400\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 1.2760 - val_loss: 1.1343\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.2655 - val_loss: 1.1293\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.2559 - val_loss: 1.1247\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 1.2473 - val_loss: 1.1199\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 1.2385 - val_loss: 1.1144\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.2281 - val_loss: 1.1099\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.2198 - val_loss: 1.1053\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.2111 - val_loss: 1.1001\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 1.2012 - val_loss: 1.0956\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 76us/sample - loss: 1.1926 - val_loss: 1.0915\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.1846 - val_loss: 1.0881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.1778 - val_loss: 1.0838\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.1697 - val_loss: 1.0801\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.1622 - val_loss: 1.0757\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 71us/sample - loss: 1.1540 - val_loss: 1.0720\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.1467 - val_loss: 1.0685\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1398 - val_loss: 1.0646\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1322 - val_loss: 1.0606\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.1247 - val_loss: 1.0576\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.1184 - val_loss: 1.0545\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1125 - val_loss: 1.0518\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.1068 - val_loss: 1.0486\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 1.1006 - val_loss: 1.0457\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.0948 - val_loss: 1.0427\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0892 - val_loss: 1.0399\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.0839 - val_loss: 1.0371\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0786 - val_loss: 1.0346\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0732 - val_loss: 1.0317\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0680 - val_loss: 1.0295\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0630 - val_loss: 1.0267\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0574 - val_loss: 1.0241\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0525 - val_loss: 1.0221\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 1.0479 - val_loss: 1.0188\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.0421 - val_loss: 1.0167\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0375 - val_loss: 1.0137\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0318 - val_loss: 1.0115\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0274 - val_loss: 1.0091\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.0228 - val_loss: 1.0065\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0180 - val_loss: 1.0045\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0139 - val_loss: 1.0018\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 1.0086 - val_loss: 0.9995\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 1.0040 - val_loss: 0.9974\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9996 - val_loss: 0.9958\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.9961 - val_loss: 0.9937\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9915 - val_loss: 0.9913\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9870 - val_loss: 0.9898\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 71us/sample - loss: 0.9835 - val_loss: 0.9883\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9796 - val_loss: 0.9866\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9761 - val_loss: 0.9852\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.9729 - val_loss: 0.9835\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9691 - val_loss: 0.9815\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9651 - val_loss: 0.9797\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9615 - val_loss: 0.9782\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9584 - val_loss: 0.9761\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9545 - val_loss: 0.9742\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 73us/sample - loss: 0.9507 - val_loss: 0.9724\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.9474 - val_loss: 0.9711\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.9444 - val_loss: 0.9695\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9414 - val_loss: 0.9684\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.9384 - val_loss: 0.9673\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.9353 - val_loss: 0.9660\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9326 - val_loss: 0.9646\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9299 - val_loss: 0.9633\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9270 - val_loss: 0.9623\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9245 - val_loss: 0.9616\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9221 - val_loss: 0.9607\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.9202 - val_loss: 0.9596\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.9177 - val_loss: 0.9586\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.9153 - val_loss: 0.9575\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.9127 - val_loss: 0.9562\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9105 - val_loss: 0.9550\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9080 - val_loss: 0.9542\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.9058 - val_loss: 0.9531\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9034 - val_loss: 0.9514\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.9001 - val_loss: 0.9504\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8978 - val_loss: 0.9488\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8951 - val_loss: 0.9477\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8932 - val_loss: 0.9469\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8913 - val_loss: 0.9464\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8899 - val_loss: 0.9458\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8876 - val_loss: 0.9446\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8853 - val_loss: 0.9440\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.8832 - val_loss: 0.9431\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8811 - val_loss: 0.9420\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8789 - val_loss: 0.9413\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8774 - val_loss: 0.9405\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8757 - val_loss: 0.9398\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8740 - val_loss: 0.9392\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8727 - val_loss: 0.9387\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8712 - val_loss: 0.9378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8691 - val_loss: 0.9372\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8678 - val_loss: 0.9364\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8656 - val_loss: 0.9358\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8638 - val_loss: 0.9354\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8624 - val_loss: 0.9348\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8610 - val_loss: 0.9343\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8598 - val_loss: 0.9339\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8585 - val_loss: 0.9336\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8574 - val_loss: 0.9332\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8562 - val_loss: 0.9325\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8549 - val_loss: 0.9319\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8532 - val_loss: 0.9314\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8521 - val_loss: 0.9306\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8506 - val_loss: 0.9299\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8491 - val_loss: 0.9293\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8477 - val_loss: 0.9287\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8464 - val_loss: 0.9283\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8454 - val_loss: 0.9278\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8441 - val_loss: 0.9274\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8433 - val_loss: 0.9271\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8423 - val_loss: 0.9267\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8411 - val_loss: 0.9265\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8404 - val_loss: 0.9263\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8393 - val_loss: 0.9259\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8385 - val_loss: 0.9254\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8374 - val_loss: 0.9247\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.8362 - val_loss: 0.9246\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8350 - val_loss: 0.9243\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8339 - val_loss: 0.9237\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8329 - val_loss: 0.9239\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8321 - val_loss: 0.9234\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8314 - val_loss: 0.9226\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8301 - val_loss: 0.9224\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8292 - val_loss: 0.9225\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8284 - val_loss: 0.9221\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8276 - val_loss: 0.9213\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8261 - val_loss: 0.9210\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8255 - val_loss: 0.9205\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8246 - val_loss: 0.9202\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8236 - val_loss: 0.9203\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8228 - val_loss: 0.9200\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.8221 - val_loss: 0.9193\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8211 - val_loss: 0.9190\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8204 - val_loss: 0.9190\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8198 - val_loss: 0.9187\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8192 - val_loss: 0.9182\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8181 - val_loss: 0.9181\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.8173 - val_loss: 0.9180\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8169 - val_loss: 0.9176\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8158 - val_loss: 0.9173\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8152 - val_loss: 0.9169\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8144 - val_loss: 0.9170\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8138 - val_loss: 0.9169\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8135 - val_loss: 0.9169\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.8129 - val_loss: 0.9169\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8124 - val_loss: 0.9164\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8115 - val_loss: 0.9162\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8109 - val_loss: 0.9163\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8106 - val_loss: 0.9162\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8100 - val_loss: 0.9161\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8095 - val_loss: 0.9158\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8087 - val_loss: 0.9156\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8083 - val_loss: 0.9153\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8079 - val_loss: 0.9151\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8073 - val_loss: 0.9149\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8067 - val_loss: 0.9145\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8061 - val_loss: 0.9143\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8054 - val_loss: 0.9145\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8052 - val_loss: 0.9144\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8047 - val_loss: 0.9146\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8043 - val_loss: 0.9145\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8041 - val_loss: 0.9145\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_list = [EarlyStopping(patience=5)]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "model.load_weights('simple_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50==============================] - 0s 1ms/sample - loss: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9703411746025086"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50==============================] - 0s 1ms/sample - loss: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9703411746025086"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('simple_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/500\n",
      "120/120==============================] - 0s 1ms/sample - loss: 3.7105 - val_loss: 2.0793\n",
      "Epoch 2/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 3.6552 - val_loss: 2.0487\n",
      "Epoch 3/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 3.5991 - val_loss: 2.0185\n",
      "Epoch 4/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 3.5449 - val_loss: 1.9882\n",
      "Epoch 5/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 3.4897 - val_loss: 1.9595\n",
      "Epoch 6/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 3.4379 - val_loss: 1.9315\n",
      "Epoch 7/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 3.3867 - val_loss: 1.9041\n",
      "Epoch 8/500\n",
      "120/120==============================] - 0s 78us/sample - loss: 3.3372 - val_loss: 1.8779\n",
      "Epoch 9/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 3.2887 - val_loss: 1.8516\n",
      "Epoch 10/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 3.2401 - val_loss: 1.8251\n",
      "Epoch 11/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 3.1918 - val_loss: 1.8000\n",
      "Epoch 12/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 3.1452 - val_loss: 1.7753\n",
      "Epoch 13/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 3.0997 - val_loss: 1.7512\n",
      "Epoch 14/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 3.0554 - val_loss: 1.7280\n",
      "Epoch 15/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 3.0121 - val_loss: 1.7047\n",
      "Epoch 16/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 2.9687 - val_loss: 1.6818\n",
      "Epoch 17/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 2.9260 - val_loss: 1.6599\n",
      "Epoch 18/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.8851 - val_loss: 1.6384\n",
      "Epoch 19/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 2.8451 - val_loss: 1.6177\n",
      "Epoch 20/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 2.8062 - val_loss: 1.5973\n",
      "Epoch 21/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.7673 - val_loss: 1.5770\n",
      "Epoch 22/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 2.7290 - val_loss: 1.5573\n",
      "Epoch 23/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 2.6920 - val_loss: 1.5383\n",
      "Epoch 24/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 2.6558 - val_loss: 1.5192\n",
      "Epoch 25/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 2.6195 - val_loss: 1.5005\n",
      "Epoch 26/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 2.5836 - val_loss: 1.4826\n",
      "Epoch 27/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.5493 - val_loss: 1.4651\n",
      "Epoch 28/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 2.5155 - val_loss: 1.4480\n",
      "Epoch 29/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 2.4827 - val_loss: 1.4311\n",
      "Epoch 30/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 2.4505 - val_loss: 1.4148\n",
      "Epoch 31/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 2.4185 - val_loss: 1.3988\n",
      "Epoch 32/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 2.3872 - val_loss: 1.3828\n",
      "Epoch 33/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 2.3560 - val_loss: 1.3673\n",
      "Epoch 34/500\n",
      "120/120==============================] - 0s 84us/sample - loss: 2.3258 - val_loss: 1.3520\n",
      "Epoch 35/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 2.2957 - val_loss: 1.3373\n",
      "Epoch 36/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 2.2668 - val_loss: 1.3230\n",
      "Epoch 37/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.2388 - val_loss: 1.3091\n",
      "Epoch 38/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 2.2109 - val_loss: 1.2952\n",
      "Epoch 39/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 2.1835 - val_loss: 1.2820\n",
      "Epoch 40/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.1572 - val_loss: 1.2689\n",
      "Epoch 41/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 2.1309 - val_loss: 1.2562\n",
      "Epoch 42/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.1056 - val_loss: 1.2441\n",
      "Epoch 43/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 2.0809 - val_loss: 1.2319\n",
      "Epoch 44/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 2.0563 - val_loss: 1.2200\n",
      "Epoch 45/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 2.0320 - val_loss: 1.2081\n",
      "Epoch 46/500\n",
      "120/120==============================] - 0s 76us/sample - loss: 2.0079 - val_loss: 1.1969\n",
      "Epoch 47/500\n",
      "120/120==============================] - 0s 80us/sample - loss: 1.9850 - val_loss: 1.1860\n",
      "Epoch 48/500\n",
      "120/120==============================] - 0s 78us/sample - loss: 1.9627 - val_loss: 1.1751\n",
      "Epoch 49/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.9403 - val_loss: 1.1647\n",
      "Epoch 50/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.9187 - val_loss: 1.1544\n",
      "Epoch 51/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.8975 - val_loss: 1.1441\n",
      "Epoch 52/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.8757 - val_loss: 1.1342\n",
      "Epoch 53/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.8553 - val_loss: 1.1247\n",
      "Epoch 54/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.8351 - val_loss: 1.1150\n",
      "Epoch 55/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.8147 - val_loss: 1.1057\n",
      "Epoch 56/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.7950 - val_loss: 1.0968\n",
      "Epoch 57/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 1.7763 - val_loss: 1.0882\n",
      "Epoch 58/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.7579 - val_loss: 1.0797\n",
      "Epoch 59/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.7396 - val_loss: 1.0714\n",
      "Epoch 60/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 1.7215 - val_loss: 1.0633\n",
      "Epoch 61/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.7040 - val_loss: 1.0553\n",
      "Epoch 62/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.6867 - val_loss: 1.0476\n",
      "Epoch 63/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.6698 - val_loss: 1.0399\n",
      "Epoch 64/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.6530 - val_loss: 1.0325\n",
      "Epoch 65/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.6366 - val_loss: 1.0252\n",
      "Epoch 66/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.6205 - val_loss: 1.0179\n",
      "Epoch 67/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.6044 - val_loss: 1.0109\n",
      "Epoch 68/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.5889 - val_loss: 1.0041\n",
      "Epoch 69/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 1.5735 - val_loss: 0.9974\n",
      "Epoch 70/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.5585 - val_loss: 0.9911\n",
      "Epoch 71/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.5441 - val_loss: 0.9849\n",
      "Epoch 72/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.5298 - val_loss: 0.9788\n",
      "Epoch 73/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.5161 - val_loss: 0.9729\n",
      "Epoch 74/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.5023 - val_loss: 0.9670\n",
      "Epoch 75/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.4889 - val_loss: 0.9615\n",
      "Epoch 76/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.4759 - val_loss: 0.9560\n",
      "Epoch 77/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.4630 - val_loss: 0.9507\n",
      "Epoch 78/500\n",
      "120/120==============================] - 0s 74us/sample - loss: 1.4506 - val_loss: 0.9454\n",
      "Epoch 79/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.4381 - val_loss: 0.9403\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120==============================] - 0s 72us/sample - loss: 1.4261 - val_loss: 0.9352\n",
      "Epoch 81/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 1.4137 - val_loss: 0.9303\n",
      "Epoch 82/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.4019 - val_loss: 0.9255\n",
      "Epoch 83/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.3903 - val_loss: 0.9207\n",
      "Epoch 84/500\n",
      "120/120==============================] - 0s 75us/sample - loss: 1.3788 - val_loss: 0.9160\n",
      "Epoch 85/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.3671 - val_loss: 0.9114\n",
      "Epoch 86/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.3556 - val_loss: 0.9069\n",
      "Epoch 87/500\n",
      "120/120==============================] - 0s 71us/sample - loss: 1.3446 - val_loss: 0.9026\n",
      "Epoch 88/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.3339 - val_loss: 0.8985\n",
      "Epoch 89/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.3236 - val_loss: 0.8946\n",
      "Epoch 90/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.3136 - val_loss: 0.8908\n",
      "Epoch 91/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 1.3042 - val_loss: 0.8870\n",
      "Epoch 92/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.2941 - val_loss: 0.8834\n",
      "Epoch 93/500\n",
      "120/120==============================] - 0s 76us/sample - loss: 1.2850 - val_loss: 0.8799\n",
      "Epoch 94/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.2759 - val_loss: 0.8765\n",
      "Epoch 95/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.2672 - val_loss: 0.8732\n",
      "Epoch 96/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 1.2583 - val_loss: 0.8700\n",
      "Epoch 97/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 1.2496 - val_loss: 0.8666\n",
      "Epoch 98/500\n",
      "120/120==============================] - 0s 71us/sample - loss: 1.2409 - val_loss: 0.8634\n",
      "Epoch 99/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.2321 - val_loss: 0.8604\n",
      "Epoch 100/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.2237 - val_loss: 0.8573\n",
      "Epoch 101/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 1.2152 - val_loss: 0.8544\n",
      "Epoch 102/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.2073 - val_loss: 0.8515\n",
      "Epoch 103/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 1.1992 - val_loss: 0.8488\n",
      "Epoch 104/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 1.1916 - val_loss: 0.8462\n",
      "Epoch 105/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.1841 - val_loss: 0.8435\n",
      "Epoch 106/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.1766 - val_loss: 0.8410\n",
      "Epoch 107/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.1693 - val_loss: 0.8385\n",
      "Epoch 108/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.1621 - val_loss: 0.8361\n",
      "Epoch 109/500\n",
      "120/120==============================] - 0s 74us/sample - loss: 1.1549 - val_loss: 0.8337\n",
      "Epoch 110/500\n",
      "120/120==============================] - 0s 74us/sample - loss: 1.1482 - val_loss: 0.8315\n",
      "Epoch 111/500\n",
      "120/120==============================] - 0s 84us/sample - loss: 1.1414 - val_loss: 0.8294\n",
      "Epoch 112/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 1.1348 - val_loss: 0.8273\n",
      "Epoch 113/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.1284 - val_loss: 0.8252\n",
      "Epoch 114/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.1218 - val_loss: 0.8231\n",
      "Epoch 115/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.1154 - val_loss: 0.8212\n",
      "Epoch 116/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.1094 - val_loss: 0.8192\n",
      "Epoch 117/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.1031 - val_loss: 0.8174\n",
      "Epoch 118/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 1.0973 - val_loss: 0.8157\n",
      "Epoch 119/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.0916 - val_loss: 0.8138\n",
      "Epoch 120/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.0854 - val_loss: 0.8121\n",
      "Epoch 121/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.0798 - val_loss: 0.8104\n",
      "Epoch 122/500\n",
      "120/120==============================] - 0s 74us/sample - loss: 1.0742 - val_loss: 0.8089\n",
      "Epoch 123/500\n",
      "120/120==============================] - 0s 75us/sample - loss: 1.0689 - val_loss: 0.8074\n",
      "Epoch 124/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.0639 - val_loss: 0.8059\n",
      "Epoch 125/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 1.0586 - val_loss: 0.8045\n",
      "Epoch 126/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0536 - val_loss: 0.8031\n",
      "Epoch 127/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 1.0485 - val_loss: 0.8017\n",
      "Epoch 128/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 1.0434 - val_loss: 0.8005\n",
      "Epoch 129/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 1.0387 - val_loss: 0.7992\n",
      "Epoch 130/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.0341 - val_loss: 0.7981\n",
      "Epoch 131/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 1.0296 - val_loss: 0.7969\n",
      "Epoch 132/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0250 - val_loss: 0.7958\n",
      "Epoch 133/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 1.0207 - val_loss: 0.7947\n",
      "Epoch 134/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0161 - val_loss: 0.7936\n",
      "Epoch 135/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.0119 - val_loss: 0.7926\n",
      "Epoch 136/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.0078 - val_loss: 0.7916\n",
      "Epoch 137/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0039 - val_loss: 0.7907\n",
      "Epoch 138/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 0.9997 - val_loss: 0.7898\n",
      "Epoch 139/500\n",
      "120/120==============================] - 0s 79us/sample - loss: 0.9957 - val_loss: 0.7889\n",
      "Epoch 140/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 0.9919 - val_loss: 0.7881\n",
      "Epoch 141/500\n",
      "120/120==============================] - 0s 78us/sample - loss: 0.9881 - val_loss: 0.7872\n",
      "Epoch 142/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.9843 - val_loss: 0.7864\n",
      "Epoch 143/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 0.9806 - val_loss: 0.7856\n",
      "Epoch 144/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 0.9769 - val_loss: 0.7850\n",
      "Epoch 145/500\n",
      "120/120==============================] - 0s 78us/sample - loss: 0.9735 - val_loss: 0.7842\n",
      "Epoch 146/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.9699 - val_loss: 0.7836\n",
      "Epoch 147/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.9662 - val_loss: 0.7829\n",
      "Epoch 148/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.9628 - val_loss: 0.7823\n",
      "Epoch 149/500\n",
      "120/120==============================] - 0s 71us/sample - loss: 0.9594 - val_loss: 0.7817\n",
      "Epoch 150/500\n",
      "120/120==============================] - 0s 82us/sample - loss: 0.9563 - val_loss: 0.7812\n",
      "Epoch 151/500\n",
      "120/120==============================] - 0s 71us/sample - loss: 0.9534 - val_loss: 0.7806\n",
      "Epoch 152/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.9502 - val_loss: 0.7801\n",
      "Epoch 153/500\n",
      "120/120==============================] - 0s 84us/sample - loss: 0.9470 - val_loss: 0.7796\n",
      "Epoch 154/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 0.9441 - val_loss: 0.7792\n",
      "Epoch 155/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.9410 - val_loss: 0.7787\n",
      "Epoch 156/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 0.9382 - val_loss: 0.7783\n",
      "Epoch 157/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.9352 - val_loss: 0.7779\n",
      "Epoch 158/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.9324 - val_loss: 0.7776\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120==============================] - 0s 63us/sample - loss: 0.9299 - val_loss: 0.7772\n",
      "Epoch 160/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 0.9271 - val_loss: 0.7769\n",
      "Epoch 161/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 0.9247 - val_loss: 0.7766\n",
      "Epoch 162/500\n",
      "120/120==============================] - 0s 71us/sample - loss: 0.9222 - val_loss: 0.7763\n",
      "Epoch 163/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 0.9197 - val_loss: 0.7760\n",
      "Epoch 164/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 0.9173 - val_loss: 0.7758\n",
      "Epoch 165/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.9150 - val_loss: 0.7755\n",
      "Epoch 166/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.9126 - val_loss: 0.7753\n",
      "Epoch 167/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.9102 - val_loss: 0.7751\n",
      "Epoch 168/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 0.9081 - val_loss: 0.7749\n",
      "Epoch 169/500\n",
      "120/120==============================] - 0s 76us/sample - loss: 0.9054 - val_loss: 0.7748\n",
      "Epoch 170/500\n",
      "120/120==============================] - 0s 73us/sample - loss: 0.9033 - val_loss: 0.7746\n",
      "Epoch 171/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.9012 - val_loss: 0.7745\n",
      "Epoch 172/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.8993 - val_loss: 0.7744\n",
      "Epoch 173/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.8972 - val_loss: 0.7742\n",
      "Epoch 174/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 0.8952 - val_loss: 0.7741\n",
      "Epoch 175/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.8933 - val_loss: 0.7741\n",
      "Epoch 176/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 0.8914 - val_loss: 0.7740\n",
      "Epoch 177/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 0.8894 - val_loss: 0.7739\n",
      "Epoch 178/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 0.8876 - val_loss: 0.7739\n",
      "Epoch 179/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.8858 - val_loss: 0.7739\n",
      "Epoch 180/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.8839 - val_loss: 0.7738\n",
      "Epoch 181/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.8822 - val_loss: 0.7738\n",
      "Epoch 182/500\n",
      "120/120==============================] - 0s 77us/sample - loss: 0.8804 - val_loss: 0.7738\n",
      "Epoch 183/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.8789 - val_loss: 0.7738\n",
      "Epoch 184/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8772 - val_loss: 0.7738\n",
      "Epoch 185/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8755 - val_loss: 0.7739\n",
      "Epoch 186/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8739 - val_loss: 0.7739\n",
      "Epoch 187/500\n",
      "120/120==============================] - 0s 51us/sample - loss: 0.8722 - val_loss: 0.7740\n",
      "Epoch 188/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8708 - val_loss: 0.7740\n",
      "Epoch 189/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.8692 - val_loss: 0.7741\n",
      "Epoch 190/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8677 - val_loss: 0.7742\n",
      "Epoch 191/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.8663 - val_loss: 0.7742\n",
      "Epoch 192/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8650 - val_loss: 0.7743\n",
      "Epoch 193/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 0.8634 - val_loss: 0.7744\n",
      "Epoch 194/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8621 - val_loss: 0.7745\n",
      "Epoch 195/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8608 - val_loss: 0.7746\n",
      "Epoch 196/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8595 - val_loss: 0.7747\n",
      "Epoch 197/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8584 - val_loss: 0.7749\n",
      "Epoch 198/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.8572 - val_loss: 0.7750\n",
      "Epoch 199/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8556 - val_loss: 0.7752\n",
      "Epoch 200/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.8545 - val_loss: 0.7753\n",
      "Epoch 201/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8532 - val_loss: 0.7755\n",
      "Epoch 202/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8518 - val_loss: 0.7756\n",
      "Epoch 203/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8509 - val_loss: 0.7758\n",
      "Epoch 204/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8495 - val_loss: 0.7760\n",
      "Epoch 205/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.8484 - val_loss: 0.7762\n",
      "Epoch 206/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8472 - val_loss: 0.7764\n",
      "Epoch 207/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8462 - val_loss: 0.7765\n",
      "Epoch 208/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8453 - val_loss: 0.7767\n",
      "Epoch 209/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8441 - val_loss: 0.7769\n",
      "Epoch 210/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8434 - val_loss: 0.7771\n",
      "Epoch 211/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8421 - val_loss: 0.7773\n",
      "Epoch 212/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8410 - val_loss: 0.7775\n",
      "Epoch 213/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.8401 - val_loss: 0.7777\n",
      "Epoch 214/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8392 - val_loss: 0.7780\n",
      "Epoch 215/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8382 - val_loss: 0.7782\n",
      "Epoch 216/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.8375 - val_loss: 0.7784\n",
      "Epoch 217/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8366 - val_loss: 0.7786\n",
      "Epoch 218/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8355 - val_loss: 0.7789\n",
      "Epoch 219/500\n",
      "120/120==============================] - 0s 51us/sample - loss: 0.8347 - val_loss: 0.7791\n",
      "Epoch 220/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.8337 - val_loss: 0.7794\n",
      "Epoch 221/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8329 - val_loss: 0.7796\n",
      "Epoch 222/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8321 - val_loss: 0.7798\n",
      "Epoch 223/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.8314 - val_loss: 0.7801\n",
      "Epoch 224/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8308 - val_loss: 0.7803\n",
      "Epoch 225/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8298 - val_loss: 0.7806\n",
      "Epoch 226/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8291 - val_loss: 0.7808\n",
      "Epoch 227/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8283 - val_loss: 0.7811\n",
      "Epoch 228/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8276 - val_loss: 0.7813\n",
      "Epoch 229/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8269 - val_loss: 0.7816\n",
      "Epoch 230/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8262 - val_loss: 0.7818\n",
      "Epoch 231/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8255 - val_loss: 0.7821\n",
      "Epoch 232/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8249 - val_loss: 0.7823\n",
      "Epoch 233/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8242 - val_loss: 0.7826\n",
      "Epoch 234/500\n",
      "120/120==============================] - 0s 51us/sample - loss: 0.8236 - val_loss: 0.7828\n",
      "Epoch 235/500\n",
      "120/120==============================] - 0s 49us/sample - loss: 0.8231 - val_loss: 0.7831\n",
      "Epoch 236/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8223 - val_loss: 0.7834\n",
      "Epoch 237/500\n",
      "120/120==============================] - ETA: 0s - loss: 1.246 - 0s 35us/sample - loss: 0.8218 - val_loss: 0.7837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8211 - val_loss: 0.7840\n",
      "Epoch 239/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.8204 - val_loss: 0.7842\n",
      "Epoch 240/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8199 - val_loss: 0.7845\n",
      "Epoch 241/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.8195 - val_loss: 0.7847\n",
      "Epoch 242/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8188 - val_loss: 0.7850\n",
      "Epoch 243/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8183 - val_loss: 0.7853\n",
      "Epoch 244/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8177 - val_loss: 0.7856\n",
      "Epoch 245/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8172 - val_loss: 0.7859\n",
      "Epoch 246/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8167 - val_loss: 0.7861\n",
      "Epoch 247/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.8163 - val_loss: 0.7864\n",
      "Epoch 248/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.8156 - val_loss: 0.7866\n",
      "Epoch 249/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8152 - val_loss: 0.7869\n",
      "Epoch 250/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8147 - val_loss: 0.7872\n",
      "Epoch 251/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8143 - val_loss: 0.7876\n",
      "Epoch 252/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8136 - val_loss: 0.7878\n",
      "Epoch 253/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8132 - val_loss: 0.7881\n",
      "Epoch 254/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.8128 - val_loss: 0.7883\n",
      "Epoch 255/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8123 - val_loss: 0.7886\n",
      "Epoch 256/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.8119 - val_loss: 0.7889\n",
      "Epoch 257/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8115 - val_loss: 0.7892\n",
      "Epoch 258/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8110 - val_loss: 0.7895\n",
      "Epoch 259/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8107 - val_loss: 0.7897\n",
      "Epoch 260/500\n",
      "120/120==============================] - 0s 51us/sample - loss: 0.8103 - val_loss: 0.7900\n",
      "Epoch 261/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8100 - val_loss: 0.7902\n",
      "Epoch 262/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8096 - val_loss: 0.7906\n",
      "Epoch 263/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.8092 - val_loss: 0.7909\n",
      "Epoch 264/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.8087 - val_loss: 0.7912\n",
      "Epoch 265/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8083 - val_loss: 0.7914\n",
      "Epoch 266/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8080 - val_loss: 0.7917\n",
      "Epoch 267/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8076 - val_loss: 0.7920\n",
      "Epoch 268/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8074 - val_loss: 0.7923\n",
      "Epoch 269/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8069 - val_loss: 0.7926\n",
      "Epoch 270/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8066 - val_loss: 0.7929\n",
      "Epoch 271/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 0.8062 - val_loss: 0.7932\n",
      "Epoch 272/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8058 - val_loss: 0.7935\n",
      "Epoch 273/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8055 - val_loss: 0.7937\n",
      "Epoch 274/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.8053 - val_loss: 0.7940\n",
      "Epoch 275/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8050 - val_loss: 0.7943\n",
      "Epoch 276/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8046 - val_loss: 0.7945\n",
      "Epoch 277/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.8044 - val_loss: 0.7949\n",
      "Epoch 278/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8039 - val_loss: 0.7952\n",
      "Epoch 279/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8036 - val_loss: 0.7954\n",
      "Epoch 280/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8033 - val_loss: 0.7957\n",
      "Epoch 281/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.8032 - val_loss: 0.7960\n",
      "Epoch 282/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.8028 - val_loss: 0.7963\n",
      "Epoch 283/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8025 - val_loss: 0.7966\n",
      "Epoch 284/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8023 - val_loss: 0.7968\n",
      "Epoch 285/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8020 - val_loss: 0.7970\n",
      "Epoch 286/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8019 - val_loss: 0.7973\n",
      "Epoch 287/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8016 - val_loss: 0.7976\n",
      "Epoch 288/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8014 - val_loss: 0.7978\n",
      "Epoch 289/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.8012 - val_loss: 0.7980\n",
      "Epoch 290/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8009 - val_loss: 0.7983\n",
      "Epoch 291/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8006 - val_loss: 0.7986\n",
      "Epoch 292/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.8005 - val_loss: 0.7989\n",
      "Epoch 293/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8002 - val_loss: 0.7992\n",
      "Epoch 294/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8002 - val_loss: 0.7995\n",
      "Epoch 295/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7997 - val_loss: 0.7997\n",
      "Epoch 296/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7994 - val_loss: 0.8000\n",
      "Epoch 297/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7992 - val_loss: 0.8003\n",
      "Epoch 298/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7991 - val_loss: 0.8005\n",
      "Epoch 299/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7988 - val_loss: 0.8007\n",
      "Epoch 300/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7987 - val_loss: 0.8009\n",
      "Epoch 301/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7985 - val_loss: 0.8012\n",
      "Epoch 302/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.7983 - val_loss: 0.8015\n",
      "Epoch 303/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7981 - val_loss: 0.8017\n",
      "Epoch 304/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7980 - val_loss: 0.8020\n",
      "Epoch 305/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.7978 - val_loss: 0.8022\n",
      "Epoch 306/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7975 - val_loss: 0.8025\n",
      "Epoch 307/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7973 - val_loss: 0.8027\n",
      "Epoch 308/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7972 - val_loss: 0.8030\n",
      "Epoch 309/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7971 - val_loss: 0.8032\n",
      "Epoch 310/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7970 - val_loss: 0.8034\n",
      "Epoch 311/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7970 - val_loss: 0.8036\n",
      "Epoch 312/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7966 - val_loss: 0.8039\n",
      "Epoch 313/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7964 - val_loss: 0.8041\n",
      "Epoch 314/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.7963 - val_loss: 0.8043\n",
      "Epoch 315/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7963 - val_loss: 0.8046\n",
      "Epoch 316/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7961 - val_loss: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7958 - val_loss: 0.8051\n",
      "Epoch 318/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7958 - val_loss: 0.8053\n",
      "Epoch 319/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7957 - val_loss: 0.8056\n",
      "Epoch 320/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7954 - val_loss: 0.8058\n",
      "Epoch 321/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7952 - val_loss: 0.8060\n",
      "Epoch 322/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7951 - val_loss: 0.8062\n",
      "Epoch 323/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7950 - val_loss: 0.8064\n",
      "Epoch 324/500\n",
      "120/120==============================] - 0s 49us/sample - loss: 0.7949 - val_loss: 0.8066\n",
      "Epoch 325/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7948 - val_loss: 0.8069\n",
      "Epoch 326/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7946 - val_loss: 0.8071\n",
      "Epoch 327/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7947 - val_loss: 0.8074\n",
      "Epoch 328/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7943 - val_loss: 0.8076\n",
      "Epoch 329/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7943 - val_loss: 0.8079\n",
      "Epoch 330/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.7941 - val_loss: 0.8081\n",
      "Epoch 331/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7941 - val_loss: 0.8083\n",
      "Epoch 332/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7939 - val_loss: 0.8085\n",
      "Epoch 333/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7938 - val_loss: 0.8088\n",
      "Epoch 334/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7937 - val_loss: 0.8090\n",
      "Epoch 335/500\n",
      "120/120==============================] - 0s 48us/sample - loss: 0.7936 - val_loss: 0.8092\n",
      "Epoch 336/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7934 - val_loss: 0.8094\n",
      "Epoch 337/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7933 - val_loss: 0.8097\n",
      "Epoch 338/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7934 - val_loss: 0.8098\n",
      "Epoch 339/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7932 - val_loss: 0.8100\n",
      "Epoch 340/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7930 - val_loss: 0.8103\n",
      "Epoch 341/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7930 - val_loss: 0.8105\n",
      "Epoch 342/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7928 - val_loss: 0.8107\n",
      "Epoch 343/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7928 - val_loss: 0.8109\n",
      "Epoch 344/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7927 - val_loss: 0.8111\n",
      "Epoch 345/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7926 - val_loss: 0.8113\n",
      "Epoch 346/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7926 - val_loss: 0.8114\n",
      "Epoch 347/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7924 - val_loss: 0.8117\n",
      "Epoch 348/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7925 - val_loss: 0.8118\n",
      "Epoch 349/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7922 - val_loss: 0.8120\n",
      "Epoch 350/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7923 - val_loss: 0.8122\n",
      "Epoch 351/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7922 - val_loss: 0.8124\n",
      "Epoch 352/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7920 - val_loss: 0.8125\n",
      "Epoch 353/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7920 - val_loss: 0.8127\n",
      "Epoch 354/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7920 - val_loss: 0.8128\n",
      "Epoch 355/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7920 - val_loss: 0.8130\n",
      "Epoch 356/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7920 - val_loss: 0.8132\n",
      "Epoch 357/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7917 - val_loss: 0.8134\n",
      "Epoch 358/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7916 - val_loss: 0.8136\n",
      "Epoch 359/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7916 - val_loss: 0.8137\n",
      "Epoch 360/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7917 - val_loss: 0.8139\n",
      "Epoch 361/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7916 - val_loss: 0.8141\n",
      "Epoch 362/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7914 - val_loss: 0.8142\n",
      "Epoch 363/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7914 - val_loss: 0.8144\n",
      "Epoch 364/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7913 - val_loss: 0.8145\n",
      "Epoch 365/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7912 - val_loss: 0.8147\n",
      "Epoch 366/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7912 - val_loss: 0.8148\n",
      "Epoch 367/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7911 - val_loss: 0.8150\n",
      "Epoch 368/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.7911 - val_loss: 0.8152\n",
      "Epoch 369/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7910 - val_loss: 0.8153\n",
      "Epoch 370/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7910 - val_loss: 0.8155\n",
      "Epoch 371/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.7910 - val_loss: 0.8156\n",
      "Epoch 372/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7909 - val_loss: 0.8157\n",
      "Epoch 373/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7908 - val_loss: 0.8159\n",
      "Epoch 374/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7909 - val_loss: 0.8161\n",
      "Epoch 375/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7907 - val_loss: 0.8163\n",
      "Epoch 376/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7908 - val_loss: 0.8165\n",
      "Epoch 377/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7906 - val_loss: 0.8166\n",
      "Epoch 378/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7905 - val_loss: 0.8168\n",
      "Epoch 379/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7905 - val_loss: 0.8170\n",
      "Epoch 380/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7905 - val_loss: 0.8172\n",
      "Epoch 381/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7903 - val_loss: 0.8173\n",
      "Epoch 382/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7904 - val_loss: 0.8175\n",
      "Epoch 383/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7903 - val_loss: 0.8176\n",
      "Epoch 384/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7902 - val_loss: 0.8178\n",
      "Epoch 385/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7903 - val_loss: 0.8179\n",
      "Epoch 386/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7903 - val_loss: 0.8181\n",
      "Epoch 387/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7901 - val_loss: 0.8183\n",
      "Epoch 388/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7901 - val_loss: 0.8184\n",
      "Epoch 389/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7901 - val_loss: 0.8185\n",
      "Epoch 390/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.7900 - val_loss: 0.8187\n",
      "Epoch 391/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 0.7902 - val_loss: 0.8189\n",
      "Epoch 392/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 0.7900 - val_loss: 0.8189\n",
      "Epoch 393/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7899 - val_loss: 0.8190\n",
      "Epoch 394/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7899 - val_loss: 0.8191\n",
      "Epoch 395/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7899 - val_loss: 0.8193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7898 - val_loss: 0.8195\n",
      "Epoch 397/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7897 - val_loss: 0.8196\n",
      "Epoch 398/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7897 - val_loss: 0.8198\n",
      "Epoch 399/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7896 - val_loss: 0.8199\n",
      "Epoch 400/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7897 - val_loss: 0.8201\n",
      "Epoch 401/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7896 - val_loss: 0.8202\n",
      "Epoch 402/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7896 - val_loss: 0.8203\n",
      "Epoch 403/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7896 - val_loss: 0.8204\n",
      "Epoch 404/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7896 - val_loss: 0.8205\n",
      "Epoch 405/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.7895 - val_loss: 0.8207\n",
      "Epoch 406/500\n",
      "120/120==============================] - 0s 50us/sample - loss: 0.7896 - val_loss: 0.8209\n",
      "Epoch 407/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7894 - val_loss: 0.8210\n",
      "Epoch 408/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7893 - val_loss: 0.8211\n",
      "Epoch 409/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7894 - val_loss: 0.8213\n",
      "Epoch 410/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7894 - val_loss: 0.8214\n",
      "Epoch 411/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7894 - val_loss: 0.8215\n",
      "Epoch 412/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7894 - val_loss: 0.8217\n",
      "Epoch 413/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7893 - val_loss: 0.8218\n",
      "Epoch 414/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7892 - val_loss: 0.8218\n",
      "Epoch 415/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7892 - val_loss: 0.8220\n",
      "Epoch 416/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.7892 - val_loss: 0.8221\n",
      "Epoch 417/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.7892 - val_loss: 0.8222\n",
      "Epoch 418/500\n",
      "120/120==============================] - 0s 48us/sample - loss: 0.7892 - val_loss: 0.8224\n",
      "Epoch 419/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7891 - val_loss: 0.8224\n",
      "Epoch 420/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7892 - val_loss: 0.8226\n",
      "Epoch 421/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.7891 - val_loss: 0.8227\n",
      "Epoch 422/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7892 - val_loss: 0.8227\n",
      "Epoch 423/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7891 - val_loss: 0.8229\n",
      "Epoch 424/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7890 - val_loss: 0.8230\n",
      "Epoch 425/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7890 - val_loss: 0.8231\n",
      "Epoch 426/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7890 - val_loss: 0.8232\n",
      "Epoch 427/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7889 - val_loss: 0.8234\n",
      "Epoch 428/500\n",
      "120/120==============================] - 0s 48us/sample - loss: 0.7889 - val_loss: 0.8234\n",
      "Epoch 429/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.7889 - val_loss: 0.8236\n",
      "Epoch 430/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7889 - val_loss: 0.8237\n",
      "Epoch 431/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7890 - val_loss: 0.8238\n",
      "Epoch 432/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7890 - val_loss: 0.8239\n",
      "Epoch 433/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7890 - val_loss: 0.8240\n",
      "Epoch 434/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7888 - val_loss: 0.8241\n",
      "Epoch 435/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7888 - val_loss: 0.8242\n",
      "Epoch 436/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7888 - val_loss: 0.8243\n",
      "Epoch 437/500\n",
      "120/120==============================] - 0s 51us/sample - loss: 0.7889 - val_loss: 0.8243\n",
      "Epoch 438/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7888 - val_loss: 0.8245\n",
      "Epoch 439/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7888 - val_loss: 0.8245\n",
      "Epoch 440/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7887 - val_loss: 0.8245\n",
      "Epoch 441/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7888 - val_loss: 0.8247\n",
      "Epoch 442/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7887 - val_loss: 0.8247\n",
      "Epoch 443/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7888 - val_loss: 0.8248\n",
      "Epoch 444/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7887 - val_loss: 0.8249\n",
      "Epoch 445/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7887 - val_loss: 0.8250\n",
      "Epoch 446/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7886 - val_loss: 0.8251\n",
      "Epoch 447/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.7886 - val_loss: 0.8252\n",
      "Epoch 448/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 0.7889 - val_loss: 0.8253\n",
      "Epoch 449/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7887 - val_loss: 0.8254\n",
      "Epoch 450/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7886 - val_loss: 0.8254\n",
      "Epoch 451/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7887 - val_loss: 0.8255\n",
      "Epoch 452/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7886 - val_loss: 0.8256\n",
      "Epoch 453/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7888 - val_loss: 0.8256\n",
      "Epoch 454/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7885 - val_loss: 0.8257\n",
      "Epoch 455/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7885 - val_loss: 0.8258\n",
      "Epoch 456/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7886 - val_loss: 0.8258\n",
      "Epoch 457/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7885 - val_loss: 0.8260\n",
      "Epoch 458/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7885 - val_loss: 0.8261\n",
      "Epoch 459/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7885 - val_loss: 0.8262\n",
      "Epoch 460/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7885 - val_loss: 0.8262\n",
      "Epoch 461/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7885 - val_loss: 0.8263\n",
      "Epoch 462/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7887 - val_loss: 0.8263\n",
      "Epoch 463/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7886 - val_loss: 0.8265\n",
      "Epoch 464/500\n",
      "120/120==============================] - 0s 49us/sample - loss: 0.7884 - val_loss: 0.8265\n",
      "Epoch 465/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7885 - val_loss: 0.8266\n",
      "Epoch 466/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7884 - val_loss: 0.8267\n",
      "Epoch 467/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7883 - val_loss: 0.8268\n",
      "Epoch 468/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7885 - val_loss: 0.8269\n",
      "Epoch 469/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7883 - val_loss: 0.8270\n",
      "Epoch 470/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7884 - val_loss: 0.8271\n",
      "Epoch 471/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.7883 - val_loss: 0.8272\n",
      "Epoch 472/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7884 - val_loss: 0.8272\n",
      "Epoch 473/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7884 - val_loss: 0.8273\n",
      "Epoch 474/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 0.7883 - val_loss: 0.8274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7883 - val_loss: 0.8275\n",
      "Epoch 476/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7886 - val_loss: 0.8275\n",
      "Epoch 477/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7883 - val_loss: 0.8276\n",
      "Epoch 478/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7883 - val_loss: 0.8277\n",
      "Epoch 479/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7883 - val_loss: 0.8278\n",
      "Epoch 480/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7885 - val_loss: 0.8279\n",
      "Epoch 481/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.7883 - val_loss: 0.8280\n",
      "Epoch 482/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7882 - val_loss: 0.8282\n",
      "Epoch 483/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7882 - val_loss: 0.8283\n",
      "Epoch 484/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7882 - val_loss: 0.8283\n",
      "Epoch 485/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7882 - val_loss: 0.8283\n",
      "Epoch 486/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7882 - val_loss: 0.8284\n",
      "Epoch 487/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7882 - val_loss: 0.8285\n",
      "Epoch 488/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7882 - val_loss: 0.8286\n",
      "Epoch 489/500\n",
      "120/120==============================] - 0s 52us/sample - loss: 0.7882 - val_loss: 0.8287\n",
      "Epoch 490/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7882 - val_loss: 0.8287\n",
      "Epoch 491/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7882 - val_loss: 0.8288\n",
      "Epoch 492/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7882 - val_loss: 0.8288\n",
      "Epoch 493/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7882 - val_loss: 0.8289\n",
      "Epoch 494/500\n",
      "120/120==============================] - 0s 48us/sample - loss: 0.7881 - val_loss: 0.8290\n",
      "Epoch 495/500\n",
      "120/120==============================] - 0s 49us/sample - loss: 0.7881 - val_loss: 0.8290\n",
      "Epoch 496/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7881 - val_loss: 0.8290\n",
      "Epoch 497/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7881 - val_loss: 0.8291\n",
      "Epoch 498/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7883 - val_loss: 0.8291\n",
      "Epoch 499/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7881 - val_loss: 0.8292\n",
      "Epoch 500/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7881 - val_loss: 0.8293\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "callback_list = [ModelCheckpoint(filepath='my_model.h5', \n",
    "                                 monitor='val_loss', save_best_only=True)]\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restoring the saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50==============================] - 0s 1ms/sample - loss: 1.0212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0212203574180603"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('simple_model.h5')\n",
    "model.load_weights('my_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_arr = np.arange(-2, 2, 0.1)\n",
    "y_arr = model.predict(x_arr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr, '-r', lw=3)\n",
    "# plt.savefig('images/14_05.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서를 다차원 배열로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]], shape=(3, 4), dtype=float64)\n",
      "T1의 크기: (3, 4)\n",
      "T1의 크기: (3, 4)\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
      "array([[ 0.14402906,  0.71120754,  0.27521944, -0.73707145],\n",
      "       [ 1.39096253,  1.05561972,  0.0764452 , -0.1990654 ],\n",
      "       [-0.48206527, -0.28935989, -1.16747646, -0.35476874]])>\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float64, numpy=array([ 1.05046203,  2.85023996, -1.41889641])>\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1., 2., 3., 3.5],\n",
    "                [4., 5., 6., 6.5],\n",
    "                [7., 8., 9., 9.5]])\n",
    "T1 = tf.constant(arr)\n",
    "print(T1)\n",
    "s = T1.get_shape()\n",
    "print('T1의 크기:', s)\n",
    "print('T1의 크기:', T1.shape)\n",
    "T2 = tf.Variable(np.random.normal(size=s))\n",
    "print(T2)\n",
    "T3 = tf.Variable(np.random.normal(size=s[0]))\n",
    "print(T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[1.  2.  3.  3.5 4.  5.  6.  6.5 7.  8.  9.  9.5]]], shape=(1, 1, 12), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]], shape=(1, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T4 = tf.reshape(T1, shape=[1, 1, -1])\n",
    "print(T4)\n",
    "T5 = tf.reshape(T1, shape=[1, 3, -1])\n",
    "print(T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. ]\n",
      "  [4. ]\n",
      "  [7. ]]\n",
      "\n",
      " [[2. ]\n",
      "  [5. ]\n",
      "  [8. ]]\n",
      "\n",
      " [[3. ]\n",
      "  [6. ]\n",
      "  [9. ]]\n",
      "\n",
      " [[3.5]\n",
      "  [6.5]\n",
      "  [9.5]]], shape=(4, 3, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1.  4.  7. ]\n",
      "  [2.  5.  8. ]\n",
      "  [3.  6.  9. ]\n",
      "  [3.5 6.5 9.5]]], shape=(1, 4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T6 = tf.transpose(T5, perm=[2, 1, 0])\n",
    "print(T6)\n",
    "T7 = tf.transpose(T5, perm=[0, 2, 1])\n",
    "print(T7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=77349, shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]]])>, <tf.Tensor: id=77350, shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[3. , 3.5],\n",
      "        [6. , 6.5],\n",
      "        [9. , 9.5]]])>]\n"
     ]
    }
   ],
   "source": [
    "t5_splt = tf.split(T5, \n",
    "                   num_or_size_splits=2, \n",
    "                   axis=2)\n",
    "print(t5_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(10, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.ones(shape=(5, 1), dtype=tf.float32)\n",
    "t2 = tf.zeros(shape=(5, 1), dtype=tf.float32)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "t3 = tf.concat([t1, t2], axis=0)\n",
    "print(t3)\n",
    "t4 = tf.concat([t1, t2], axis=1)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing the graph with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 2ms/sample - loss: 14.6074 - val_loss: 9.9960\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 14.3126 - val_loss: 9.8000\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 14.0206 - val_loss: 9.6254\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 13.7543 - val_loss: 9.4431\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 13.4687 - val_loss: 9.2650\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 13.1935 - val_loss: 9.1059\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 12.9461 - val_loss: 8.9283\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 12.6730 - val_loss: 8.7570\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 12.4154 - val_loss: 8.6039\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 12.1796 - val_loss: 8.4446\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 11.9311 - val_loss: 8.3004\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 11.7093 - val_loss: 8.1516\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 11.4768 - val_loss: 7.9925\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 11.2365 - val_loss: 7.8487\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 11.0168 - val_loss: 7.7151\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 10.8137 - val_loss: 7.5535\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 10.5839 - val_loss: 7.4143\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 10.3728 - val_loss: 7.2873\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 10.1747 - val_loss: 7.1556\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 9.9725 - val_loss: 7.0315\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 9.7824 - val_loss: 6.9075\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 9.5923 - val_loss: 6.7903\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 9.4112 - val_loss: 6.6642\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 9.2176 - val_loss: 6.5480\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 9.0433 - val_loss: 6.4305\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 8.8651 - val_loss: 6.3105\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 8.6823 - val_loss: 6.1903\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 8.5041 - val_loss: 6.0814\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 8.3437 - val_loss: 5.9805\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 8.1905 - val_loss: 5.8782\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 8.0385 - val_loss: 5.7715\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 7.8785 - val_loss: 5.6758\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 7.7322 - val_loss: 5.5821\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 7.5885 - val_loss: 5.4865\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 7.4402 - val_loss: 5.3848\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 7.2870 - val_loss: 5.2971\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 7.1542 - val_loss: 5.2116\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 7.0238 - val_loss: 5.1271\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 6.8958 - val_loss: 5.0440\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 6.7718 - val_loss: 4.9604\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 6.6426 - val_loss: 4.8761\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 6.5140 - val_loss: 4.7896\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 6.3826 - val_loss: 4.7148\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 6.2673 - val_loss: 4.6402\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 6.1544 - val_loss: 4.5589\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 6.0368 - val_loss: 4.4917\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 5.9322 - val_loss: 4.4169\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 5.8229 - val_loss: 4.3475\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 5.7169 - val_loss: 4.2723\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 5.6070 - val_loss: 4.2012\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 5.5004 - val_loss: 4.1289\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 5.3941 - val_loss: 4.0677\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 5.2974 - val_loss: 4.0017\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 5.1997 - val_loss: 3.9388\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 5.1048 - val_loss: 3.8748\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 5.0097 - val_loss: 3.8131\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 4.9169 - val_loss: 3.7513\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 4.8246 - val_loss: 3.6926\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 4.7385 - val_loss: 3.6388\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 4.6563 - val_loss: 3.5790\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 4.5669 - val_loss: 3.5251\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 4.4864 - val_loss: 3.4679\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 4.4005 - val_loss: 3.4157\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 4.3251 - val_loss: 3.3681\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 4.2526 - val_loss: 3.3108\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 4.1675 - val_loss: 3.2644\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 4.1000 - val_loss: 3.2195\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 4.0327 - val_loss: 3.1661\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.9509 - val_loss: 3.1166\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 3.8800 - val_loss: 3.0715\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 3.8143 - val_loss: 3.0283\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 3.7486 - val_loss: 2.9850\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.6854 - val_loss: 2.9433\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 3.6230 - val_loss: 2.8997\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.5618 - val_loss: 2.8563\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 3.4970 - val_loss: 2.8136\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 3.4336 - val_loss: 2.7740\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 3.3754 - val_loss: 2.7369\n",
      "Epoch 79/500\n",
      "105/105==============================] - ETA: 0s - loss: 4.313 - 0s 47us/sample - loss: 3.3200 - val_loss: 2.7008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 3.2654 - val_loss: 2.6654\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.2128 - val_loss: 2.6271\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 3.1567 - val_loss: 2.5919\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 3.1057 - val_loss: 2.5605\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 3.0587 - val_loss: 2.5273\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.0104 - val_loss: 2.4973\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.9658 - val_loss: 2.4637\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 2.9182 - val_loss: 2.4338\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.8747 - val_loss: 2.4049\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 2.8314 - val_loss: 2.3756\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 2.7873 - val_loss: 2.3462\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 2.7428 - val_loss: 2.3182\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.7002 - val_loss: 2.2885\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 2.6562 - val_loss: 2.2591\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.6131 - val_loss: 2.2346\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 2.5762 - val_loss: 2.2060\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.5332 - val_loss: 2.1789\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.4941 - val_loss: 2.1572\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.4617 - val_loss: 2.1361\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.4295 - val_loss: 2.1107\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.3929 - val_loss: 2.0858\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 2.3577 - val_loss: 2.0632\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 2.3230 - val_loss: 2.0406\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 2.2891 - val_loss: 2.0148\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 2.2536 - val_loss: 1.9934\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.2236 - val_loss: 1.9714\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 2.1911 - val_loss: 1.9513\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 2.1612 - val_loss: 1.9328\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.1338 - val_loss: 1.9128\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.1043 - val_loss: 1.8931\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 2.0762 - val_loss: 1.8723\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 2.0477 - val_loss: 1.8528\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 2.0211 - val_loss: 1.8328\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.9910 - val_loss: 1.8164\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.9683 - val_loss: 1.7988\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.9433 - val_loss: 1.7789\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.9147 - val_loss: 1.7597\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.8863 - val_loss: 1.7425\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.8616 - val_loss: 1.7272\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.8394 - val_loss: 1.7118\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.8176 - val_loss: 1.6975\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 1.7969 - val_loss: 1.6827\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.7769 - val_loss: 1.6701\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.7581 - val_loss: 1.6553\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.7377 - val_loss: 1.6407\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.7166 - val_loss: 1.6282\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.6983 - val_loss: 1.6146\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.6788 - val_loss: 1.6010\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.6603 - val_loss: 1.5894\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.6433 - val_loss: 1.5752\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.6241 - val_loss: 1.5616\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.6055 - val_loss: 1.5500\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 1.5886 - val_loss: 1.5350\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.5686 - val_loss: 1.5248\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.5532 - val_loss: 1.5137\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.5366 - val_loss: 1.5025\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 76us/sample - loss: 1.5202 - val_loss: 1.4906\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.5028 - val_loss: 1.4796\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.4870 - val_loss: 1.4663\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.4706 - val_loss: 1.4559\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.4566 - val_loss: 1.4458\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 1.4413 - val_loss: 1.4361\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.4279 - val_loss: 1.4267\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.4139 - val_loss: 1.4169\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.4002 - val_loss: 1.4066\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.3867 - val_loss: 1.3980\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.3744 - val_loss: 1.3886\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.3613 - val_loss: 1.3806\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.3495 - val_loss: 1.3703\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 1.3354 - val_loss: 1.3608\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 1.3222 - val_loss: 1.3531\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.3111 - val_loss: 1.3448\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.2999 - val_loss: 1.3369\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.2890 - val_loss: 1.3285\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.2770 - val_loss: 1.3189\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.2639 - val_loss: 1.3107\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 1.2523 - val_loss: 1.3030\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.2418 - val_loss: 1.2970\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.2327 - val_loss: 1.2899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.2228 - val_loss: 1.2818\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.2114 - val_loss: 1.2746\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.2010 - val_loss: 1.2672\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.1918 - val_loss: 1.2616\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 1.1829 - val_loss: 1.2546\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.1737 - val_loss: 1.2485\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.1653 - val_loss: 1.2407\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.1557 - val_loss: 1.2372\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1497 - val_loss: 1.2307\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.1410 - val_loss: 1.2253\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1331 - val_loss: 1.2206\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.1263 - val_loss: 1.2155\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.1191 - val_loss: 1.2096\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.1109 - val_loss: 1.2052\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 83us/sample - loss: 1.1047 - val_loss: 1.1993\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 1.0968 - val_loss: 1.1933\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 1.0896 - val_loss: 1.1897\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.0834 - val_loss: 1.1843\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.0767 - val_loss: 1.1797\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0697 - val_loss: 1.1742\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 1.0626 - val_loss: 1.1700\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0568 - val_loss: 1.1647\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0502 - val_loss: 1.1610\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 1.0451 - val_loss: 1.1564\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.0388 - val_loss: 1.1516\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0328 - val_loss: 1.1476\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.0279 - val_loss: 1.1450\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.0239 - val_loss: 1.1410\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 1.0187 - val_loss: 1.1362\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.0128 - val_loss: 1.1324\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 1.0080 - val_loss: 1.1296\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0037 - val_loss: 1.1257\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.9987 - val_loss: 1.1223\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.9938 - val_loss: 1.1188\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9888 - val_loss: 1.1149\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9835 - val_loss: 1.1122\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.9790 - val_loss: 1.1081\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9741 - val_loss: 1.1053\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9705 - val_loss: 1.1017\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.9663 - val_loss: 1.0980\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9621 - val_loss: 1.0939\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.9574 - val_loss: 1.0916\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9536 - val_loss: 1.0882\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9498 - val_loss: 1.0859\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.9466 - val_loss: 1.0827\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9428 - val_loss: 1.0790\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9382 - val_loss: 1.0760\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.9344 - val_loss: 1.0736\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9308 - val_loss: 1.0708\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.9276 - val_loss: 1.0681\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9242 - val_loss: 1.0649\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9209 - val_loss: 1.0626\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9182 - val_loss: 1.0603\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9153 - val_loss: 1.0577\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.9121 - val_loss: 1.0548\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9091 - val_loss: 1.0532\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9067 - val_loss: 1.0512\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 0.9040 - val_loss: 1.0489\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9014 - val_loss: 1.0466\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8991 - val_loss: 1.0452\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8968 - val_loss: 1.0431\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8947 - val_loss: 1.0412\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.8926 - val_loss: 1.0398\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8907 - val_loss: 1.0377\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8882 - val_loss: 1.0363\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8863 - val_loss: 1.0339\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8838 - val_loss: 1.0325\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8819 - val_loss: 1.0319\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8805 - val_loss: 1.0304\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8786 - val_loss: 1.0282\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8767 - val_loss: 1.0273\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8751 - val_loss: 1.0250\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8727 - val_loss: 1.0234\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8705 - val_loss: 1.0210\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8679 - val_loss: 1.0203\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8666 - val_loss: 1.0194\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8650 - val_loss: 1.0177\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8633 - val_loss: 1.0169\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8620 - val_loss: 1.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8603 - val_loss: 1.0135\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8581 - val_loss: 1.0117\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8564 - val_loss: 1.0091\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.8537 - val_loss: 1.0077\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8518 - val_loss: 1.0072\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8508 - val_loss: 1.0060\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8492 - val_loss: 1.0043\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8476 - val_loss: 1.0028\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8458 - val_loss: 1.0011\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8439 - val_loss: 0.9997\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8425 - val_loss: 0.9982\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8410 - val_loss: 0.9968\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8395 - val_loss: 0.9959\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8383 - val_loss: 0.9953\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8375 - val_loss: 0.9930\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8353 - val_loss: 0.9918\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8341 - val_loss: 0.9904\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8327 - val_loss: 0.9896\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8318 - val_loss: 0.9883\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8303 - val_loss: 0.9865\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8290 - val_loss: 0.9861\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8281 - val_loss: 0.9852\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8271 - val_loss: 0.9846\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8258 - val_loss: 0.9833\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8246 - val_loss: 0.9828\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8240 - val_loss: 0.9822\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8230 - val_loss: 0.9813\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8225 - val_loss: 0.9810\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8219 - val_loss: 0.9805\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 69us/sample - loss: 0.8213 - val_loss: 0.9799\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8206 - val_loss: 0.9794\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8200 - val_loss: 0.9786\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8192 - val_loss: 0.9783\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8187 - val_loss: 0.9767\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8177 - val_loss: 0.9750\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8161 - val_loss: 0.9740\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8150 - val_loss: 0.9730\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8139 - val_loss: 0.9723\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8133 - val_loss: 0.9716\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8126 - val_loss: 0.9713\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8119 - val_loss: 0.9704\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8108 - val_loss: 0.9696\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 0.8100 - val_loss: 0.9687\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8091 - val_loss: 0.9683\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8085 - val_loss: 0.9676\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8078 - val_loss: 0.9665\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8069 - val_loss: 0.9655\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8060 - val_loss: 0.9649\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8056 - val_loss: 0.9642\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8050 - val_loss: 0.9641\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8047 - val_loss: 0.9631\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8040 - val_loss: 0.9631\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8036 - val_loss: 0.9627\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8033 - val_loss: 0.9619\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 0.8026 - val_loss: 0.9616\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8024 - val_loss: 0.9612\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8016 - val_loss: 0.9610\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.8012 - val_loss: 0.9609\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8011 - val_loss: 0.9612\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8010 - val_loss: 0.9605\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8005 - val_loss: 0.9602\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8002 - val_loss: 0.9594\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7997 - val_loss: 0.9583\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7990 - val_loss: 0.9587\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7990 - val_loss: 0.9585\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7984 - val_loss: 0.9580\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7981 - val_loss: 0.9571\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7976 - val_loss: 0.9570\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7974 - val_loss: 0.9570\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7971 - val_loss: 0.9567\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7967 - val_loss: 0.9561\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7963 - val_loss: 0.9563\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7961 - val_loss: 0.9553\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7954 - val_loss: 0.9549\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7950 - val_loss: 0.9548\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7948 - val_loss: 0.9541\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7943 - val_loss: 0.9536\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 75us/sample - loss: 0.7939 - val_loss: 0.9536\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 75us/sample - loss: 0.7936 - val_loss: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7934 - val_loss: 0.9531\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7934 - val_loss: 0.9528\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7930 - val_loss: 0.9521\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7929 - val_loss: 0.9513\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7926 - val_loss: 0.9507\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7923 - val_loss: 0.9509\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7923 - val_loss: 0.9504\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7922 - val_loss: 0.9499\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7915 - val_loss: 0.9500\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7916 - val_loss: 0.9496\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7911 - val_loss: 0.9492\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.7907 - val_loss: 0.9493\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 68us/sample - loss: 0.7907 - val_loss: 0.9497\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7905 - val_loss: 0.9494\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7903 - val_loss: 0.9492\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7899 - val_loss: 0.9488\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7897 - val_loss: 0.9486\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7894 - val_loss: 0.9481\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7891 - val_loss: 0.9474\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7889 - val_loss: 0.9471\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7885 - val_loss: 0.9471\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7884 - val_loss: 0.9468\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7883 - val_loss: 0.9462\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7880 - val_loss: 0.9461\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7877 - val_loss: 0.9458\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7877 - val_loss: 0.9458\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7877 - val_loss: 0.9464\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7877 - val_loss: 0.9457\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7873 - val_loss: 0.9455\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7871 - val_loss: 0.9450\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7868 - val_loss: 0.9449\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7867 - val_loss: 0.9447\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7864 - val_loss: 0.9442\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7866 - val_loss: 0.9448\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7864 - val_loss: 0.9446\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7863 - val_loss: 0.9441\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7862 - val_loss: 0.9446\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 71us/sample - loss: 0.7861 - val_loss: 0.9445\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7860 - val_loss: 0.9441\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.7859 - val_loss: 0.9435\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7856 - val_loss: 0.9429\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7855 - val_loss: 0.9431\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7853 - val_loss: 0.9429\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7851 - val_loss: 0.9427\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7852 - val_loss: 0.9427\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7852 - val_loss: 0.9424\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7847 - val_loss: 0.9423\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7845 - val_loss: 0.9420\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7843 - val_loss: 0.9419\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.7843 - val_loss: 0.9415\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7842 - val_loss: 0.9417\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7841 - val_loss: 0.9417\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7838 - val_loss: 0.9415\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7836 - val_loss: 0.9408\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7835 - val_loss: 0.9414\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7835 - val_loss: 0.9408\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7834 - val_loss: 0.9408\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7832 - val_loss: 0.9407\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7829 - val_loss: 0.9401\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7827 - val_loss: 0.9399\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7827 - val_loss: 0.9399\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7826 - val_loss: 0.9397\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7826 - val_loss: 0.9393\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7825 - val_loss: 0.9397\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7826 - val_loss: 0.9401\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7825 - val_loss: 0.9401\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7825 - val_loss: 0.9400\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.7823 - val_loss: 0.9401\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7827 - val_loss: 0.9399\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7821 - val_loss: 0.9397\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7821 - val_loss: 0.9393\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7818 - val_loss: 0.9392\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7818 - val_loss: 0.9390\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7817 - val_loss: 0.9390\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7819 - val_loss: 0.9389\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7817 - val_loss: 0.9386\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7816 - val_loss: 0.9388\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.7816 - val_loss: 0.9389\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7818 - val_loss: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7816 - val_loss: 0.9388\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7814 - val_loss: 0.9390\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7814 - val_loss: 0.9389\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7813 - val_loss: 0.9385\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7812 - val_loss: 0.9383\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 73us/sample - loss: 0.7811 - val_loss: 0.9381\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7812 - val_loss: 0.9383\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7812 - val_loss: 0.9382\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7813 - val_loss: 0.9390\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7812 - val_loss: 0.9387\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7811 - val_loss: 0.9384\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7812 - val_loss: 0.9384\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7811 - val_loss: 0.9385\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7810 - val_loss: 0.9386\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7810 - val_loss: 0.9389\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7811 - val_loss: 0.9389\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7810 - val_loss: 0.9389\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7810 - val_loss: 0.9387\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7812 - val_loss: 0.9383\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 83us/sample - loss: 0.7809 - val_loss: 0.9381\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7808 - val_loss: 0.9381\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 70us/sample - loss: 0.7809 - val_loss: 0.9379\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7808 - val_loss: 0.9376\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7806 - val_loss: 0.9377\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7807 - val_loss: 0.9375\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7806 - val_loss: 0.9371\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7807 - val_loss: 0.9374\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7806 - val_loss: 0.9371\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7804 - val_loss: 0.9375\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7805 - val_loss: 0.9373\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7804 - val_loss: 0.9368\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7804 - val_loss: 0.9370\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7805 - val_loss: 0.9370\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 72us/sample - loss: 0.7805 - val_loss: 0.9370\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7805 - val_loss: 0.9372\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7804 - val_loss: 0.9372\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7806 - val_loss: 0.9368\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7803 - val_loss: 0.9366\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7803 - val_loss: 0.9365\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7804 - val_loss: 0.9363\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7802 - val_loss: 0.9362\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7803 - val_loss: 0.9363\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7802 - val_loss: 0.9359\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7804 - val_loss: 0.9362\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7803 - val_loss: 0.9367\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7803 - val_loss: 0.9363\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7802 - val_loss: 0.9362\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7801 - val_loss: 0.9362\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7801 - val_loss: 0.9361\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7801 - val_loss: 0.9361\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7801 - val_loss: 0.9360\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7800 - val_loss: 0.9357\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 0.7800 - val_loss: 0.9358\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7799 - val_loss: 0.9360\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 0.7801 - val_loss: 0.9356\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7800 - val_loss: 0.9355\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7800 - val_loss: 0.9354\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 71us/sample - loss: 0.7799 - val_loss: 0.9357\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7801 - val_loss: 0.9352\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7800 - val_loss: 0.9354\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7798 - val_loss: 0.9354\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7799 - val_loss: 0.9349\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7798 - val_loss: 0.9347\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7796 - val_loss: 0.9350\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7797 - val_loss: 0.9352\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7796 - val_loss: 0.9354\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7797 - val_loss: 0.9355\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7798 - val_loss: 0.9356\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7798 - val_loss: 0.9353\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 66us/sample - loss: 0.7797 - val_loss: 0.9348\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7796 - val_loss: 0.9347\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9346\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7796 - val_loss: 0.9346\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7796 - val_loss: 0.9344\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 88us/sample - loss: 0.7799 - val_loss: 0.9343\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7796 - val_loss: 0.9345\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7796 - val_loss: 0.9347\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7797 - val_loss: 0.9349\n",
      "Epoch 474/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7796 - val_loss: 0.9351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7796 - val_loss: 0.9350\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7796 - val_loss: 0.9347\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 71us/sample - loss: 0.7797 - val_loss: 0.9344\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.7796 - val_loss: 0.9343\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9344\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7795 - val_loss: 0.9344\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7796 - val_loss: 0.9339\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7795 - val_loss: 0.9342\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7796 - val_loss: 0.9341\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7796 - val_loss: 0.9340\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7795 - val_loss: 0.9337\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7795 - val_loss: 0.9337\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7795 - val_loss: 0.9336\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7795 - val_loss: 0.9336\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7795 - val_loss: 0.9333\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7794 - val_loss: 0.9335\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7794 - val_loss: 0.9338\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7794 - val_loss: 0.9337\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7794 - val_loss: 0.9336\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 67us/sample - loss: 0.7794 - val_loss: 0.9336\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7796 - val_loss: 0.9338\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7796 - val_loss: 0.9335\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7794 - val_loss: 0.9337\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7794 - val_loss: 0.9336\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7794 - val_loss: 0.9336\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7794 - val_loss: 0.9337\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "callback_list = [TensorBoard()]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
