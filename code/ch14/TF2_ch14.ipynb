{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning - Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the optional watermark extension is a small IPython notebook plugin that I developed to make the code reproducible. You can just skip the following line(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2019-02-04 \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.15.4\n",
      "tensorflow 2.0.0-preview\n",
      "matplotlib 3.0.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -v -p numpy,tensorflow,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The use of `watermark` is optional. You can install this IPython extension via \"`pip install watermark`\". For more information, please see: https://github.com/rasbt/watermark.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14 - Going Deeper: The Mechanics of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to get the rank and shape of a tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크기: () (4,) (2, 2)\n",
      "랭크: 0 1 2\n"
     ]
    }
   ],
   "source": [
    "## t1, t2, t3 텐서를 정의합니다.\n",
    "t1 = tf.constant(np.pi)\n",
    "t2 = tf.constant([1, 2, 3, 4])\n",
    "t3 = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "## 랭크를 구합니다.\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)\n",
    "\n",
    "## 크기를 구합니다\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "print('크기:', s1, s2, s3)\n",
    "\n",
    "print('랭크:', \n",
    "      r1.numpy(), \n",
    "      r2.numpy(), \n",
    "      r3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding TensorFlow's computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2) \n",
    "c = tf.constant(3) \n",
    "\n",
    "z = 2*(a-b) + c\n",
    "\n",
    "print('2*(a-b)+c => ', z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "## 텐서플로 1.x 방식\n",
    "g = tf.Graph()\n",
    " \n",
    "## 그래프에 노드를 추가합니다.\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    \n",
    "## 그래프를 실행합니다.\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c => ', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_func():\n",
    "    a = tf.constant(1)\n",
    "    b = tf.constant(2) \n",
    "    c = tf.constant(3) \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "print('2*(a-b)+c => ', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.eager.def_function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(simple_func.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "def simple_func():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "simple_func = tf.function(simple_func)\n",
    "\n",
    "print('2*(a-b)+c => ', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func = simple_func.get_concrete_function()\n",
    "con_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"add\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with TensorFlow’s variables, and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables in TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w1:0' shape=(2, 4) dtype=int64>\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w1')\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'w1/Initializer/initial_value' type=Const>,\n",
       " <tf.Operation 'w1' type=VarHandleOp>,\n",
       " <tf.Operation 'w1/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'w1/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'w1/Read/ReadVariableOp' type=ReadVariableOp>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^w1/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    print(init.node_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2, 4), dtype=int64)\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    w1 = w1 + 1\n",
    "    print(w1)\n",
    "    \n",
    "with tf.compat.v1.Session(graph=g1) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w1')\n",
    "    w1 = w1.assign(w1 + 1)\n",
    "\n",
    "with tf.compat.v1.Session(graph=g2) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "w2 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                          [5, 6, 7, 8]]), name='w2')\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())\n",
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[ 3,  4,  5,  6],\n",
      "       [ 7,  8,  9, 10]])>\n"
     ]
    }
   ],
   "source": [
    "print(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 API 자세히 배우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create a random toy dataset for regression\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, \n",
    "                             scale=(0.5 + t*t/3), \n",
    "                             size=None)\n",
    "        y.append(r)\n",
    "    return  x, 1.726*x -0.84 + np.array(y)\n",
    "\n",
    "\n",
    "x, y = make_random_data() \n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "# plt.savefig('images/14_03.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=1, input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 655us/sample - loss: 3.5764 - val_loss: 2.4064\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.5192 - val_loss: 2.3748\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 3.4626 - val_loss: 2.3428\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.4050 - val_loss: 2.3114\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 3.3495 - val_loss: 2.2813\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.2949 - val_loss: 2.2537\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 3.2460 - val_loss: 2.2263\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 3.1960 - val_loss: 2.1984\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 3.1459 - val_loss: 2.1713\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 3.0967 - val_loss: 2.1443\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 3.0482 - val_loss: 2.1186\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.0025 - val_loss: 2.0937\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.9570 - val_loss: 2.0692\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.9117 - val_loss: 2.0419\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.8624 - val_loss: 2.0142\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.8136 - val_loss: 1.9927\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.7747 - val_loss: 1.9694\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.7327 - val_loss: 1.9473\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.6927 - val_loss: 1.9250\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.6527 - val_loss: 1.9020\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.6110 - val_loss: 1.8805\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.5719 - val_loss: 1.8594\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.5344 - val_loss: 1.8421\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.5028 - val_loss: 1.8222\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.4673 - val_loss: 1.8021\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.4314 - val_loss: 1.7836\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.3987 - val_loss: 1.7650\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.3662 - val_loss: 1.7483\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.3355 - val_loss: 1.7320\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.3056 - val_loss: 1.7127\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.2711 - val_loss: 1.6943\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 2.2377 - val_loss: 1.6769\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.2075 - val_loss: 1.6620\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.1811 - val_loss: 1.6484\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 2.1555 - val_loss: 1.6334\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.1290 - val_loss: 1.6191\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.1032 - val_loss: 1.6051\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.0782 - val_loss: 1.5925\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.0544 - val_loss: 1.5792\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.0300 - val_loss: 1.5635\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.0019 - val_loss: 1.5505\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.9778 - val_loss: 1.5379\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.9549 - val_loss: 1.5252\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.9321 - val_loss: 1.5121\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.9085 - val_loss: 1.4997\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.8860 - val_loss: 1.4873\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.8639 - val_loss: 1.4742\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.8409 - val_loss: 1.4620\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.8186 - val_loss: 1.4490\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.7951 - val_loss: 1.4358\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.7712 - val_loss: 1.4236\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.7498 - val_loss: 1.4130\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.7307 - val_loss: 1.4025\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.7113 - val_loss: 1.3921\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.6929 - val_loss: 1.3800\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.6714 - val_loss: 1.3691\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.6512 - val_loss: 1.3584\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.6329 - val_loss: 1.3501\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.6169 - val_loss: 1.3404\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.5992 - val_loss: 1.3312\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5827 - val_loss: 1.3222\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.5658 - val_loss: 1.3111\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5467 - val_loss: 1.3046\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.5334 - val_loss: 1.2955\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.5177 - val_loss: 1.2874\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.5028 - val_loss: 1.2798\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.4889 - val_loss: 1.2712\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.4731 - val_loss: 1.2631\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.4590 - val_loss: 1.2557\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.4452 - val_loss: 1.2485\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.4318 - val_loss: 1.2408\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.4183 - val_loss: 1.2338\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.4055 - val_loss: 1.2258\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.3911 - val_loss: 1.2187\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.3789 - val_loss: 1.2119\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.3665 - val_loss: 1.2051\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.3541 - val_loss: 1.1990\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.3425 - val_loss: 1.1917\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3297 - val_loss: 1.1855\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 36us/sample - loss: 1.3181 - val_loss: 1.1789\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.3062 - val_loss: 1.1728\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.2953 - val_loss: 1.1672\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2850 - val_loss: 1.1615\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2748 - val_loss: 1.1566\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2654 - val_loss: 1.1499\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.2537 - val_loss: 1.1445\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.2443 - val_loss: 1.1397\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.2352 - val_loss: 1.1347\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.2264 - val_loss: 1.1290\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2164 - val_loss: 1.1234\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.2062 - val_loss: 1.1184\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1972 - val_loss: 1.1139\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1888 - val_loss: 1.1096\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1805 - val_loss: 1.1046\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.1716 - val_loss: 1.0998\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 1.1630 - val_loss: 1.0947\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.1542 - val_loss: 1.0894\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.1446 - val_loss: 1.0856\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1376 - val_loss: 1.0815\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1298 - val_loss: 1.0774\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1226 - val_loss: 1.0739\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.1156 - val_loss: 1.0687\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1065 - val_loss: 1.0653\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.1002 - val_loss: 1.0609\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.0924 - val_loss: 1.0575\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0862 - val_loss: 1.0538\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0798 - val_loss: 1.0507\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0738 - val_loss: 1.0474\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0675 - val_loss: 1.0433\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0604 - val_loss: 1.0397\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0538 - val_loss: 1.0362\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.0475 - val_loss: 1.0325\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0411 - val_loss: 1.0292\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0348 - val_loss: 1.0273\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.0306 - val_loss: 1.0242\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.0252 - val_loss: 1.0205\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0184 - val_loss: 1.0184\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0140 - val_loss: 1.0150\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0085 - val_loss: 1.0123\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.0034 - val_loss: 1.0094\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9983 - val_loss: 1.0071\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9941 - val_loss: 1.0049\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9898 - val_loss: 1.0023\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9852 - val_loss: 0.9991\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9803 - val_loss: 0.9970\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9764 - val_loss: 0.9943\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.9718 - val_loss: 0.9922\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9676 - val_loss: 0.9899\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9634 - val_loss: 0.9876\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9593 - val_loss: 0.9856\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.9558 - val_loss: 0.9833\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9517 - val_loss: 0.9810\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9476 - val_loss: 0.9790\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9436 - val_loss: 0.9761\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9390 - val_loss: 0.9741\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9350 - val_loss: 0.9717\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9311 - val_loss: 0.9696\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9275 - val_loss: 0.9678\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9241 - val_loss: 0.9660\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9207 - val_loss: 0.9641\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9174 - val_loss: 0.9628\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9150 - val_loss: 0.9616\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9119 - val_loss: 0.9590\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9078 - val_loss: 0.9576\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.9049 - val_loss: 0.9560\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9018 - val_loss: 0.9546\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8994 - val_loss: 0.9536\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8968 - val_loss: 0.9523\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8944 - val_loss: 0.9508\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8918 - val_loss: 0.9492\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8889 - val_loss: 0.9485\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8866 - val_loss: 0.9466\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8833 - val_loss: 0.9451\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8805 - val_loss: 0.9441\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8786 - val_loss: 0.9429\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8765 - val_loss: 0.9419\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8745 - val_loss: 0.9405\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8718 - val_loss: 0.9392\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 37us/sample - loss: 0.8694 - val_loss: 0.9379\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8670 - val_loss: 0.9364\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8647 - val_loss: 0.9354\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8624 - val_loss: 0.9342\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8597 - val_loss: 0.9325\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8569 - val_loss: 0.9314\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8553 - val_loss: 0.9303\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8528 - val_loss: 0.9290\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8509 - val_loss: 0.9280\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8489 - val_loss: 0.9275\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8475 - val_loss: 0.9264\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8456 - val_loss: 0.9260\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8443 - val_loss: 0.9246\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8420 - val_loss: 0.9238\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8404 - val_loss: 0.9227\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8385 - val_loss: 0.9219\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8370 - val_loss: 0.9212\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8356 - val_loss: 0.9204\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8343 - val_loss: 0.9201\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8329 - val_loss: 0.9196\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8316 - val_loss: 0.9190\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8305 - val_loss: 0.9185\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8292 - val_loss: 0.9178\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8278 - val_loss: 0.9170\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8264 - val_loss: 0.9165\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8252 - val_loss: 0.9161\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8237 - val_loss: 0.9155\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8226 - val_loss: 0.9146\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8211 - val_loss: 0.9135\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8197 - val_loss: 0.9130\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8187 - val_loss: 0.9122\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8174 - val_loss: 0.9119\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8164 - val_loss: 0.9116\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8152 - val_loss: 0.9113\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8143 - val_loss: 0.9107\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8132 - val_loss: 0.9103\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8122 - val_loss: 0.9098\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8113 - val_loss: 0.9093\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8101 - val_loss: 0.9079\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8083 - val_loss: 0.9073\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8070 - val_loss: 0.9066\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8062 - val_loss: 0.9064\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8055 - val_loss: 0.9058\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.8048 - val_loss: 0.9053\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8039 - val_loss: 0.9051\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8032 - val_loss: 0.9043\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8022 - val_loss: 0.9040\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8013 - val_loss: 0.9033\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8002 - val_loss: 0.9031\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7994 - val_loss: 0.9025\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7983 - val_loss: 0.9023\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7976 - val_loss: 0.9019\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7969 - val_loss: 0.9023\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7963 - val_loss: 0.9020\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7955 - val_loss: 0.9015\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7947 - val_loss: 0.9013\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7943 - val_loss: 0.9013\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7941 - val_loss: 0.9012\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7933 - val_loss: 0.9008\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7926 - val_loss: 0.9003\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7919 - val_loss: 0.9002\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7915 - val_loss: 0.8996\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7906 - val_loss: 0.8993\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7899 - val_loss: 0.8991\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7898 - val_loss: 0.8987\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7887 - val_loss: 0.8986\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7880 - val_loss: 0.8977\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7870 - val_loss: 0.8967\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7861 - val_loss: 0.8965\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7856 - val_loss: 0.8963\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7851 - val_loss: 0.8956\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7843 - val_loss: 0.8955\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7838 - val_loss: 0.8953\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7835 - val_loss: 0.8955\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7831 - val_loss: 0.8952\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7829 - val_loss: 0.8956\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7823 - val_loss: 0.8953\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7818 - val_loss: 0.8950\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7813 - val_loss: 0.8949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7809 - val_loss: 0.8951\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7803 - val_loss: 0.8951\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7800 - val_loss: 0.8950\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7794 - val_loss: 0.8950\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7789 - val_loss: 0.8948\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7785 - val_loss: 0.8950\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7783 - val_loss: 0.8947\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7778 - val_loss: 0.8943\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7776 - val_loss: 0.8942\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7769 - val_loss: 0.8939\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7767 - val_loss: 0.8937\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7762 - val_loss: 0.8935\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7759 - val_loss: 0.8940\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7755 - val_loss: 0.8935\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7751 - val_loss: 0.8935\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7747 - val_loss: 0.8932\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7744 - val_loss: 0.8930\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7742 - val_loss: 0.8927\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7737 - val_loss: 0.8931\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7734 - val_loss: 0.8928\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7728 - val_loss: 0.8931\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7726 - val_loss: 0.8933\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7722 - val_loss: 0.8928\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7720 - val_loss: 0.8928\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7715 - val_loss: 0.8927\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7710 - val_loss: 0.8930\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7706 - val_loss: 0.8928\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7704 - val_loss: 0.8925\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7701 - val_loss: 0.8926\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7698 - val_loss: 0.8923\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7695 - val_loss: 0.8924\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7694 - val_loss: 0.8926\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7693 - val_loss: 0.8929\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7691 - val_loss: 0.8927\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7689 - val_loss: 0.8928\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7687 - val_loss: 0.8925\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7685 - val_loss: 0.8927\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7683 - val_loss: 0.8929\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7680 - val_loss: 0.8932\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7681 - val_loss: 0.8931\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7676 - val_loss: 0.8930\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7674 - val_loss: 0.8935\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7672 - val_loss: 0.8937\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7671 - val_loss: 0.8935\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7667 - val_loss: 0.8933\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7664 - val_loss: 0.8931\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7662 - val_loss: 0.8931\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7662 - val_loss: 0.8927\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7659 - val_loss: 0.8926\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7658 - val_loss: 0.8929\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7657 - val_loss: 0.8934\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7656 - val_loss: 0.8928\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7652 - val_loss: 0.8928\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7649 - val_loss: 0.8927\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7647 - val_loss: 0.8929\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7646 - val_loss: 0.8928\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7643 - val_loss: 0.8935\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7642 - val_loss: 0.8933\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7639 - val_loss: 0.8930\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7638 - val_loss: 0.8930\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7636 - val_loss: 0.8933\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7636 - val_loss: 0.8933\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7634 - val_loss: 0.8933\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7629 - val_loss: 0.8933\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7629 - val_loss: 0.8939\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7628 - val_loss: 0.8940\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7627 - val_loss: 0.8938\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7626 - val_loss: 0.8942\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7626 - val_loss: 0.8941\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7626 - val_loss: 0.8941\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7621 - val_loss: 0.8939\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7620 - val_loss: 0.8937\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7619 - val_loss: 0.8936\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7617 - val_loss: 0.8936\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7614 - val_loss: 0.8937\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7614 - val_loss: 0.8939\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7613 - val_loss: 0.8933\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7610 - val_loss: 0.8933\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7609 - val_loss: 0.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7608 - val_loss: 0.8932\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7607 - val_loss: 0.8933\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7606 - val_loss: 0.8934\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7607 - val_loss: 0.8932\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7604 - val_loss: 0.8931\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7603 - val_loss: 0.8933\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7603 - val_loss: 0.8933\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7601 - val_loss: 0.8934\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7600 - val_loss: 0.8930\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7600 - val_loss: 0.8931\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7599 - val_loss: 0.8933\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7600 - val_loss: 0.8933\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7598 - val_loss: 0.8938\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7597 - val_loss: 0.8935\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7597 - val_loss: 0.8940\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7596 - val_loss: 0.8941\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7595 - val_loss: 0.8944\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7594 - val_loss: 0.8943\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7593 - val_loss: 0.8939\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7592 - val_loss: 0.8935\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7593 - val_loss: 0.8930\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7591 - val_loss: 0.8935\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7591 - val_loss: 0.8937\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7591 - val_loss: 0.8938\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7592 - val_loss: 0.8938\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7589 - val_loss: 0.8937\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7589 - val_loss: 0.8937\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7589 - val_loss: 0.8936\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7588 - val_loss: 0.8933\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7587 - val_loss: 0.8934\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7588 - val_loss: 0.8932\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7587 - val_loss: 0.8928\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7586 - val_loss: 0.8930\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7588 - val_loss: 0.8929\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7584 - val_loss: 0.8932\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7583 - val_loss: 0.8933\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7584 - val_loss: 0.8931\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7584 - val_loss: 0.8932\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7585 - val_loss: 0.8931\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7583 - val_loss: 0.8932\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7582 - val_loss: 0.8934\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7581 - val_loss: 0.8937\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7581 - val_loss: 0.8939\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7581 - val_loss: 0.8939\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7580 - val_loss: 0.8938\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7581 - val_loss: 0.8941\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7580 - val_loss: 0.8943\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7580 - val_loss: 0.8943\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7579 - val_loss: 0.8946\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7579 - val_loss: 0.8944\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7579 - val_loss: 0.8941\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7579 - val_loss: 0.8945\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7578 - val_loss: 0.8952\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.7578 - val_loss: 0.8951\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7578 - val_loss: 0.8951\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7578 - val_loss: 0.8948\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7577 - val_loss: 0.8948\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7577 - val_loss: 0.8946\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7576 - val_loss: 0.8946\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7579 - val_loss: 0.8946\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7577 - val_loss: 0.8945\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7576 - val_loss: 0.8945\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7576 - val_loss: 0.8945\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7575 - val_loss: 0.8948\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7575 - val_loss: 0.8945\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7574 - val_loss: 0.8949\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7574 - val_loss: 0.8949\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7575 - val_loss: 0.8950\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7573 - val_loss: 0.8953\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7571 - val_loss: 0.8954\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7571 - val_loss: 0.8953\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7573 - val_loss: 0.8958\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7570 - val_loss: 0.8957\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7571 - val_loss: 0.8957\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7569 - val_loss: 0.8957\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7569 - val_loss: 0.8954\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7570 - val_loss: 0.8954\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7569 - val_loss: 0.8954\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7569 - val_loss: 0.8954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7569 - val_loss: 0.8955\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7569 - val_loss: 0.8953\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7567 - val_loss: 0.8953\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7567 - val_loss: 0.8955\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7567 - val_loss: 0.8956\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7565 - val_loss: 0.8957\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7566 - val_loss: 0.8960\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7566 - val_loss: 0.8960\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7566 - val_loss: 0.8961\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7565 - val_loss: 0.8962\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7565 - val_loss: 0.8961\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7565 - val_loss: 0.8961\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7565 - val_loss: 0.8964\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7564 - val_loss: 0.8967\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7564 - val_loss: 0.8970\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7565 - val_loss: 0.8971\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7564 - val_loss: 0.8976\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7563 - val_loss: 0.8977\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7563 - val_loss: 0.8981\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7562 - val_loss: 0.8979\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7563 - val_loss: 0.8975\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.8976\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7561 - val_loss: 0.8976\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7561 - val_loss: 0.8974\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7562 - val_loss: 0.8976\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7563 - val_loss: 0.8977\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7562 - val_loss: 0.8977\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7561 - val_loss: 0.8980\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7562 - val_loss: 0.8981\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7561 - val_loss: 0.8979\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7560 - val_loss: 0.8980\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7562 - val_loss: 0.8979\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7562 - val_loss: 0.8975\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7560 - val_loss: 0.8975\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7565 - val_loss: 0.8982\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7562 - val_loss: 0.8983\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7562 - val_loss: 0.8986\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7560 - val_loss: 0.8986\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7561 - val_loss: 0.8986\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7560 - val_loss: 0.8987\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7560 - val_loss: 0.8991\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7561 - val_loss: 0.8994\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7560 - val_loss: 0.8994\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7561 - val_loss: 0.9001\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7561 - val_loss: 0.8998\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7562 - val_loss: 0.8993\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 31us/sample - loss: 0.7560 - val_loss: 0.8995\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7560 - val_loss: 0.8995\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7562 - val_loss: 0.8996\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7560 - val_loss: 0.8995\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7563 - val_loss: 0.8993\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7560 - val_loss: 0.8991\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7560 - val_loss: 0.8990\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7562 - val_loss: 0.8991\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7560 - val_loss: 0.8992\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7560 - val_loss: 0.8988\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7559 - val_loss: 0.8987\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7560 - val_loss: 0.8986\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7560 - val_loss: 0.8988\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.8989\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7559 - val_loss: 0.8995\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7559 - val_loss: 0.8998\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7559 - val_loss: 0.8999\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7560 - val_loss: 0.8998\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.8999\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.8999\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7559 - val_loss: 0.8996\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7559 - val_loss: 0.8995\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7558 - val_loss: 0.8998\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7560 - val_loss: 0.9000\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7558 - val_loss: 0.9001\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.9001\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7559 - val_loss: 0.9000\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7560 - val_loss: 0.9002\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7558 - val_loss: 0.9008\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9006\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7558 - val_loss: 0.9006\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7557 - val_loss: 0.9003\n",
      "Epoch 474/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.9002\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7558 - val_loss: 0.9006\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7558 - val_loss: 0.9003\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.9003\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7558 - val_loss: 0.9004\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9010\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7559 - val_loss: 0.9008\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7558 - val_loss: 0.9005\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7558 - val_loss: 0.9007\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7557 - val_loss: 0.9008\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7557 - val_loss: 0.9010\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7558 - val_loss: 0.9014\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9014\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7558 - val_loss: 0.9020\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7559 - val_loss: 0.9018\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9016\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7556 - val_loss: 0.9015\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7557 - val_loss: 0.9019\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7558 - val_loss: 0.9019\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7558 - val_loss: 0.9022\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7559 - val_loss: 0.9020\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7558 - val_loss: 0.9021\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7556 - val_loss: 0.9020\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9022\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7557 - val_loss: 0.9020\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9018\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 500+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input = Input(shape=(1,))\n",
    "output = Dense(1)(input)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 780us/sample - loss: 4.3218 - val_loss: 2.8756\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 4.2448 - val_loss: 2.8328\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 4.1699 - val_loss: 2.7945\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 4.1021 - val_loss: 2.7521\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 4.0299 - val_loss: 2.7130\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 3.9615 - val_loss: 2.6734\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.8920 - val_loss: 2.6351\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.8252 - val_loss: 2.6021\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 3.7667 - val_loss: 2.5683\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 3.7070 - val_loss: 2.5308\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.6400 - val_loss: 2.4875\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.5656 - val_loss: 2.4563\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 3.5119 - val_loss: 2.4246\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 3.4569 - val_loss: 2.3945\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 3.4019 - val_loss: 2.3592\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 3.3401 - val_loss: 2.3287\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.2871 - val_loss: 2.3007\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 3.2370 - val_loss: 2.2675\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.1789 - val_loss: 2.2366\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 3.1250 - val_loss: 2.2062\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 3.0717 - val_loss: 2.1767\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 3.0200 - val_loss: 2.1519\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.9764 - val_loss: 2.1283\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 2.9332 - val_loss: 2.0999\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.8843 - val_loss: 2.0754\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.8412 - val_loss: 2.0504\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.7971 - val_loss: 2.0247\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.7521 - val_loss: 1.9991\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 2.7078 - val_loss: 1.9758\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.6679 - val_loss: 1.9533\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.6278 - val_loss: 1.9334\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 2.5927 - val_loss: 1.9120\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.5547 - val_loss: 1.8940\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.5216 - val_loss: 1.8684\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.4778 - val_loss: 1.8480\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.4414 - val_loss: 1.8258\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.4033 - val_loss: 1.8082\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.3720 - val_loss: 1.7897\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 2.3399 - val_loss: 1.7721\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.3091 - val_loss: 1.7551\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.2787 - val_loss: 1.7372\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.2468 - val_loss: 1.7173\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.2118 - val_loss: 1.7016\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 2.1837 - val_loss: 1.6837\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.1523 - val_loss: 1.6665\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.1227 - val_loss: 1.6498\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.0932 - val_loss: 1.6341\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 2.0659 - val_loss: 1.6188\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.0387 - val_loss: 1.6026\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.0099 - val_loss: 1.5881\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.9850 - val_loss: 1.5752\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.9615 - val_loss: 1.5605\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 1.9362 - val_loss: 1.5475\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.9129 - val_loss: 1.5336\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.8890 - val_loss: 1.5192\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.8638 - val_loss: 1.5038\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 1.8371 - val_loss: 1.4922\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.8156 - val_loss: 1.4771\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.7895 - val_loss: 1.4631\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.7650 - val_loss: 1.4502\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.7436 - val_loss: 1.4368\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.7211 - val_loss: 1.4245\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.6996 - val_loss: 1.4135\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.6811 - val_loss: 1.4034\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.6633 - val_loss: 1.3937\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.6457 - val_loss: 1.3828\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.6267 - val_loss: 1.3729\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.6092 - val_loss: 1.3638\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.5923 - val_loss: 1.3541\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.5751 - val_loss: 1.3448\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.5594 - val_loss: 1.3369\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5441 - val_loss: 1.3262\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.5258 - val_loss: 1.3183\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.5116 - val_loss: 1.3095\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.4963 - val_loss: 1.3004\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.4811 - val_loss: 1.2920\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.4658 - val_loss: 1.2826\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.4494 - val_loss: 1.2742\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.4349 - val_loss: 1.2657\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 41us/sample - loss: 1.4200 - val_loss: 1.2586\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.4074 - val_loss: 1.2524\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.3957 - val_loss: 1.2443\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.3825 - val_loss: 1.2376\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.3705 - val_loss: 1.2304\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.3585 - val_loss: 1.2230\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.3449 - val_loss: 1.2150\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.3316 - val_loss: 1.2075\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.3198 - val_loss: 1.2017\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.3095 - val_loss: 1.1953\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.2983 - val_loss: 1.1882\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2857 - val_loss: 1.1817\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.2745 - val_loss: 1.1748\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.2626 - val_loss: 1.1699\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.2533 - val_loss: 1.1642\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 1.2434 - val_loss: 1.1580\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.2330 - val_loss: 1.1535\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.2244 - val_loss: 1.1482\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.2152 - val_loss: 1.1431\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.2063 - val_loss: 1.1362\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.1942 - val_loss: 1.1312\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.1854 - val_loss: 1.1256\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.1756 - val_loss: 1.1207\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1674 - val_loss: 1.1151\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1580 - val_loss: 1.1107\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1505 - val_loss: 1.1061\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.1419 - val_loss: 1.1007\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1329 - val_loss: 1.0968\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.1256 - val_loss: 1.0922\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 1.1177 - val_loss: 1.0880\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1109 - val_loss: 1.0844\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1044 - val_loss: 1.0801\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0969 - val_loss: 1.0759\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0896 - val_loss: 1.0723\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0833 - val_loss: 1.0686\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0765 - val_loss: 1.0652\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.0706 - val_loss: 1.0607\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0629 - val_loss: 1.0573\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0573 - val_loss: 1.0550\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0527 - val_loss: 1.0524\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.0475 - val_loss: 1.0490\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0418 - val_loss: 1.0462\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.0366 - val_loss: 1.0431\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0313 - val_loss: 1.0391\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0246 - val_loss: 1.0351\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0184 - val_loss: 1.0330\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0133 - val_loss: 1.0293\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0074 - val_loss: 1.0264\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0028 - val_loss: 1.0234\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9980 - val_loss: 1.0204\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9931 - val_loss: 1.0181\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9888 - val_loss: 1.0147\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9826 - val_loss: 1.0122\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9782 - val_loss: 1.0081\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9716 - val_loss: 1.0059\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9677 - val_loss: 1.0029\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.9629 - val_loss: 1.0010\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9592 - val_loss: 0.9988\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9550 - val_loss: 0.9953\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.9498 - val_loss: 0.9935\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.9461 - val_loss: 0.9907\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9412 - val_loss: 0.9882\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9372 - val_loss: 0.9856\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9329 - val_loss: 0.9834\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9293 - val_loss: 0.9818\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9259 - val_loss: 0.9796\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9222 - val_loss: 0.9778\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.9189 - val_loss: 0.9761\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9158 - val_loss: 0.9744\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9133 - val_loss: 0.9729\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9104 - val_loss: 0.9704\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9060 - val_loss: 0.9692\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9030 - val_loss: 0.9674\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9000 - val_loss: 0.9650\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8962 - val_loss: 0.9633\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8934 - val_loss: 0.9617\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8902 - val_loss: 0.9605\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8878 - val_loss: 0.9588\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8852 - val_loss: 0.9572\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 38us/sample - loss: 0.8823 - val_loss: 0.9558\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8799 - val_loss: 0.9540\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8769 - val_loss: 0.9522\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8741 - val_loss: 0.9510\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8722 - val_loss: 0.9493\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8698 - val_loss: 0.9482\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8679 - val_loss: 0.9475\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8659 - val_loss: 0.9464\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8637 - val_loss: 0.9448\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8616 - val_loss: 0.9437\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8595 - val_loss: 0.9432\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8577 - val_loss: 0.9419\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8557 - val_loss: 0.9414\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8540 - val_loss: 0.9403\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8517 - val_loss: 0.9392\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8493 - val_loss: 0.9379\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8473 - val_loss: 0.9366\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8449 - val_loss: 0.9358\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8431 - val_loss: 0.9347\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8410 - val_loss: 0.9341\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8396 - val_loss: 0.9337\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8379 - val_loss: 0.9325\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8362 - val_loss: 0.9316\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8344 - val_loss: 0.9307\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8330 - val_loss: 0.9293\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8310 - val_loss: 0.9285\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8296 - val_loss: 0.9277\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8279 - val_loss: 0.9269\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8265 - val_loss: 0.9258\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8246 - val_loss: 0.9251\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8233 - val_loss: 0.9246\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8219 - val_loss: 0.9233\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8199 - val_loss: 0.9221\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8178 - val_loss: 0.9215\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8163 - val_loss: 0.9205\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8153 - val_loss: 0.9201\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8144 - val_loss: 0.9198\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8131 - val_loss: 0.9196\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8120 - val_loss: 0.9191\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8111 - val_loss: 0.9182\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8099 - val_loss: 0.9181\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8092 - val_loss: 0.9176\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8083 - val_loss: 0.9172\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8075 - val_loss: 0.9173\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8068 - val_loss: 0.9167\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8057 - val_loss: 0.9165\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8051 - val_loss: 0.9158\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8040 - val_loss: 0.9152\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8030 - val_loss: 0.9148\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8022 - val_loss: 0.9144\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8014 - val_loss: 0.9142\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8007 - val_loss: 0.9138\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8000 - val_loss: 0.9129\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7990 - val_loss: 0.9124\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7981 - val_loss: 0.9117\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7971 - val_loss: 0.9112\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7963 - val_loss: 0.9112\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7958 - val_loss: 0.9115\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7952 - val_loss: 0.9107\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7941 - val_loss: 0.9110\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7937 - val_loss: 0.9105\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7929 - val_loss: 0.9098\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7922 - val_loss: 0.9097\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7916 - val_loss: 0.9092\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7908 - val_loss: 0.9088\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7898 - val_loss: 0.9086\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7892 - val_loss: 0.9084\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7887 - val_loss: 0.9085\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7881 - val_loss: 0.9084\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7878 - val_loss: 0.9086\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7870 - val_loss: 0.9085\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7862 - val_loss: 0.9084\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7855 - val_loss: 0.9084\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7852 - val_loss: 0.9081\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7844 - val_loss: 0.9075\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7836 - val_loss: 0.9069\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7827 - val_loss: 0.9067\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7823 - val_loss: 0.9068\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7817 - val_loss: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7810 - val_loss: 0.9062\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7803 - val_loss: 0.9060\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7797 - val_loss: 0.9057\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7792 - val_loss: 0.9056\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7786 - val_loss: 0.9052\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7781 - val_loss: 0.9056\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7775 - val_loss: 0.9054\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7773 - val_loss: 0.9050\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7767 - val_loss: 0.9050\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7761 - val_loss: 0.9048\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7758 - val_loss: 0.9049\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7755 - val_loss: 0.9047\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7750 - val_loss: 0.9048\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7748 - val_loss: 0.9045\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7742 - val_loss: 0.9044\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7737 - val_loss: 0.9042\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7734 - val_loss: 0.9037\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7729 - val_loss: 0.9030\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7723 - val_loss: 0.9029\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7720 - val_loss: 0.9030\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7716 - val_loss: 0.9033\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7713 - val_loss: 0.9032\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7710 - val_loss: 0.9030\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7708 - val_loss: 0.9026\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7704 - val_loss: 0.9030\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7703 - val_loss: 0.9029\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7700 - val_loss: 0.9032\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7698 - val_loss: 0.9028\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7695 - val_loss: 0.9027\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7693 - val_loss: 0.9029\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7691 - val_loss: 0.9028\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7689 - val_loss: 0.9025\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7685 - val_loss: 0.9024\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7682 - val_loss: 0.9021\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7680 - val_loss: 0.9019\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7675 - val_loss: 0.9018\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7675 - val_loss: 0.9013\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7669 - val_loss: 0.9016\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7667 - val_loss: 0.9012\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7662 - val_loss: 0.9012\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7662 - val_loss: 0.9010\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7661 - val_loss: 0.9011\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 31us/sample - loss: 0.7657 - val_loss: 0.9016\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7655 - val_loss: 0.9013\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7655 - val_loss: 0.9021\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7654 - val_loss: 0.9022\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7651 - val_loss: 0.9025\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7649 - val_loss: 0.9024\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7648 - val_loss: 0.9025\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7646 - val_loss: 0.9022\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7643 - val_loss: 0.9019\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7641 - val_loss: 0.9017\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7641 - val_loss: 0.9018\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7638 - val_loss: 0.9018\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7638 - val_loss: 0.9016\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7636 - val_loss: 0.9015\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7632 - val_loss: 0.9014\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7631 - val_loss: 0.9013\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7630 - val_loss: 0.9011\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7629 - val_loss: 0.9012\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7628 - val_loss: 0.9007\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7629 - val_loss: 0.9010\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7625 - val_loss: 0.9004\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7623 - val_loss: 0.9004\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7622 - val_loss: 0.9003\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7621 - val_loss: 0.9001\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7619 - val_loss: 0.9000\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7618 - val_loss: 0.8999\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7616 - val_loss: 0.8996\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7613 - val_loss: 0.8995\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7613 - val_loss: 0.9001\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7614 - val_loss: 0.9002\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7614 - val_loss: 0.8999\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7609 - val_loss: 0.8999\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7608 - val_loss: 0.8997\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7607 - val_loss: 0.9000\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7606 - val_loss: 0.8999\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7605 - val_loss: 0.8999\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7605 - val_loss: 0.9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7605 - val_loss: 0.9002\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7603 - val_loss: 0.9002\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7603 - val_loss: 0.9002\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7601 - val_loss: 0.9002\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7601 - val_loss: 0.9000\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7598 - val_loss: 0.8999\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7600 - val_loss: 0.8996\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7599 - val_loss: 0.8998\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7598 - val_loss: 0.9004\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7597 - val_loss: 0.9000\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7596 - val_loss: 0.8998\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7594 - val_loss: 0.9002\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7593 - val_loss: 0.9001\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7592 - val_loss: 0.9004\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7593 - val_loss: 0.9001\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7591 - val_loss: 0.9000\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7591 - val_loss: 0.8999\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7589 - val_loss: 0.8998\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7589 - val_loss: 0.8998\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7589 - val_loss: 0.8996\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7589 - val_loss: 0.8995\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7587 - val_loss: 0.8995\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7586 - val_loss: 0.8997\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7586 - val_loss: 0.8997\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7586 - val_loss: 0.8996\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7585 - val_loss: 0.8992\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7585 - val_loss: 0.8992\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7584 - val_loss: 0.8994\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7585 - val_loss: 0.8998\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7584 - val_loss: 0.8996\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7583 - val_loss: 0.8995\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7582 - val_loss: 0.8993\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7582 - val_loss: 0.8999\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7582 - val_loss: 0.8997\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7580 - val_loss: 0.9000\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7578 - val_loss: 0.8997\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7581 - val_loss: 0.8995\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7577 - val_loss: 0.8993\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7578 - val_loss: 0.8996\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7576 - val_loss: 0.9000\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7575 - val_loss: 0.9002\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7575 - val_loss: 0.9001\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7575 - val_loss: 0.9000\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7575 - val_loss: 0.9001\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7577 - val_loss: 0.9001\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7575 - val_loss: 0.8998\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7573 - val_loss: 0.9002\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7573 - val_loss: 0.9002\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7574 - val_loss: 0.9000\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7571 - val_loss: 0.9001\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.7572 - val_loss: 0.9003\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7572 - val_loss: 0.9006\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7572 - val_loss: 0.9003\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7571 - val_loss: 0.9005\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7571 - val_loss: 0.9004\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7571 - val_loss: 0.9004\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7569 - val_loss: 0.9003\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7569 - val_loss: 0.9001\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7571 - val_loss: 0.9002\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7569 - val_loss: 0.9004\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7569 - val_loss: 0.9007\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7569 - val_loss: 0.9008\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7568 - val_loss: 0.9016\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7568 - val_loss: 0.9015\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7568 - val_loss: 0.9014\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7569 - val_loss: 0.9021\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7568 - val_loss: 0.9018\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7567 - val_loss: 0.9020\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7568 - val_loss: 0.9017\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7566 - val_loss: 0.9016\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7567 - val_loss: 0.9017\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7566 - val_loss: 0.9014\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7567 - val_loss: 0.9021\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7566 - val_loss: 0.9019\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7566 - val_loss: 0.9018\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7566 - val_loss: 0.9013\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7566 - val_loss: 0.9012\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7566 - val_loss: 0.9016\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7567 - val_loss: 0.9020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7566 - val_loss: 0.9018\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7566 - val_loss: 0.9016\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7565 - val_loss: 0.9016\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7567 - val_loss: 0.9015\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7563 - val_loss: 0.9013\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7564 - val_loss: 0.9012\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7563 - val_loss: 0.9015\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7564 - val_loss: 0.9018\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7563 - val_loss: 0.9016\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7563 - val_loss: 0.9016\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7563 - val_loss: 0.9016\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7563 - val_loss: 0.9014\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7563 - val_loss: 0.9011\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7563 - val_loss: 0.9010\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7562 - val_loss: 0.9014\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7561 - val_loss: 0.9015\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9019\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7562 - val_loss: 0.9019\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7564 - val_loss: 0.9018\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7562 - val_loss: 0.9016\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9021\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7561 - val_loss: 0.9023\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7562 - val_loss: 0.9026\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9029\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7561 - val_loss: 0.9030\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7561 - val_loss: 0.9028\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7561 - val_loss: 0.9033\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7561 - val_loss: 0.9038\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.9037\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7562 - val_loss: 0.9042\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7562 - val_loss: 0.9041\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7562 - val_loss: 0.9038\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7561 - val_loss: 0.9039\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7563 - val_loss: 0.9039\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7563 - val_loss: 0.9038\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7562 - val_loss: 0.9040\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7561 - val_loss: 0.9042\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7563 - val_loss: 0.9041\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7562 - val_loss: 0.9043\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7562 - val_loss: 0.9046\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7565 - val_loss: 0.9043\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7561 - val_loss: 0.9043\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7563 - val_loss: 0.9041\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7561 - val_loss: 0.9041\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9040\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7561 - val_loss: 0.9037\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7562 - val_loss: 0.9035\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7561 - val_loss: 0.9039\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7560 - val_loss: 0.9037\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7561 - val_loss: 0.9035\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9035\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7560 - val_loss: 0.9036\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7561 - val_loss: 0.9033\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7559 - val_loss: 0.9033\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7559 - val_loss: 0.9032\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7560 - val_loss: 0.9031\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7559 - val_loss: 0.9030\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7559 - val_loss: 0.9034\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7559 - val_loss: 0.9037\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7558 - val_loss: 0.9040\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7558 - val_loss: 0.9037\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7559 - val_loss: 0.9037\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7558 - val_loss: 0.9038\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9040\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7559 - val_loss: 0.9041\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7558 - val_loss: 0.9045\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7558 - val_loss: 0.9043\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7558 - val_loss: 0.9044\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7559 - val_loss: 0.9042\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7558 - val_loss: 0.9040\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7558 - val_loss: 0.9040\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7558 - val_loss: 0.9044\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7559 - val_loss: 0.9041\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7557 - val_loss: 0.9040\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9041\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7558 - val_loss: 0.9037\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7559 - val_loss: 0.9038\n",
      "Epoch 474/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7559 - val_loss: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7558 - val_loss: 0.9033\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7559 - val_loss: 0.9034\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7558 - val_loss: 0.9034\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7559 - val_loss: 0.9030\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7558 - val_loss: 0.9028\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7557 - val_loss: 0.9031\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7556 - val_loss: 0.9031\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7556 - val_loss: 0.9029\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7556 - val_loss: 0.9030\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7559 - val_loss: 0.9031\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7556 - val_loss: 0.9034\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7556 - val_loss: 0.9033\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7557 - val_loss: 0.9035\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7556 - val_loss: 0.9039\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7557 - val_loss: 0.9041\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7556 - val_loss: 0.9041\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7557 - val_loss: 0.9040\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7557 - val_loss: 0.9041\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7556 - val_loss: 0.9040\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7556 - val_loss: 0.9039\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7557 - val_loss: 0.9041\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7556 - val_loss: 0.9042\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7556 - val_loss: 0.9040\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7556 - val_loss: 0.9037\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7559 - val_loss: 0.9035\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7556 - val_loss: 0.9038\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과대적합 해결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 969us/sample - loss: 15.4024 - val_loss: 10.5598\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 15.0822 - val_loss: 10.3638\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 14.7749 - val_loss: 10.1295\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 14.4251 - val_loss: 9.9410\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 14.1421 - val_loss: 9.7414\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 13.8375 - val_loss: 9.5612\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 13.5625 - val_loss: 9.3832\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 13.2972 - val_loss: 9.2054\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 13.0200 - val_loss: 9.0204\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 12.7439 - val_loss: 8.8543\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 12.4876 - val_loss: 8.6921\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 12.2349 - val_loss: 8.5357\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 11.9949 - val_loss: 8.3793\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 11.7636 - val_loss: 8.2292\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 11.5379 - val_loss: 8.0872\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 11.3169 - val_loss: 7.9427\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 11.0964 - val_loss: 7.7980\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 10.8707 - val_loss: 7.6478\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 10.6432 - val_loss: 7.5071\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 10.4271 - val_loss: 7.3693\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 10.2191 - val_loss: 7.2255\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 9.9984 - val_loss: 7.0996\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 9.8053 - val_loss: 6.9666\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 9.6081 - val_loss: 6.8481\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 9.4289 - val_loss: 6.7209\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 9.2371 - val_loss: 6.6030\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 9.0610 - val_loss: 6.4749\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 8.8699 - val_loss: 6.3550\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 8.6923 - val_loss: 6.2336\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 8.5106 - val_loss: 6.1195\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 8.3437 - val_loss: 6.0173\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 8.1881 - val_loss: 5.9104\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 8.0298 - val_loss: 5.8152\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 7.8855 - val_loss: 5.7141\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 7.7380 - val_loss: 5.6057\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 7.5801 - val_loss: 5.5083\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 7.4342 - val_loss: 5.4196\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 7.2977 - val_loss: 5.3212\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 7.1523 - val_loss: 5.2397\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 7.0297 - val_loss: 5.1505\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 6.8923 - val_loss: 5.0638\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 6.7587 - val_loss: 4.9750\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 6.6227 - val_loss: 4.8834\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 6.4809 - val_loss: 4.8023\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 6.3564 - val_loss: 4.7198\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 6.2288 - val_loss: 4.6409\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 6.1108 - val_loss: 4.5610\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 5.9933 - val_loss: 4.4795\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 5.8693 - val_loss: 4.4026\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 5.7533 - val_loss: 4.3326\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 5.6493 - val_loss: 4.2588\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 5.5428 - val_loss: 4.1909\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 5.4413 - val_loss: 4.1245\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 5.3427 - val_loss: 4.0595\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 5.2445 - val_loss: 3.9987\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 5.1536 - val_loss: 3.9378\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 5.0598 - val_loss: 3.8756\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 4.9644 - val_loss: 3.8108\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 4.8724 - val_loss: 3.7542\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 4.7848 - val_loss: 3.6919\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 4.6919 - val_loss: 3.6351\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 4.6061 - val_loss: 3.5808\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 4.5268 - val_loss: 3.5246\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 4.4435 - val_loss: 3.4656\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 4.3603 - val_loss: 3.4191\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 4.2905 - val_loss: 3.3618\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 4.2049 - val_loss: 3.3126\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 4.1304 - val_loss: 3.2633\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 4.0553 - val_loss: 3.2105\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 3.9777 - val_loss: 3.1630\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.9078 - val_loss: 3.1184\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.8421 - val_loss: 3.0767\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 3.7811 - val_loss: 3.0321\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.7158 - val_loss: 2.9873\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.6477 - val_loss: 2.9407\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 31us/sample - loss: 3.5777 - val_loss: 2.8980\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.5122 - val_loss: 2.8607\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 3.4552 - val_loss: 2.8191\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 3.3922 - val_loss: 2.7811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 3.3361 - val_loss: 2.7422\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 3.2794 - val_loss: 2.7034\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.2228 - val_loss: 2.6690\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 3.1723 - val_loss: 2.6341\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.1208 - val_loss: 2.5995\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.0703 - val_loss: 2.5631\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.0161 - val_loss: 2.5281\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.9674 - val_loss: 2.4963\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.9194 - val_loss: 2.4648\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.8744 - val_loss: 2.4311\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.8280 - val_loss: 2.3977\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.7812 - val_loss: 2.3659\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.7335 - val_loss: 2.3359\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.6910 - val_loss: 2.3090\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.6515 - val_loss: 2.2818\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.6121 - val_loss: 2.2532\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.5722 - val_loss: 2.2268\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 2.5348 - val_loss: 2.2004\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.4983 - val_loss: 2.1734\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.4604 - val_loss: 2.1465\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.4213 - val_loss: 2.1182\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.3812 - val_loss: 2.0934\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.3462 - val_loss: 2.0718\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 2.3156 - val_loss: 2.0524\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.2861 - val_loss: 2.0311\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.2540 - val_loss: 2.0114\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.2244 - val_loss: 1.9894\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.1918 - val_loss: 1.9676\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.1608 - val_loss: 1.9488\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.1325 - val_loss: 1.9272\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.1026 - val_loss: 1.9074\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.0751 - val_loss: 1.8901\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 2.0493 - val_loss: 1.8721\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.0231 - val_loss: 1.8549\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.9974 - val_loss: 1.8347\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.9687 - val_loss: 1.8176\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.9434 - val_loss: 1.7993\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.9173 - val_loss: 1.7782\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.8874 - val_loss: 1.7615\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.8633 - val_loss: 1.7428\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.8354 - val_loss: 1.7269\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.8121 - val_loss: 1.7117\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.7896 - val_loss: 1.6941\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.7657 - val_loss: 1.6766\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 1.7416 - val_loss: 1.6589\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.7189 - val_loss: 1.6454\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.6997 - val_loss: 1.6333\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.6825 - val_loss: 1.6206\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.6648 - val_loss: 1.6084\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.6468 - val_loss: 1.5966\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.6305 - val_loss: 1.5830\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.6122 - val_loss: 1.5710\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.5959 - val_loss: 1.5616\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.5821 - val_loss: 1.5512\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5667 - val_loss: 1.5410\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.5518 - val_loss: 1.5291\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.5347 - val_loss: 1.5190\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.5202 - val_loss: 1.5075\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.5038 - val_loss: 1.4964\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.4881 - val_loss: 1.4858\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.4737 - val_loss: 1.4749\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.4588 - val_loss: 1.4662\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.4455 - val_loss: 1.4571\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.4322 - val_loss: 1.4449\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.4166 - val_loss: 1.4332\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.4012 - val_loss: 1.4247\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3893 - val_loss: 1.4153\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3762 - val_loss: 1.4067\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.3635 - val_loss: 1.3965\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.3498 - val_loss: 1.3876\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.3369 - val_loss: 1.3798\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.3257 - val_loss: 1.3712\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.3134 - val_loss: 1.3627\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.3018 - val_loss: 1.3545\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.2902 - val_loss: 1.3471\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.2796 - val_loss: 1.3409\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2707 - val_loss: 1.3344\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.2607 - val_loss: 1.3260\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.2492 - val_loss: 1.3186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.2392 - val_loss: 1.3108\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.2289 - val_loss: 1.3032\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.2191 - val_loss: 1.2960\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2100 - val_loss: 1.2895\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.2011 - val_loss: 1.2828\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1924 - val_loss: 1.2752\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.1830 - val_loss: 1.2684\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1743 - val_loss: 1.2611\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.1648 - val_loss: 1.2566\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1579 - val_loss: 1.2493\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1486 - val_loss: 1.2446\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.1414 - val_loss: 1.2385\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1333 - val_loss: 1.2320\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1246 - val_loss: 1.2262\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 1.1169 - val_loss: 1.2216\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.1099 - val_loss: 1.2163\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.1029 - val_loss: 1.2108\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.0960 - val_loss: 1.2061\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.0898 - val_loss: 1.1999\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0824 - val_loss: 1.1944\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.0753 - val_loss: 1.1883\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0685 - val_loss: 1.1845\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0635 - val_loss: 1.1802\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.0573 - val_loss: 1.1741\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0500 - val_loss: 1.1695\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.0444 - val_loss: 1.1653\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.0391 - val_loss: 1.1616\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0341 - val_loss: 1.1570\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0283 - val_loss: 1.1534\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.0236 - val_loss: 1.1490\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0181 - val_loss: 1.1454\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0134 - val_loss: 1.1422\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0090 - val_loss: 1.1378\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0035 - val_loss: 1.1345\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9989 - val_loss: 1.1303\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9942 - val_loss: 1.1267\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9899 - val_loss: 1.1236\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9857 - val_loss: 1.1205\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9817 - val_loss: 1.1172\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9771 - val_loss: 1.1139\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9732 - val_loss: 1.1107\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9693 - val_loss: 1.1085\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9659 - val_loss: 1.1045\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9616 - val_loss: 1.1013\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9576 - val_loss: 1.0983\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9543 - val_loss: 1.0962\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9514 - val_loss: 1.0936\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9479 - val_loss: 1.0908\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9446 - val_loss: 1.0878\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9411 - val_loss: 1.0842\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9371 - val_loss: 1.0820\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9341 - val_loss: 1.0791\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9305 - val_loss: 1.0757\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9262 - val_loss: 1.0728\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9231 - val_loss: 1.0703\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9194 - val_loss: 1.0678\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9164 - val_loss: 1.0647\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9131 - val_loss: 1.0630\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9106 - val_loss: 1.0605\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9079 - val_loss: 1.0584\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.9050 - val_loss: 1.0569\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.9027 - val_loss: 1.0538\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8998 - val_loss: 1.0515\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8972 - val_loss: 1.0491\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8944 - val_loss: 1.0475\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8917 - val_loss: 1.0455\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8894 - val_loss: 1.0433\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8867 - val_loss: 1.0414\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8844 - val_loss: 1.0394\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8818 - val_loss: 1.0376\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8800 - val_loss: 1.0358\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8777 - val_loss: 1.0344\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8759 - val_loss: 1.0320\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8731 - val_loss: 1.0299\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8706 - val_loss: 1.0280\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8687 - val_loss: 1.0271\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8673 - val_loss: 1.0257\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8653 - val_loss: 1.0244\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8640 - val_loss: 1.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8625 - val_loss: 1.0224\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8608 - val_loss: 1.0207\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8589 - val_loss: 1.0186\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.8566 - val_loss: 1.0166\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8546 - val_loss: 1.0148\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8527 - val_loss: 1.0133\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8511 - val_loss: 1.0120\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8499 - val_loss: 1.0107\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8482 - val_loss: 1.0088\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8465 - val_loss: 1.0069\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8443 - val_loss: 1.0055\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8428 - val_loss: 1.0048\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8417 - val_loss: 1.0039\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8402 - val_loss: 1.0024\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8385 - val_loss: 1.0016\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8375 - val_loss: 1.0003\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8360 - val_loss: 0.9990\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8348 - val_loss: 0.9980\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8339 - val_loss: 0.9965\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8323 - val_loss: 0.9954\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8310 - val_loss: 0.9946\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8300 - val_loss: 0.9929\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8287 - val_loss: 0.9909\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8272 - val_loss: 0.9898\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8263 - val_loss: 0.9892\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8254 - val_loss: 0.9876\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8241 - val_loss: 0.9871\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8235 - val_loss: 0.9862\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8226 - val_loss: 0.9861\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8220 - val_loss: 0.9853\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8212 - val_loss: 0.9844\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8202 - val_loss: 0.9846\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8196 - val_loss: 0.9835\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8185 - val_loss: 0.9835\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8182 - val_loss: 0.9823\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8169 - val_loss: 0.9818\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8164 - val_loss: 0.9815\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8158 - val_loss: 0.9805\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8149 - val_loss: 0.9799\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8142 - val_loss: 0.9789\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8131 - val_loss: 0.9781\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8125 - val_loss: 0.9769\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8116 - val_loss: 0.9768\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8111 - val_loss: 0.9759\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8105 - val_loss: 0.9758\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8098 - val_loss: 0.9754\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8093 - val_loss: 0.9758\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8091 - val_loss: 0.9747\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8086 - val_loss: 0.9738\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8080 - val_loss: 0.9738\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8076 - val_loss: 0.9733\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8069 - val_loss: 0.9726\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8063 - val_loss: 0.9718\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8056 - val_loss: 0.9707\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8047 - val_loss: 0.9693\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8037 - val_loss: 0.9687\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8033 - val_loss: 0.9681\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8026 - val_loss: 0.9670\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8020 - val_loss: 0.9664\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8015 - val_loss: 0.9666\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8011 - val_loss: 0.9656\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8003 - val_loss: 0.9644\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7996 - val_loss: 0.9641\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7993 - val_loss: 0.9633\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7986 - val_loss: 0.9625\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7980 - val_loss: 0.9622\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7977 - val_loss: 0.9620\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7974 - val_loss: 0.9618\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7971 - val_loss: 0.9614\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7964 - val_loss: 0.9607\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7960 - val_loss: 0.9603\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7956 - val_loss: 0.9593\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7951 - val_loss: 0.9592\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7950 - val_loss: 0.9589\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7949 - val_loss: 0.9585\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7949 - val_loss: 0.9581\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7943 - val_loss: 0.9578\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7941 - val_loss: 0.9578\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7940 - val_loss: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7940 - val_loss: 0.9581\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7938 - val_loss: 0.9577\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7935 - val_loss: 0.9563\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7926 - val_loss: 0.9557\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7922 - val_loss: 0.9554\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7918 - val_loss: 0.9551\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7917 - val_loss: 0.9553\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7915 - val_loss: 0.9550\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7913 - val_loss: 0.9547\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7912 - val_loss: 0.9552\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7910 - val_loss: 0.9546\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7906 - val_loss: 0.9542\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7902 - val_loss: 0.9538\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7901 - val_loss: 0.9538\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7900 - val_loss: 0.9538\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7899 - val_loss: 0.9537\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7897 - val_loss: 0.9535\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7896 - val_loss: 0.9531\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7892 - val_loss: 0.9527\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7891 - val_loss: 0.9525\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7890 - val_loss: 0.9525\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7889 - val_loss: 0.9522\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7884 - val_loss: 0.9518\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7883 - val_loss: 0.9511\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7881 - val_loss: 0.9509\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7879 - val_loss: 0.9503\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7877 - val_loss: 0.9496\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7875 - val_loss: 0.9498\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7873 - val_loss: 0.9496\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7870 - val_loss: 0.9496\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7869 - val_loss: 0.9495\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7867 - val_loss: 0.9494\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7869 - val_loss: 0.9494\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7867 - val_loss: 0.9496\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7868 - val_loss: 0.9493\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7866 - val_loss: 0.9495\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7865 - val_loss: 0.9492\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7864 - val_loss: 0.9488\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7862 - val_loss: 0.9482\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7859 - val_loss: 0.9482\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7859 - val_loss: 0.9476\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7859 - val_loss: 0.9480\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7858 - val_loss: 0.9483\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7859 - val_loss: 0.9479\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7857 - val_loss: 0.9475\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7856 - val_loss: 0.9468\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7854 - val_loss: 0.9463\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7852 - val_loss: 0.9456\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7848 - val_loss: 0.9448\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7846 - val_loss: 0.9446\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7846 - val_loss: 0.9442\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7843 - val_loss: 0.9439\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7842 - val_loss: 0.9438\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7842 - val_loss: 0.9438\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7840 - val_loss: 0.9439\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7839 - val_loss: 0.9434\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7840 - val_loss: 0.9433\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7838 - val_loss: 0.9433\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7837 - val_loss: 0.9432\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7835 - val_loss: 0.9428\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7833 - val_loss: 0.9424\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7831 - val_loss: 0.9425\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7832 - val_loss: 0.9423\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7832 - val_loss: 0.9422\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7830 - val_loss: 0.9419\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7830 - val_loss: 0.9417\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7830 - val_loss: 0.9416\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7829 - val_loss: 0.9416\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7829 - val_loss: 0.9417\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7829 - val_loss: 0.9414\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7827 - val_loss: 0.9415\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7826 - val_loss: 0.9409\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7825 - val_loss: 0.9408\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7826 - val_loss: 0.9408\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7824 - val_loss: 0.9401\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7823 - val_loss: 0.9401\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7822 - val_loss: 0.9400\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7822 - val_loss: 0.9396\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7822 - val_loss: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7822 - val_loss: 0.9394\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7822 - val_loss: 0.9391\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7823 - val_loss: 0.9390\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7820 - val_loss: 0.9393\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7820 - val_loss: 0.9392\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7822 - val_loss: 0.9384\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7819 - val_loss: 0.9384\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7816 - val_loss: 0.9383\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7815 - val_loss: 0.9381\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7817 - val_loss: 0.9381\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7816 - val_loss: 0.9375\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7814 - val_loss: 0.9377\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7814 - val_loss: 0.9377\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7813 - val_loss: 0.9378\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7814 - val_loss: 0.9373\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7813 - val_loss: 0.9376\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7812 - val_loss: 0.9375\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7812 - val_loss: 0.9373\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7812 - val_loss: 0.9369\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7811 - val_loss: 0.9364\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7809 - val_loss: 0.9371\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7811 - val_loss: 0.9370\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7810 - val_loss: 0.9369\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7810 - val_loss: 0.9370\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7809 - val_loss: 0.9372\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7809 - val_loss: 0.9373\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7808 - val_loss: 0.9374\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7809 - val_loss: 0.9376\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.7808 - val_loss: 0.9378\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7808 - val_loss: 0.9377\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7808 - val_loss: 0.9369\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7808 - val_loss: 0.9370\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7806 - val_loss: 0.9366\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7806 - val_loss: 0.9362\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7805 - val_loss: 0.9364\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7805 - val_loss: 0.9366\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7806 - val_loss: 0.9366\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7805 - val_loss: 0.9364\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7805 - val_loss: 0.9366\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7805 - val_loss: 0.9366\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7804 - val_loss: 0.9369\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7805 - val_loss: 0.9371\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7804 - val_loss: 0.9370\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7803 - val_loss: 0.9365\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7803 - val_loss: 0.9366\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7803 - val_loss: 0.9365\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7802 - val_loss: 0.9368\n",
      "Epoch 443/500\n",
      "105/105==============================] - ETA: 0s - loss: 0.634 - 0s 35us/sample - loss: 0.7801 - val_loss: 0.9365\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7802 - val_loss: 0.9361\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7800 - val_loss: 0.9362\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7802 - val_loss: 0.9362\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7800 - val_loss: 0.9365\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7801 - val_loss: 0.9364\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7800 - val_loss: 0.9361\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7804 - val_loss: 0.9358\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7800 - val_loss: 0.9358\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7799 - val_loss: 0.9355\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.7799 - val_loss: 0.9355\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7799 - val_loss: 0.9354\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7800 - val_loss: 0.9358\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7799 - val_loss: 0.9358\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7799 - val_loss: 0.9357\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7799 - val_loss: 0.9359\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7800 - val_loss: 0.9366\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7800 - val_loss: 0.9365\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7799 - val_loss: 0.9365\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7799 - val_loss: 0.9365\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7799 - val_loss: 0.9365\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7799 - val_loss: 0.9362\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7799 - val_loss: 0.9360\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7799 - val_loss: 0.9358\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7798 - val_loss: 0.9359\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7798 - val_loss: 0.9358\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7797 - val_loss: 0.9356\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7797 - val_loss: 0.9356\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7798 - val_loss: 0.9357\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7797 - val_loss: 0.9357\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7798 - val_loss: 0.9354\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 40us/sample - loss: 0.7796 - val_loss: 0.9351\n",
      "Epoch 475/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7797 - val_loss: 0.9349\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7797 - val_loss: 0.9347\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7796 - val_loss: 0.9348\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7798 - val_loss: 0.9347\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7796 - val_loss: 0.9345\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7796 - val_loss: 0.9347\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9347\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7796 - val_loss: 0.9348\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9344\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7796 - val_loss: 0.9343\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7797 - val_loss: 0.9343\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7795 - val_loss: 0.9343\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7796 - val_loss: 0.9342\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7795 - val_loss: 0.9342\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7796 - val_loss: 0.9340\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7797 - val_loss: 0.9340\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7796 - val_loss: 0.9342\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7796 - val_loss: 0.9345\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9340\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7797 - val_loss: 0.9346\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7797 - val_loss: 0.9344\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7796 - val_loss: 0.9344\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9346\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7798 - val_loss: 0.9350\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9351\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7796 - val_loss: 0.9349\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 1ms/sample - loss: 8.0516 - val_loss: 5.3857\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 7.9011 - val_loss: 5.2859\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 7.7406 - val_loss: 5.1954\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 7.5969 - val_loss: 5.1100\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 7.4590 - val_loss: 5.0182\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 7.3115 - val_loss: 4.9367\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 7.1809 - val_loss: 4.8442\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 7.0322 - val_loss: 4.7708\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 6.9121 - val_loss: 4.6902\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 6.7824 - val_loss: 4.6160\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 6.6585 - val_loss: 4.5345\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 6.5289 - val_loss: 4.4578\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 6.4028 - val_loss: 4.3894\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 6.2913 - val_loss: 4.3103\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 6.1608 - val_loss: 4.2349\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 6.0378 - val_loss: 4.1641\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 5.9239 - val_loss: 4.0911\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 5.8070 - val_loss: 4.0278\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 5.7017 - val_loss: 3.9587\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 5.5908 - val_loss: 3.9004\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 5.4955 - val_loss: 3.8434\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 5.4004 - val_loss: 3.7783\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 5.2941 - val_loss: 3.7219\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 5.2048 - val_loss: 3.6681\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 5.1158 - val_loss: 3.6084\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 5.0204 - val_loss: 3.5555\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 4.9353 - val_loss: 3.5028\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 4.8520 - val_loss: 3.4528\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 4.7691 - val_loss: 3.3949\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 4.6764 - val_loss: 3.3425\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 4.5925 - val_loss: 3.2947\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 4.5167 - val_loss: 3.2429\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 4.4342 - val_loss: 3.1990\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 4.3612 - val_loss: 3.1471\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 4.2792 - val_loss: 3.1001\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 4.2027 - val_loss: 3.0607\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 4.1380 - val_loss: 3.0204\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 4.0705 - val_loss: 2.9741\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.9962 - val_loss: 2.9301\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 3.9248 - val_loss: 2.8919\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 3.8625 - val_loss: 2.8499\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 3.7941 - val_loss: 2.8092\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 3.7292 - val_loss: 2.7674\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.6611 - val_loss: 2.7298\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 3.5998 - val_loss: 2.6931\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 3.5402 - val_loss: 2.6541\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 3.4773 - val_loss: 2.6156\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 3.4146 - val_loss: 2.5751\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 3.3491 - val_loss: 2.5390\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 3.2906 - val_loss: 2.5042\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 3.2341 - val_loss: 2.4751\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 3.1852 - val_loss: 2.4402\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.1299 - val_loss: 2.4042\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.0753 - val_loss: 2.3691\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 3.0195 - val_loss: 2.3399\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.9731 - val_loss: 2.3099\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.9248 - val_loss: 2.2827\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.8814 - val_loss: 2.2568\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 2.8403 - val_loss: 2.2329\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.8005 - val_loss: 2.2048\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.7573 - val_loss: 2.1805\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.7175 - val_loss: 2.1513\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 2.6697 - val_loss: 2.1211\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.6224 - val_loss: 2.0992\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 2.5868 - val_loss: 2.0774\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.5523 - val_loss: 2.0571\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.5193 - val_loss: 2.0359\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.4860 - val_loss: 2.0116\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.4486 - val_loss: 1.9880\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.4104 - val_loss: 1.9661\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.3749 - val_loss: 1.9434\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.3402 - val_loss: 1.9198\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.3046 - val_loss: 1.8986\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 2.2700 - val_loss: 1.8768\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 2.2373 - val_loss: 1.8560\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.2047 - val_loss: 1.8347\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 2.1702 - val_loss: 1.8152\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.1385 - val_loss: 1.7961\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.1082 - val_loss: 1.7798\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 36us/sample - loss: 2.0821 - val_loss: 1.7611\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 2.0528 - val_loss: 1.7451\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.0264 - val_loss: 1.7267\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.9970 - val_loss: 1.7097\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.9702 - val_loss: 1.6944\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.9461 - val_loss: 1.6787\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.9201 - val_loss: 1.6624\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.8942 - val_loss: 1.6494\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.8723 - val_loss: 1.6345\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.8496 - val_loss: 1.6220\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.8290 - val_loss: 1.6080\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.8070 - val_loss: 1.5948\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.7857 - val_loss: 1.5806\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.7641 - val_loss: 1.5666\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.7428 - val_loss: 1.5531\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.7226 - val_loss: 1.5418\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.7038 - val_loss: 1.5287\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.6840 - val_loss: 1.5186\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.6674 - val_loss: 1.5073\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.6488 - val_loss: 1.4953\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.6304 - val_loss: 1.4857\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.6140 - val_loss: 1.4717\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.5931 - val_loss: 1.4616\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.5770 - val_loss: 1.4498\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.5584 - val_loss: 1.4397\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5427 - val_loss: 1.4284\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.5258 - val_loss: 1.4175\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.5089 - val_loss: 1.4083\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.4948 - val_loss: 1.3971\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.4770 - val_loss: 1.3865\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.4609 - val_loss: 1.3780\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.4470 - val_loss: 1.3707\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.4351 - val_loss: 1.3622\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.4209 - val_loss: 1.3522\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.4054 - val_loss: 1.3445\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3933 - val_loss: 1.3376\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.3813 - val_loss: 1.3300\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.3693 - val_loss: 1.3230\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.3578 - val_loss: 1.3155\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.3455 - val_loss: 1.3079\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.3331 - val_loss: 1.2995\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.3207 - val_loss: 1.2922\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.3097 - val_loss: 1.2840\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 1.2974 - val_loss: 1.2763\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2853 - val_loss: 1.2689\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.2745 - val_loss: 1.2626\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.2648 - val_loss: 1.2557\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2546 - val_loss: 1.2500\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 1.2454 - val_loss: 1.2443\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2359 - val_loss: 1.2386\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.2269 - val_loss: 1.2322\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.2176 - val_loss: 1.2263\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.2082 - val_loss: 1.2215\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.2003 - val_loss: 1.2170\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.1925 - val_loss: 1.2118\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.1850 - val_loss: 1.2063\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1769 - val_loss: 1.2013\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1690 - val_loss: 1.1964\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1611 - val_loss: 1.1906\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.1532 - val_loss: 1.1850\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 1.1450 - val_loss: 1.1806\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.1381 - val_loss: 1.1755\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.1304 - val_loss: 1.1694\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.1209 - val_loss: 1.1648\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.1136 - val_loss: 1.1585\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 1.1049 - val_loss: 1.1535\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.0981 - val_loss: 1.1494\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.0920 - val_loss: 1.1461\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 1.0869 - val_loss: 1.1429\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.0807 - val_loss: 1.1379\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 1.0736 - val_loss: 1.1344\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0678 - val_loss: 1.1304\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0615 - val_loss: 1.1261\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0549 - val_loss: 1.1219\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 1.0489 - val_loss: 1.1178\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.0432 - val_loss: 1.1144\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.0381 - val_loss: 1.1110\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0333 - val_loss: 1.1081\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0288 - val_loss: 1.1041\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 41us/sample - loss: 1.0228 - val_loss: 1.1009\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.0182 - val_loss: 1.0972\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0122 - val_loss: 1.0942\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0073 - val_loss: 1.0918\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0032 - val_loss: 1.0886\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9987 - val_loss: 1.0858\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9947 - val_loss: 1.0832\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9906 - val_loss: 1.0809\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9871 - val_loss: 1.0781\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.9831 - val_loss: 1.0749\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9786 - val_loss: 1.0721\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.9741 - val_loss: 1.0694\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9703 - val_loss: 1.0661\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9659 - val_loss: 1.0629\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.9612 - val_loss: 1.0603\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9572 - val_loss: 1.0574\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9533 - val_loss: 1.0553\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.9500 - val_loss: 1.0525\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9462 - val_loss: 1.0503\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9433 - val_loss: 1.0483\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9402 - val_loss: 1.0459\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9367 - val_loss: 1.0440\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9341 - val_loss: 1.0421\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9312 - val_loss: 1.0400\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9284 - val_loss: 1.0376\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9251 - val_loss: 1.0348\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9215 - val_loss: 1.0333\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9187 - val_loss: 1.0315\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.9157 - val_loss: 1.0292\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.9127 - val_loss: 1.0282\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9105 - val_loss: 1.0259\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9077 - val_loss: 1.0231\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9043 - val_loss: 1.0214\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.9018 - val_loss: 1.0205\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8998 - val_loss: 1.0186\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8972 - val_loss: 1.0159\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8935 - val_loss: 1.0142\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8913 - val_loss: 1.0119\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8884 - val_loss: 1.0102\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8859 - val_loss: 1.0092\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8841 - val_loss: 1.0077\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8819 - val_loss: 1.0052\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8791 - val_loss: 1.0038\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8770 - val_loss: 1.0027\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8753 - val_loss: 1.0010\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8732 - val_loss: 0.9990\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8705 - val_loss: 0.9980\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8687 - val_loss: 0.9967\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8672 - val_loss: 0.9951\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8646 - val_loss: 0.9936\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8626 - val_loss: 0.9920\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8607 - val_loss: 0.9911\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8592 - val_loss: 0.9901\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8580 - val_loss: 0.9892\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8565 - val_loss: 0.9883\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8552 - val_loss: 0.9865\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8528 - val_loss: 0.9855\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8514 - val_loss: 0.9848\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8504 - val_loss: 0.9838\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 33us/sample - loss: 0.8488 - val_loss: 0.9829\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8474 - val_loss: 0.9815\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8456 - val_loss: 0.9803\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8443 - val_loss: 0.9790\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8430 - val_loss: 0.9779\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.8413 - val_loss: 0.9766\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8398 - val_loss: 0.9752\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8381 - val_loss: 0.9742\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8366 - val_loss: 0.9737\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8359 - val_loss: 0.9728\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8347 - val_loss: 0.9725\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8338 - val_loss: 0.9716\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8329 - val_loss: 0.9710\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8319 - val_loss: 0.9704\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8307 - val_loss: 0.9695\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8297 - val_loss: 0.9686\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8289 - val_loss: 0.9680\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8279 - val_loss: 0.9672\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8271 - val_loss: 0.9662\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8261 - val_loss: 0.9654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8249 - val_loss: 0.9650\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8241 - val_loss: 0.9644\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8231 - val_loss: 0.9635\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8220 - val_loss: 0.9634\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8217 - val_loss: 0.9628\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8208 - val_loss: 0.9623\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8200 - val_loss: 0.9618\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8191 - val_loss: 0.9610\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.8182 - val_loss: 0.9602\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8176 - val_loss: 0.9595\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8165 - val_loss: 0.9586\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8156 - val_loss: 0.9578\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8152 - val_loss: 0.9574\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8143 - val_loss: 0.9571\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8139 - val_loss: 0.9565\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8132 - val_loss: 0.9559\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8125 - val_loss: 0.9555\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8120 - val_loss: 0.9552\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8113 - val_loss: 0.9555\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.8107 - val_loss: 0.9552\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8103 - val_loss: 0.9548\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8096 - val_loss: 0.9539\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8089 - val_loss: 0.9529\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8082 - val_loss: 0.9528\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8076 - val_loss: 0.9523\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 32us/sample - loss: 0.8069 - val_loss: 0.9516\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8062 - val_loss: 0.9515\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8060 - val_loss: 0.9517\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8055 - val_loss: 0.9509\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8048 - val_loss: 0.9504\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8041 - val_loss: 0.9497\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8036 - val_loss: 0.9493\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8031 - val_loss: 0.9489\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8027 - val_loss: 0.9486\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8024 - val_loss: 0.9483\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.8019 - val_loss: 0.9484\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8016 - val_loss: 0.9484\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8012 - val_loss: 0.9478\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8009 - val_loss: 0.9476\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.8003 - val_loss: 0.9474\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8000 - val_loss: 0.9472\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7996 - val_loss: 0.9472\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7993 - val_loss: 0.9465\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7989 - val_loss: 0.9461\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 35us/sample - loss: 0.7985 - val_loss: 0.9465\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7984 - val_loss: 0.9458\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 34us/sample - loss: 0.7977 - val_loss: 0.9454\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7973 - val_loss: 0.9454\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7970 - val_loss: 0.9447\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7964 - val_loss: 0.9452\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7961 - val_loss: 0.9451\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7959 - val_loss: 0.9451\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7959 - val_loss: 0.9452\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7953 - val_loss: 0.9448\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_list = [EarlyStopping(patience=5)]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "model.load_weights('simple_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50==============================] - 0s 919us/sample - loss: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9540133500099182"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50==============================] - 0s 998us/sample - loss: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9540133500099182"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('simple_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/500\n",
      "120/120==============================] - 0s 1ms/sample - loss: 1.9541 - val_loss: 1.2799\n",
      "Epoch 2/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.9346 - val_loss: 1.2692\n",
      "Epoch 3/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.9152 - val_loss: 1.2583\n",
      "Epoch 4/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.8950 - val_loss: 1.2479\n",
      "Epoch 5/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.8755 - val_loss: 1.2377\n",
      "Epoch 6/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.8570 - val_loss: 1.2278\n",
      "Epoch 7/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 1.8389 - val_loss: 1.2180\n",
      "Epoch 8/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.8211 - val_loss: 1.2084\n",
      "Epoch 9/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.8034 - val_loss: 1.1990\n",
      "Epoch 10/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.7860 - val_loss: 1.1896\n",
      "Epoch 11/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.7686 - val_loss: 1.1805\n",
      "Epoch 12/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.7518 - val_loss: 1.1716\n",
      "Epoch 13/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.7354 - val_loss: 1.1629\n",
      "Epoch 14/500\n",
      "120/120==============================] - 0s 52us/sample - loss: 1.7194 - val_loss: 1.1546\n",
      "Epoch 15/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 1.7039 - val_loss: 1.1462\n",
      "Epoch 16/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.6882 - val_loss: 1.1380\n",
      "Epoch 17/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.6732 - val_loss: 1.1300\n",
      "Epoch 18/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.6583 - val_loss: 1.1222\n",
      "Epoch 19/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.6433 - val_loss: 1.1145\n",
      "Epoch 20/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.6286 - val_loss: 1.1068\n",
      "Epoch 21/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.6141 - val_loss: 1.0995\n",
      "Epoch 22/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.6003 - val_loss: 1.0924\n",
      "Epoch 23/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.5864 - val_loss: 1.0853\n",
      "Epoch 24/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.5726 - val_loss: 1.0782\n",
      "Epoch 25/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.5591 - val_loss: 1.0715\n",
      "Epoch 26/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.5463 - val_loss: 1.0648\n",
      "Epoch 27/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 1.5333 - val_loss: 1.0582\n",
      "Epoch 28/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.5204 - val_loss: 1.0517\n",
      "Epoch 29/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.5078 - val_loss: 1.0455\n",
      "Epoch 30/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.4955 - val_loss: 1.0393\n",
      "Epoch 31/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 1.4836 - val_loss: 1.0334\n",
      "Epoch 32/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.4716 - val_loss: 1.0275\n",
      "Epoch 33/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.4599 - val_loss: 1.0218\n",
      "Epoch 34/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.4484 - val_loss: 1.0160\n",
      "Epoch 35/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.4370 - val_loss: 1.0106\n",
      "Epoch 36/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.4262 - val_loss: 1.0051\n",
      "Epoch 37/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.4152 - val_loss: 0.9998\n",
      "Epoch 38/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.4047 - val_loss: 0.9946\n",
      "Epoch 39/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.3942 - val_loss: 0.9895\n",
      "Epoch 40/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.3839 - val_loss: 0.9846\n",
      "Epoch 41/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.3738 - val_loss: 0.9797\n",
      "Epoch 42/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.3641 - val_loss: 0.9748\n",
      "Epoch 43/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.3544 - val_loss: 0.9703\n",
      "Epoch 44/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 1.3448 - val_loss: 0.9658\n",
      "Epoch 45/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.3354 - val_loss: 0.9613\n",
      "Epoch 46/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.3263 - val_loss: 0.9570\n",
      "Epoch 47/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 1.3174 - val_loss: 0.9527\n",
      "Epoch 48/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.3084 - val_loss: 0.9484\n",
      "Epoch 49/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.2995 - val_loss: 0.9444\n",
      "Epoch 50/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.2910 - val_loss: 0.9404\n",
      "Epoch 51/500\n",
      "120/120==============================] - 0s 72us/sample - loss: 1.2825 - val_loss: 0.9367\n",
      "Epoch 52/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.2745 - val_loss: 0.9328\n",
      "Epoch 53/500\n",
      "120/120==============================] - 0s 71us/sample - loss: 1.2657 - val_loss: 0.9289\n",
      "Epoch 54/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 1.2577 - val_loss: 0.9251\n",
      "Epoch 55/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.2496 - val_loss: 0.9215\n",
      "Epoch 56/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.2418 - val_loss: 0.9179\n",
      "Epoch 57/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.2341 - val_loss: 0.9145\n",
      "Epoch 58/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.2266 - val_loss: 0.9112\n",
      "Epoch 59/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.2195 - val_loss: 0.9079\n",
      "Epoch 60/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.2124 - val_loss: 0.9047\n",
      "Epoch 61/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.2052 - val_loss: 0.9016\n",
      "Epoch 62/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.1982 - val_loss: 0.8986\n",
      "Epoch 63/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.1911 - val_loss: 0.8955\n",
      "Epoch 64/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.1842 - val_loss: 0.8927\n",
      "Epoch 65/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.1777 - val_loss: 0.8898\n",
      "Epoch 66/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.1712 - val_loss: 0.8870\n",
      "Epoch 67/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.1648 - val_loss: 0.8843\n",
      "Epoch 68/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.1585 - val_loss: 0.8815\n",
      "Epoch 69/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.1524 - val_loss: 0.8790\n",
      "Epoch 70/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.1462 - val_loss: 0.8765\n",
      "Epoch 71/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 1.1401 - val_loss: 0.8739\n",
      "Epoch 72/500\n",
      "120/120==============================] - ETA: 0s - loss: 1.092 - 0s 62us/sample - loss: 1.1341 - val_loss: 0.8716\n",
      "Epoch 73/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 1.1286 - val_loss: 0.8692\n",
      "Epoch 74/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 1.1231 - val_loss: 0.8670\n",
      "Epoch 75/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.1176 - val_loss: 0.8647\n",
      "Epoch 76/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.1120 - val_loss: 0.8625\n",
      "Epoch 77/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.1067 - val_loss: 0.8603\n",
      "Epoch 78/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 1.1013 - val_loss: 0.8582\n",
      "Epoch 79/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0959 - val_loss: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0905 - val_loss: 0.8539\n",
      "Epoch 81/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 1.0854 - val_loss: 0.8519\n",
      "Epoch 82/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.0803 - val_loss: 0.8500\n",
      "Epoch 83/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.0753 - val_loss: 0.8481\n",
      "Epoch 84/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 1.0705 - val_loss: 0.8462\n",
      "Epoch 85/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.0659 - val_loss: 0.8444\n",
      "Epoch 86/500\n",
      "120/120==============================] - 0s 75us/sample - loss: 1.0613 - val_loss: 0.8426\n",
      "Epoch 87/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0566 - val_loss: 0.8409\n",
      "Epoch 88/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.0521 - val_loss: 0.8391\n",
      "Epoch 89/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.0476 - val_loss: 0.8374\n",
      "Epoch 90/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 1.0433 - val_loss: 0.8359\n",
      "Epoch 91/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.0391 - val_loss: 0.8343\n",
      "Epoch 92/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 1.0351 - val_loss: 0.8328\n",
      "Epoch 93/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.0308 - val_loss: 0.8313\n",
      "Epoch 94/500\n",
      "120/120==============================] - 0s 68us/sample - loss: 1.0268 - val_loss: 0.8300\n",
      "Epoch 95/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.0229 - val_loss: 0.8285\n",
      "Epoch 96/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 1.0191 - val_loss: 0.8272\n",
      "Epoch 97/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 1.0152 - val_loss: 0.8259\n",
      "Epoch 98/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 1.0115 - val_loss: 0.8246\n",
      "Epoch 99/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 1.0079 - val_loss: 0.8233\n",
      "Epoch 100/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 1.0043 - val_loss: 0.8221\n",
      "Epoch 101/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 1.0006 - val_loss: 0.8208\n",
      "Epoch 102/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 0.9972 - val_loss: 0.8197\n",
      "Epoch 103/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 0.9938 - val_loss: 0.8186\n",
      "Epoch 104/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.9904 - val_loss: 0.8175\n",
      "Epoch 105/500\n",
      "120/120==============================] - 0s 52us/sample - loss: 0.9869 - val_loss: 0.8165\n",
      "Epoch 106/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 0.9836 - val_loss: 0.8155\n",
      "Epoch 107/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 0.9803 - val_loss: 0.8144\n",
      "Epoch 108/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 0.9771 - val_loss: 0.8134\n",
      "Epoch 109/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 0.9740 - val_loss: 0.8125\n",
      "Epoch 110/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 0.9708 - val_loss: 0.8116\n",
      "Epoch 111/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.9680 - val_loss: 0.8106\n",
      "Epoch 112/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 0.9648 - val_loss: 0.8098\n",
      "Epoch 113/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 0.9619 - val_loss: 0.8089\n",
      "Epoch 114/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.9593 - val_loss: 0.8081\n",
      "Epoch 115/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.9562 - val_loss: 0.8074\n",
      "Epoch 116/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 0.9534 - val_loss: 0.8066\n",
      "Epoch 117/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.9505 - val_loss: 0.8058\n",
      "Epoch 118/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.9479 - val_loss: 0.8050\n",
      "Epoch 119/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 0.9452 - val_loss: 0.8043\n",
      "Epoch 120/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.9427 - val_loss: 0.8037\n",
      "Epoch 121/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.9404 - val_loss: 0.8030\n",
      "Epoch 122/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.9379 - val_loss: 0.8023\n",
      "Epoch 123/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 0.9354 - val_loss: 0.8017\n",
      "Epoch 124/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 0.9330 - val_loss: 0.8012\n",
      "Epoch 125/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.9305 - val_loss: 0.8006\n",
      "Epoch 126/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.9283 - val_loss: 0.8002\n",
      "Epoch 127/500\n",
      "120/120==============================] - 0s 70us/sample - loss: 0.9257 - val_loss: 0.7997\n",
      "Epoch 128/500\n",
      "120/120==============================] - 0s 67us/sample - loss: 0.9234 - val_loss: 0.7991\n",
      "Epoch 129/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.9212 - val_loss: 0.7986\n",
      "Epoch 130/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.9190 - val_loss: 0.7981\n",
      "Epoch 131/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 0.9168 - val_loss: 0.7977\n",
      "Epoch 132/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.9146 - val_loss: 0.7972\n",
      "Epoch 133/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 0.9125 - val_loss: 0.7968\n",
      "Epoch 134/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 0.9105 - val_loss: 0.7964\n",
      "Epoch 135/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 0.9083 - val_loss: 0.7960\n",
      "Epoch 136/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 0.9064 - val_loss: 0.7956\n",
      "Epoch 137/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 0.9045 - val_loss: 0.7952\n",
      "Epoch 138/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.9025 - val_loss: 0.7949\n",
      "Epoch 139/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.9006 - val_loss: 0.7945\n",
      "Epoch 140/500\n",
      "120/120==============================] - 0s 65us/sample - loss: 0.8987 - val_loss: 0.7942\n",
      "Epoch 141/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.8969 - val_loss: 0.7938\n",
      "Epoch 142/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.8952 - val_loss: 0.7935\n",
      "Epoch 143/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.8933 - val_loss: 0.7933\n",
      "Epoch 144/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.8916 - val_loss: 0.7930\n",
      "Epoch 145/500\n",
      "120/120==============================] - 0s 59us/sample - loss: 0.8898 - val_loss: 0.7927\n",
      "Epoch 146/500\n",
      "120/120==============================] - 0s 63us/sample - loss: 0.8881 - val_loss: 0.7924\n",
      "Epoch 147/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 0.8867 - val_loss: 0.7921\n",
      "Epoch 148/500\n",
      "120/120==============================] - 0s 64us/sample - loss: 0.8852 - val_loss: 0.7919\n",
      "Epoch 149/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.8834 - val_loss: 0.7916\n",
      "Epoch 150/500\n",
      "120/120==============================] - 0s 60us/sample - loss: 0.8817 - val_loss: 0.7914\n",
      "Epoch 151/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.8802 - val_loss: 0.7912\n",
      "Epoch 152/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 0.8787 - val_loss: 0.7910\n",
      "Epoch 153/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 0.8772 - val_loss: 0.7908\n",
      "Epoch 154/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 0.8758 - val_loss: 0.7906\n",
      "Epoch 155/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.8743 - val_loss: 0.7904\n",
      "Epoch 156/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 0.8729 - val_loss: 0.7902\n",
      "Epoch 157/500\n",
      "120/120==============================] - 0s 54us/sample - loss: 0.8715 - val_loss: 0.7901\n",
      "Epoch 158/500\n",
      "120/120==============================] - 0s 58us/sample - loss: 0.8701 - val_loss: 0.7901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.8688 - val_loss: 0.7899\n",
      "Epoch 160/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.8676 - val_loss: 0.7899\n",
      "Epoch 161/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.8664 - val_loss: 0.7897\n",
      "Epoch 162/500\n",
      "120/120==============================] - 0s 62us/sample - loss: 0.8649 - val_loss: 0.7896\n",
      "Epoch 163/500\n",
      "120/120==============================] - 0s 61us/sample - loss: 0.8637 - val_loss: 0.7896\n",
      "Epoch 164/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.8624 - val_loss: 0.7895\n",
      "Epoch 165/500\n",
      "120/120==============================] - 0s 57us/sample - loss: 0.8612 - val_loss: 0.7895\n",
      "Epoch 166/500\n",
      "120/120==============================] - 0s 53us/sample - loss: 0.8600 - val_loss: 0.7894\n",
      "Epoch 167/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.8589 - val_loss: 0.7894\n",
      "Epoch 168/500\n",
      "120/120==============================] - 0s 66us/sample - loss: 0.8577 - val_loss: 0.7894\n",
      "Epoch 169/500\n",
      "120/120==============================] - 0s 56us/sample - loss: 0.8566 - val_loss: 0.7893\n",
      "Epoch 170/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 0.8554 - val_loss: 0.7892\n",
      "Epoch 171/500\n",
      "120/120==============================] - 0s 55us/sample - loss: 0.8544 - val_loss: 0.7892\n",
      "Epoch 172/500\n",
      "120/120==============================] - 0s 69us/sample - loss: 0.8534 - val_loss: 0.7891\n",
      "Epoch 173/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8522 - val_loss: 0.7892\n",
      "Epoch 174/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8512 - val_loss: 0.7892\n",
      "Epoch 175/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8501 - val_loss: 0.7892\n",
      "Epoch 176/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8490 - val_loss: 0.7892\n",
      "Epoch 177/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8480 - val_loss: 0.7892\n",
      "Epoch 178/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8471 - val_loss: 0.7891\n",
      "Epoch 179/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8461 - val_loss: 0.7891\n",
      "Epoch 180/500\n",
      "120/120==============================] - 0s 25us/sample - loss: 0.8452 - val_loss: 0.7892\n",
      "Epoch 181/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8441 - val_loss: 0.7892\n",
      "Epoch 182/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.8433 - val_loss: 0.7893\n",
      "Epoch 183/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8424 - val_loss: 0.7893\n",
      "Epoch 184/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8416 - val_loss: 0.7893\n",
      "Epoch 185/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8405 - val_loss: 0.7894\n",
      "Epoch 186/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8397 - val_loss: 0.7894\n",
      "Epoch 187/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8388 - val_loss: 0.7895\n",
      "Epoch 188/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8381 - val_loss: 0.7896\n",
      "Epoch 189/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8370 - val_loss: 0.7897\n",
      "Epoch 190/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8363 - val_loss: 0.7898\n",
      "Epoch 191/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8355 - val_loss: 0.7899\n",
      "Epoch 192/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8348 - val_loss: 0.7899\n",
      "Epoch 193/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8340 - val_loss: 0.7900\n",
      "Epoch 194/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8333 - val_loss: 0.7902\n",
      "Epoch 195/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8325 - val_loss: 0.7903\n",
      "Epoch 196/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8318 - val_loss: 0.7903\n",
      "Epoch 197/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8311 - val_loss: 0.7904\n",
      "Epoch 198/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8305 - val_loss: 0.7905\n",
      "Epoch 199/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8298 - val_loss: 0.7907\n",
      "Epoch 200/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8290 - val_loss: 0.7908\n",
      "Epoch 201/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8283 - val_loss: 0.7909\n",
      "Epoch 202/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.8276 - val_loss: 0.7911\n",
      "Epoch 203/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8269 - val_loss: 0.7912\n",
      "Epoch 204/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8263 - val_loss: 0.7914\n",
      "Epoch 205/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8258 - val_loss: 0.7915\n",
      "Epoch 206/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8250 - val_loss: 0.7917\n",
      "Epoch 207/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8245 - val_loss: 0.7919\n",
      "Epoch 208/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8239 - val_loss: 0.7920\n",
      "Epoch 209/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8232 - val_loss: 0.7922\n",
      "Epoch 210/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8226 - val_loss: 0.7924\n",
      "Epoch 211/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8222 - val_loss: 0.7926\n",
      "Epoch 212/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8216 - val_loss: 0.7927\n",
      "Epoch 213/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8210 - val_loss: 0.7928\n",
      "Epoch 214/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8205 - val_loss: 0.7930\n",
      "Epoch 215/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8198 - val_loss: 0.7932\n",
      "Epoch 216/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8193 - val_loss: 0.7933\n",
      "Epoch 217/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8187 - val_loss: 0.7935\n",
      "Epoch 218/500\n",
      "120/120==============================] - 0s 25us/sample - loss: 0.8184 - val_loss: 0.7938\n",
      "Epoch 219/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8178 - val_loss: 0.7939\n",
      "Epoch 220/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.8172 - val_loss: 0.7941\n",
      "Epoch 221/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8168 - val_loss: 0.7942\n",
      "Epoch 222/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.8163 - val_loss: 0.7944\n",
      "Epoch 223/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.8160 - val_loss: 0.7945\n",
      "Epoch 224/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.8154 - val_loss: 0.7947\n",
      "Epoch 225/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.8150 - val_loss: 0.7949\n",
      "Epoch 226/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8146 - val_loss: 0.7950\n",
      "Epoch 227/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8141 - val_loss: 0.7952\n",
      "Epoch 228/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8137 - val_loss: 0.7955\n",
      "Epoch 229/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8133 - val_loss: 0.7956\n",
      "Epoch 230/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8128 - val_loss: 0.7959\n",
      "Epoch 231/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8126 - val_loss: 0.7961\n",
      "Epoch 232/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8120 - val_loss: 0.7963\n",
      "Epoch 233/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8115 - val_loss: 0.7965\n",
      "Epoch 234/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.8111 - val_loss: 0.7967\n",
      "Epoch 235/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8109 - val_loss: 0.7968\n",
      "Epoch 236/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8104 - val_loss: 0.7970\n",
      "Epoch 237/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8101 - val_loss: 0.7972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8097 - val_loss: 0.7974\n",
      "Epoch 239/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8094 - val_loss: 0.7976\n",
      "Epoch 240/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8090 - val_loss: 0.7978\n",
      "Epoch 241/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8087 - val_loss: 0.7980\n",
      "Epoch 242/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8084 - val_loss: 0.7982\n",
      "Epoch 243/500\n",
      "120/120==============================] - 0s 25us/sample - loss: 0.8079 - val_loss: 0.7984\n",
      "Epoch 244/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8076 - val_loss: 0.7986\n",
      "Epoch 245/500\n",
      "120/120==============================] - 0s 49us/sample - loss: 0.8073 - val_loss: 0.7987\n",
      "Epoch 246/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8070 - val_loss: 0.7989\n",
      "Epoch 247/500\n",
      "120/120==============================] - 0s 25us/sample - loss: 0.8068 - val_loss: 0.7990\n",
      "Epoch 248/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.8066 - val_loss: 0.7992\n",
      "Epoch 249/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.8061 - val_loss: 0.7994\n",
      "Epoch 250/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8057 - val_loss: 0.7996\n",
      "Epoch 251/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.8055 - val_loss: 0.7998\n",
      "Epoch 252/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8053 - val_loss: 0.8000\n",
      "Epoch 253/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.8049 - val_loss: 0.8003\n",
      "Epoch 254/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8045 - val_loss: 0.8004\n",
      "Epoch 255/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8044 - val_loss: 0.8006\n",
      "Epoch 256/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.8042 - val_loss: 0.8009\n",
      "Epoch 257/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.8037 - val_loss: 0.8011\n",
      "Epoch 258/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.8035 - val_loss: 0.8013\n",
      "Epoch 259/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.8032 - val_loss: 0.8014\n",
      "Epoch 260/500\n",
      "120/120==============================] - 0s 50us/sample - loss: 0.8030 - val_loss: 0.8016\n",
      "Epoch 261/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8028 - val_loss: 0.8017\n",
      "Epoch 262/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8026 - val_loss: 0.8020\n",
      "Epoch 263/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.8023 - val_loss: 0.8022\n",
      "Epoch 264/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8022 - val_loss: 0.8024\n",
      "Epoch 265/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.8017 - val_loss: 0.8026\n",
      "Epoch 266/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.8016 - val_loss: 0.8029\n",
      "Epoch 267/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8013 - val_loss: 0.8031\n",
      "Epoch 268/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.8012 - val_loss: 0.8032\n",
      "Epoch 269/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8008 - val_loss: 0.8035\n",
      "Epoch 270/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.8007 - val_loss: 0.8037\n",
      "Epoch 271/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.8005 - val_loss: 0.8039\n",
      "Epoch 272/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.8002 - val_loss: 0.8041\n",
      "Epoch 273/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.8000 - val_loss: 0.8043\n",
      "Epoch 274/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7998 - val_loss: 0.8045\n",
      "Epoch 275/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7997 - val_loss: 0.8047\n",
      "Epoch 276/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7995 - val_loss: 0.8049\n",
      "Epoch 277/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7991 - val_loss: 0.8051\n",
      "Epoch 278/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7990 - val_loss: 0.8053\n",
      "Epoch 279/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7988 - val_loss: 0.8055\n",
      "Epoch 280/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7987 - val_loss: 0.8057\n",
      "Epoch 281/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7984 - val_loss: 0.8060\n",
      "Epoch 282/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7983 - val_loss: 0.8061\n",
      "Epoch 283/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7983 - val_loss: 0.8062\n",
      "Epoch 284/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7980 - val_loss: 0.8065\n",
      "Epoch 285/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7979 - val_loss: 0.8066\n",
      "Epoch 286/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7976 - val_loss: 0.8068\n",
      "Epoch 287/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7976 - val_loss: 0.8070\n",
      "Epoch 288/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7974 - val_loss: 0.8072\n",
      "Epoch 289/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7971 - val_loss: 0.8073\n",
      "Epoch 290/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7970 - val_loss: 0.8075\n",
      "Epoch 291/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7969 - val_loss: 0.8076\n",
      "Epoch 292/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7968 - val_loss: 0.8078\n",
      "Epoch 293/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7968 - val_loss: 0.8079\n",
      "Epoch 294/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7964 - val_loss: 0.8081\n",
      "Epoch 295/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7963 - val_loss: 0.8083\n",
      "Epoch 296/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7961 - val_loss: 0.8085\n",
      "Epoch 297/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7961 - val_loss: 0.8086\n",
      "Epoch 298/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7960 - val_loss: 0.8087\n",
      "Epoch 299/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7957 - val_loss: 0.8089\n",
      "Epoch 300/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7956 - val_loss: 0.8091\n",
      "Epoch 301/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7955 - val_loss: 0.8092\n",
      "Epoch 302/500\n",
      "120/120==============================] - 0s 25us/sample - loss: 0.7953 - val_loss: 0.8094\n",
      "Epoch 303/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7953 - val_loss: 0.8095\n",
      "Epoch 304/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7951 - val_loss: 0.8097\n",
      "Epoch 305/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7950 - val_loss: 0.8099\n",
      "Epoch 306/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7949 - val_loss: 0.8101\n",
      "Epoch 307/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7948 - val_loss: 0.8102\n",
      "Epoch 308/500\n",
      "120/120==============================] - 0s 45us/sample - loss: 0.7947 - val_loss: 0.8104\n",
      "Epoch 309/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7946 - val_loss: 0.8105\n",
      "Epoch 310/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.7944 - val_loss: 0.8107\n",
      "Epoch 311/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7945 - val_loss: 0.8109\n",
      "Epoch 312/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7943 - val_loss: 0.8111\n",
      "Epoch 313/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7943 - val_loss: 0.8113\n",
      "Epoch 314/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.7940 - val_loss: 0.8115\n",
      "Epoch 315/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7939 - val_loss: 0.8116\n",
      "Epoch 316/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7939 - val_loss: 0.8118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7938 - val_loss: 0.8120\n",
      "Epoch 318/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.7936 - val_loss: 0.8122\n",
      "Epoch 319/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7936 - val_loss: 0.8124\n",
      "Epoch 320/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7934 - val_loss: 0.8126\n",
      "Epoch 321/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7933 - val_loss: 0.8127\n",
      "Epoch 322/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7933 - val_loss: 0.8129\n",
      "Epoch 323/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7933 - val_loss: 0.8131\n",
      "Epoch 324/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7930 - val_loss: 0.8132\n",
      "Epoch 325/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.7930 - val_loss: 0.8134\n",
      "Epoch 326/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.7929 - val_loss: 0.8135\n",
      "Epoch 327/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7928 - val_loss: 0.8137\n",
      "Epoch 328/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7930 - val_loss: 0.8139\n",
      "Epoch 329/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7928 - val_loss: 0.8140\n",
      "Epoch 330/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7926 - val_loss: 0.8141\n",
      "Epoch 331/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7926 - val_loss: 0.8143\n",
      "Epoch 332/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7925 - val_loss: 0.8144\n",
      "Epoch 333/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7924 - val_loss: 0.8146\n",
      "Epoch 334/500\n",
      "120/120==============================] - 0s 48us/sample - loss: 0.7923 - val_loss: 0.8148\n",
      "Epoch 335/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7922 - val_loss: 0.8150\n",
      "Epoch 336/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7921 - val_loss: 0.8151\n",
      "Epoch 337/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7921 - val_loss: 0.8153\n",
      "Epoch 338/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7920 - val_loss: 0.8154\n",
      "Epoch 339/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7920 - val_loss: 0.8156\n",
      "Epoch 340/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7919 - val_loss: 0.8157\n",
      "Epoch 341/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7919 - val_loss: 0.8158\n",
      "Epoch 342/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7917 - val_loss: 0.8160\n",
      "Epoch 343/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7918 - val_loss: 0.8162\n",
      "Epoch 344/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7916 - val_loss: 0.8164\n",
      "Epoch 345/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7915 - val_loss: 0.8165\n",
      "Epoch 346/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7915 - val_loss: 0.8166\n",
      "Epoch 347/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7915 - val_loss: 0.8168\n",
      "Epoch 348/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7915 - val_loss: 0.8169\n",
      "Epoch 349/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7914 - val_loss: 0.8171\n",
      "Epoch 350/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7913 - val_loss: 0.8172\n",
      "Epoch 351/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7912 - val_loss: 0.8173\n",
      "Epoch 352/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7911 - val_loss: 0.8175\n",
      "Epoch 353/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7911 - val_loss: 0.8176\n",
      "Epoch 354/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.7911 - val_loss: 0.8177\n",
      "Epoch 355/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7911 - val_loss: 0.8179\n",
      "Epoch 356/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7910 - val_loss: 0.8180\n",
      "Epoch 357/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7910 - val_loss: 0.8182\n",
      "Epoch 358/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7909 - val_loss: 0.8183\n",
      "Epoch 359/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7909 - val_loss: 0.8184\n",
      "Epoch 360/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7908 - val_loss: 0.8185\n",
      "Epoch 361/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7907 - val_loss: 0.8187\n",
      "Epoch 362/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7907 - val_loss: 0.8188\n",
      "Epoch 363/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7907 - val_loss: 0.8190\n",
      "Epoch 364/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7905 - val_loss: 0.8191\n",
      "Epoch 365/500\n",
      "120/120==============================] - 0s 48us/sample - loss: 0.7905 - val_loss: 0.8192\n",
      "Epoch 366/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.7905 - val_loss: 0.8193\n",
      "Epoch 367/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7904 - val_loss: 0.8195\n",
      "Epoch 368/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7905 - val_loss: 0.8197\n",
      "Epoch 369/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7905 - val_loss: 0.8197\n",
      "Epoch 370/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7905 - val_loss: 0.8199\n",
      "Epoch 371/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7903 - val_loss: 0.8200\n",
      "Epoch 372/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7903 - val_loss: 0.8201\n",
      "Epoch 373/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7902 - val_loss: 0.8202\n",
      "Epoch 374/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7903 - val_loss: 0.8203\n",
      "Epoch 375/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7902 - val_loss: 0.8204\n",
      "Epoch 376/500\n",
      "120/120==============================] - 0s 44us/sample - loss: 0.7902 - val_loss: 0.8205\n",
      "Epoch 377/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7901 - val_loss: 0.8205\n",
      "Epoch 378/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7901 - val_loss: 0.8207\n",
      "Epoch 379/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7900 - val_loss: 0.8208\n",
      "Epoch 380/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7901 - val_loss: 0.8209\n",
      "Epoch 381/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7900 - val_loss: 0.8210\n",
      "Epoch 382/500\n",
      "120/120==============================] - 0s 42us/sample - loss: 0.7899 - val_loss: 0.8211\n",
      "Epoch 383/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7899 - val_loss: 0.8212\n",
      "Epoch 384/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7898 - val_loss: 0.8214\n",
      "Epoch 385/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7901 - val_loss: 0.8214\n",
      "Epoch 386/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7899 - val_loss: 0.8216\n",
      "Epoch 387/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7898 - val_loss: 0.8216\n",
      "Epoch 388/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7898 - val_loss: 0.8217\n",
      "Epoch 389/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7897 - val_loss: 0.8218\n",
      "Epoch 390/500\n",
      "120/120==============================] - 0s 50us/sample - loss: 0.7899 - val_loss: 0.8219\n",
      "Epoch 391/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.7896 - val_loss: 0.8220\n",
      "Epoch 392/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7896 - val_loss: 0.8221\n",
      "Epoch 393/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7897 - val_loss: 0.8222\n",
      "Epoch 394/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7896 - val_loss: 0.8223\n",
      "Epoch 395/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7896 - val_loss: 0.8224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7895 - val_loss: 0.8226\n",
      "Epoch 397/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7895 - val_loss: 0.8226\n",
      "Epoch 398/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7894 - val_loss: 0.8228\n",
      "Epoch 399/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7896 - val_loss: 0.8228\n",
      "Epoch 400/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7896 - val_loss: 0.8229\n",
      "Epoch 401/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7894 - val_loss: 0.8230\n",
      "Epoch 402/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7894 - val_loss: 0.8231\n",
      "Epoch 403/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7893 - val_loss: 0.8232\n",
      "Epoch 404/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7892 - val_loss: 0.8234\n",
      "Epoch 405/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7894 - val_loss: 0.8235\n",
      "Epoch 406/500\n",
      "120/120==============================] - 0s 38us/sample - loss: 0.7892 - val_loss: 0.8236\n",
      "Epoch 407/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7892 - val_loss: 0.8237\n",
      "Epoch 408/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7891 - val_loss: 0.8238\n",
      "Epoch 409/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7892 - val_loss: 0.8238\n",
      "Epoch 410/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7892 - val_loss: 0.8239\n",
      "Epoch 411/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7891 - val_loss: 0.8240\n",
      "Epoch 412/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7891 - val_loss: 0.8242\n",
      "Epoch 413/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7894 - val_loss: 0.8242\n",
      "Epoch 414/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7891 - val_loss: 0.8243\n",
      "Epoch 415/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7891 - val_loss: 0.8245\n",
      "Epoch 416/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7890 - val_loss: 0.8245\n",
      "Epoch 417/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7892 - val_loss: 0.8247\n",
      "Epoch 418/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7890 - val_loss: 0.8248\n",
      "Epoch 419/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7889 - val_loss: 0.8250\n",
      "Epoch 420/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.7889 - val_loss: 0.8251\n",
      "Epoch 421/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7889 - val_loss: 0.8251\n",
      "Epoch 422/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7889 - val_loss: 0.8252\n",
      "Epoch 423/500\n",
      "120/120==============================] - 0s 25us/sample - loss: 0.7889 - val_loss: 0.8253\n",
      "Epoch 424/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7888 - val_loss: 0.8254\n",
      "Epoch 425/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7888 - val_loss: 0.8256\n",
      "Epoch 426/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7888 - val_loss: 0.8256\n",
      "Epoch 427/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7889 - val_loss: 0.8257\n",
      "Epoch 428/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7888 - val_loss: 0.8257\n",
      "Epoch 429/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7888 - val_loss: 0.8258\n",
      "Epoch 430/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7888 - val_loss: 0.8259\n",
      "Epoch 431/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7887 - val_loss: 0.8260\n",
      "Epoch 432/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7887 - val_loss: 0.8260\n",
      "Epoch 433/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7886 - val_loss: 0.8261\n",
      "Epoch 434/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7887 - val_loss: 0.8261\n",
      "Epoch 435/500\n",
      "120/120==============================] - 0s 47us/sample - loss: 0.7889 - val_loss: 0.8262\n",
      "Epoch 436/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7886 - val_loss: 0.8263\n",
      "Epoch 437/500\n",
      "120/120==============================] - 0s 40us/sample - loss: 0.7887 - val_loss: 0.8264\n",
      "Epoch 438/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7886 - val_loss: 0.8265\n",
      "Epoch 439/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7887 - val_loss: 0.8266\n",
      "Epoch 440/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7886 - val_loss: 0.8266\n",
      "Epoch 441/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7886 - val_loss: 0.8267\n",
      "Epoch 442/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7886 - val_loss: 0.8267\n",
      "Epoch 443/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7885 - val_loss: 0.8267\n",
      "Epoch 444/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7886 - val_loss: 0.8268\n",
      "Epoch 445/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7886 - val_loss: 0.8269\n",
      "Epoch 446/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7885 - val_loss: 0.8269\n",
      "Epoch 447/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7885 - val_loss: 0.8270\n",
      "Epoch 448/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7885 - val_loss: 0.8271\n",
      "Epoch 449/500\n",
      "120/120==============================] - 0s 46us/sample - loss: 0.7886 - val_loss: 0.8271\n",
      "Epoch 450/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7886 - val_loss: 0.8272\n",
      "Epoch 451/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7886 - val_loss: 0.8273\n",
      "Epoch 452/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7885 - val_loss: 0.8274\n",
      "Epoch 453/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7884 - val_loss: 0.8275\n",
      "Epoch 454/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7884 - val_loss: 0.8275\n",
      "Epoch 455/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7884 - val_loss: 0.8275\n",
      "Epoch 456/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7885 - val_loss: 0.8276\n",
      "Epoch 457/500\n",
      "120/120==============================] - 0s 26us/sample - loss: 0.7884 - val_loss: 0.8277\n",
      "Epoch 458/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7883 - val_loss: 0.8277\n",
      "Epoch 459/500\n",
      "120/120==============================] - 0s 37us/sample - loss: 0.7884 - val_loss: 0.8278\n",
      "Epoch 460/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7884 - val_loss: 0.8278\n",
      "Epoch 461/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7884 - val_loss: 0.8278\n",
      "Epoch 462/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7885 - val_loss: 0.8278\n",
      "Epoch 463/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7883 - val_loss: 0.8278\n",
      "Epoch 464/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7884 - val_loss: 0.8278\n",
      "Epoch 465/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7883 - val_loss: 0.8279\n",
      "Epoch 466/500\n",
      "120/120==============================] - 0s 32us/sample - loss: 0.7883 - val_loss: 0.8280\n",
      "Epoch 467/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7883 - val_loss: 0.8280\n",
      "Epoch 468/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7883 - val_loss: 0.8280\n",
      "Epoch 469/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7883 - val_loss: 0.8281\n",
      "Epoch 470/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7884 - val_loss: 0.8282\n",
      "Epoch 471/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7883 - val_loss: 0.8282\n",
      "Epoch 472/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7883 - val_loss: 0.8283\n",
      "Epoch 473/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7883 - val_loss: 0.8284\n",
      "Epoch 474/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7883 - val_loss: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7882 - val_loss: 0.8285\n",
      "Epoch 476/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7882 - val_loss: 0.8286\n",
      "Epoch 477/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7885 - val_loss: 0.8286\n",
      "Epoch 478/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7882 - val_loss: 0.8287\n",
      "Epoch 479/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7883 - val_loss: 0.8288\n",
      "Epoch 480/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7881 - val_loss: 0.8288\n",
      "Epoch 481/500\n",
      "120/120==============================] - 0s 34us/sample - loss: 0.7882 - val_loss: 0.8289\n",
      "Epoch 482/500\n",
      "120/120==============================] - 0s 31us/sample - loss: 0.7883 - val_loss: 0.8289\n",
      "Epoch 483/500\n",
      "120/120==============================] - 0s 33us/sample - loss: 0.7882 - val_loss: 0.8290\n",
      "Epoch 484/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7881 - val_loss: 0.8291\n",
      "Epoch 485/500\n",
      "120/120==============================] - 0s 41us/sample - loss: 0.7882 - val_loss: 0.8292\n",
      "Epoch 486/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7883 - val_loss: 0.8292\n",
      "Epoch 487/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7882 - val_loss: 0.8294\n",
      "Epoch 488/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7882 - val_loss: 0.8294\n",
      "Epoch 489/500\n",
      "120/120==============================] - 0s 28us/sample - loss: 0.7882 - val_loss: 0.8294\n",
      "Epoch 490/500\n",
      "120/120==============================] - 0s 30us/sample - loss: 0.7881 - val_loss: 0.8295\n",
      "Epoch 491/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7881 - val_loss: 0.8296\n",
      "Epoch 492/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7881 - val_loss: 0.8297\n",
      "Epoch 493/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7883 - val_loss: 0.8297\n",
      "Epoch 494/500\n",
      "120/120==============================] - 0s 36us/sample - loss: 0.7881 - val_loss: 0.8298\n",
      "Epoch 495/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7882 - val_loss: 0.8299\n",
      "Epoch 496/500\n",
      "120/120==============================] - 0s 27us/sample - loss: 0.7881 - val_loss: 0.8300\n",
      "Epoch 497/500\n",
      "120/120==============================] - 0s 39us/sample - loss: 0.7880 - val_loss: 0.8300\n",
      "Epoch 498/500\n",
      "120/120==============================] - 0s 43us/sample - loss: 0.7880 - val_loss: 0.8301\n",
      "Epoch 499/500\n",
      "120/120==============================] - 0s 35us/sample - loss: 0.7880 - val_loss: 0.8301\n",
      "Epoch 500/500\n",
      "120/120==============================] - 0s 29us/sample - loss: 0.7880 - val_loss: 0.8301\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "callback_list = [ModelCheckpoint(filepath='my_model.h5', \n",
    "                                 monitor='val_loss', save_best_only=True)]\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restoring the saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50==============================] - 0s 1ms/sample - loss: 1.0239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0238643383979797"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('simple_model.h5')\n",
    "model.load_weights('my_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_arr = np.arange(-2, 2, 0.1)\n",
    "y_arr = model.predict(x_arr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr, '-r', lw=3)\n",
    "# plt.savefig('images/14_05.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서를 다차원 배열로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]], shape=(3, 4), dtype=float64)\n",
      "T1의 크기: (3, 4)\n",
      "T1의 크기: (3, 4)\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
      "array([[ 1.00077942,  0.76718517,  0.7585358 , -0.10983495],\n",
      "       [ 0.10824642, -0.0648924 ,  1.20550726,  0.59442177],\n",
      "       [-0.21372099,  0.32027211, -0.34539183,  0.94037937]])>\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float64, numpy=array([ 1.07797999, -0.48164379,  0.15853372])>\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1., 2., 3., 3.5],\n",
    "                [4., 5., 6., 6.5],\n",
    "                [7., 8., 9., 9.5]])\n",
    "T1 = tf.constant(arr)\n",
    "print(T1)\n",
    "s = T1.get_shape()\n",
    "print('T1의 크기:', s)\n",
    "print('T1의 크기:', T1.shape)\n",
    "T2 = tf.Variable(np.random.normal(size=s))\n",
    "print(T2)\n",
    "T3 = tf.Variable(np.random.normal(size=s[0]))\n",
    "print(T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[1.  2.  3.  3.5 4.  5.  6.  6.5 7.  8.  9.  9.5]]], shape=(1, 1, 12), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]], shape=(1, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T4 = tf.reshape(T1, shape=[1, 1, -1])\n",
    "print(T4)\n",
    "T5 = tf.reshape(T1, shape=[1, 3, -1])\n",
    "print(T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. ]\n",
      "  [4. ]\n",
      "  [7. ]]\n",
      "\n",
      " [[2. ]\n",
      "  [5. ]\n",
      "  [8. ]]\n",
      "\n",
      " [[3. ]\n",
      "  [6. ]\n",
      "  [9. ]]\n",
      "\n",
      " [[3.5]\n",
      "  [6.5]\n",
      "  [9.5]]], shape=(4, 3, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1.  4.  7. ]\n",
      "  [2.  5.  8. ]\n",
      "  [3.  6.  9. ]\n",
      "  [3.5 6.5 9.5]]], shape=(1, 4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T6 = tf.transpose(T5, perm=[2, 1, 0])\n",
    "print(T6)\n",
    "T7 = tf.transpose(T5, perm=[0, 2, 1])\n",
    "print(T7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=79303, shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]]])>, <tf.Tensor: id=79304, shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[3. , 3.5],\n",
      "        [6. , 6.5],\n",
      "        [9. , 9.5]]])>]\n"
     ]
    }
   ],
   "source": [
    "t5_splt = tf.split(T5, \n",
    "                   num_or_size_splits=2, \n",
    "                   axis=2)\n",
    "print(t5_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(10, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.ones(shape=(5, 1), dtype=tf.float32)\n",
    "t2 = tf.zeros(shape=(5, 1), dtype=tf.float32)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "t3 = tf.concat([t1, t2], axis=0)\n",
    "print(t3)\n",
    "t4 = tf.concat([t1, t2], axis=1)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing the graph with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/500\n",
      "105/105==============================] - 0s 2ms/sample - loss: 7.9064 - val_loss: 5.2901\n",
      "Epoch 2/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 7.7675 - val_loss: 5.1964\n",
      "Epoch 3/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 7.6195 - val_loss: 5.1116\n",
      "Epoch 4/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 7.4790 - val_loss: 5.0235\n",
      "Epoch 5/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 7.3378 - val_loss: 4.9412\n",
      "Epoch 6/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 7.2040 - val_loss: 4.8616\n",
      "Epoch 7/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 7.0735 - val_loss: 4.7661\n",
      "Epoch 8/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 6.9169 - val_loss: 4.6810\n",
      "Epoch 9/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 6.7828 - val_loss: 4.6021\n",
      "Epoch 10/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 6.6566 - val_loss: 4.5257\n",
      "Epoch 11/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 6.5309 - val_loss: 4.4497\n",
      "Epoch 12/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 6.4098 - val_loss: 4.3770\n",
      "Epoch 13/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 6.2912 - val_loss: 4.3039\n",
      "Epoch 14/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 6.1767 - val_loss: 4.2262\n",
      "Epoch 15/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 6.0505 - val_loss: 4.1505\n",
      "Epoch 16/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 5.9284 - val_loss: 4.0811\n",
      "Epoch 17/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 5.8169 - val_loss: 4.0146\n",
      "Epoch 18/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 5.7089 - val_loss: 3.9501\n",
      "Epoch 19/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 5.6031 - val_loss: 3.8881\n",
      "Epoch 20/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 5.5018 - val_loss: 3.8220\n",
      "Epoch 21/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 5.3960 - val_loss: 3.7611\n",
      "Epoch 22/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 5.2985 - val_loss: 3.7053\n",
      "Epoch 23/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 5.2071 - val_loss: 3.6471\n",
      "Epoch 24/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 5.1142 - val_loss: 3.5944\n",
      "Epoch 25/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 5.0281 - val_loss: 3.5370\n",
      "Epoch 26/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 4.9377 - val_loss: 3.4856\n",
      "Epoch 27/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 4.8550 - val_loss: 3.4349\n",
      "Epoch 28/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 4.7713 - val_loss: 3.3816\n",
      "Epoch 29/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 4.6838 - val_loss: 3.3292\n",
      "Epoch 30/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 4.5972 - val_loss: 3.2791\n",
      "Epoch 31/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 4.5143 - val_loss: 3.2267\n",
      "Epoch 32/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 4.4294 - val_loss: 3.1756\n",
      "Epoch 33/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 4.3472 - val_loss: 3.1323\n",
      "Epoch 34/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 4.2756 - val_loss: 3.0807\n",
      "Epoch 35/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 4.1912 - val_loss: 3.0332\n",
      "Epoch 36/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 4.1151 - val_loss: 2.9941\n",
      "Epoch 37/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 4.0516 - val_loss: 2.9567\n",
      "Epoch 38/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 3.9892 - val_loss: 2.9131\n",
      "Epoch 39/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 3.9194 - val_loss: 2.8704\n",
      "Epoch 40/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.8518 - val_loss: 2.8303\n",
      "Epoch 41/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 3.7847 - val_loss: 2.7903\n",
      "Epoch 42/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 3.7191 - val_loss: 2.7470\n",
      "Epoch 43/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.6522 - val_loss: 2.7103\n",
      "Epoch 44/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.5944 - val_loss: 2.6710\n",
      "Epoch 45/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 3.5302 - val_loss: 2.6345\n",
      "Epoch 46/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 3.4710 - val_loss: 2.6023\n",
      "Epoch 47/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 3.4178 - val_loss: 2.5668\n",
      "Epoch 48/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 3.3601 - val_loss: 2.5331\n",
      "Epoch 49/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 3.3064 - val_loss: 2.4981\n",
      "Epoch 50/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 3.2522 - val_loss: 2.4660\n",
      "Epoch 51/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 3.2020 - val_loss: 2.4299\n",
      "Epoch 52/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 3.1433 - val_loss: 2.4020\n",
      "Epoch 53/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 3.0992 - val_loss: 2.3718\n",
      "Epoch 54/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 3.0505 - val_loss: 2.3385\n",
      "Epoch 55/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 2.9972 - val_loss: 2.3042\n",
      "Epoch 56/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.9419 - val_loss: 2.2746\n",
      "Epoch 57/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 2.8945 - val_loss: 2.2476\n",
      "Epoch 58/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.8507 - val_loss: 2.2211\n",
      "Epoch 59/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.8087 - val_loss: 2.1958\n",
      "Epoch 60/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.7677 - val_loss: 2.1709\n",
      "Epoch 61/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 2.7290 - val_loss: 2.1487\n",
      "Epoch 62/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 2.6924 - val_loss: 2.1236\n",
      "Epoch 63/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.6532 - val_loss: 2.0982\n",
      "Epoch 64/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.6121 - val_loss: 2.0759\n",
      "Epoch 65/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 2.5757 - val_loss: 2.0524\n",
      "Epoch 66/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 2.5379 - val_loss: 2.0295\n",
      "Epoch 67/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 2.5023 - val_loss: 2.0097\n",
      "Epoch 68/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.4693 - val_loss: 1.9859\n",
      "Epoch 69/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 2.4327 - val_loss: 1.9637\n",
      "Epoch 70/500\n",
      "105/105==============================] - 0s 65us/sample - loss: 2.3983 - val_loss: 1.9438\n",
      "Epoch 71/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 2.3655 - val_loss: 1.9189\n",
      "Epoch 72/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 2.3275 - val_loss: 1.9006\n",
      "Epoch 73/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 2.2970 - val_loss: 1.8811\n",
      "Epoch 74/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.2647 - val_loss: 1.8616\n",
      "Epoch 75/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 2.2328 - val_loss: 1.8404\n",
      "Epoch 76/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.1983 - val_loss: 1.8212\n",
      "Epoch 77/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.1675 - val_loss: 1.8005\n",
      "Epoch 78/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.1374 - val_loss: 1.7829\n",
      "Epoch 79/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 2.1099 - val_loss: 1.7646\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 40us/sample - loss: 2.0798 - val_loss: 1.7485\n",
      "Epoch 81/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 2.0540 - val_loss: 1.7321\n",
      "Epoch 82/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 2.0268 - val_loss: 1.7152\n",
      "Epoch 83/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 2.0000 - val_loss: 1.6980\n",
      "Epoch 84/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.9738 - val_loss: 1.6827\n",
      "Epoch 85/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.9489 - val_loss: 1.6669\n",
      "Epoch 86/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.9238 - val_loss: 1.6524\n",
      "Epoch 87/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.8997 - val_loss: 1.6356\n",
      "Epoch 88/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.8735 - val_loss: 1.6196\n",
      "Epoch 89/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.8482 - val_loss: 1.6062\n",
      "Epoch 90/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.8263 - val_loss: 1.5924\n",
      "Epoch 91/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 1.8049 - val_loss: 1.5794\n",
      "Epoch 92/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 1.7840 - val_loss: 1.5648\n",
      "Epoch 93/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.7605 - val_loss: 1.5490\n",
      "Epoch 94/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.7359 - val_loss: 1.5350\n",
      "Epoch 95/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.7134 - val_loss: 1.5222\n",
      "Epoch 96/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.6932 - val_loss: 1.5112\n",
      "Epoch 97/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.6748 - val_loss: 1.4991\n",
      "Epoch 98/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.6555 - val_loss: 1.4856\n",
      "Epoch 99/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.6340 - val_loss: 1.4732\n",
      "Epoch 100/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.6140 - val_loss: 1.4614\n",
      "Epoch 101/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.5964 - val_loss: 1.4512\n",
      "Epoch 102/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.5789 - val_loss: 1.4399\n",
      "Epoch 103/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.5614 - val_loss: 1.4297\n",
      "Epoch 104/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.5452 - val_loss: 1.4173\n",
      "Epoch 105/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.5270 - val_loss: 1.4102\n",
      "Epoch 106/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.5142 - val_loss: 1.3994\n",
      "Epoch 107/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.4973 - val_loss: 1.3896\n",
      "Epoch 108/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.4813 - val_loss: 1.3812\n",
      "Epoch 109/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.4676 - val_loss: 1.3723\n",
      "Epoch 110/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.4532 - val_loss: 1.3623\n",
      "Epoch 111/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.4372 - val_loss: 1.3546\n",
      "Epoch 112/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.4247 - val_loss: 1.3452\n",
      "Epoch 113/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.4099 - val_loss: 1.3357\n",
      "Epoch 114/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.3960 - val_loss: 1.3285\n",
      "Epoch 115/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.3832 - val_loss: 1.3198\n",
      "Epoch 116/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.3701 - val_loss: 1.3117\n",
      "Epoch 117/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.3565 - val_loss: 1.3029\n",
      "Epoch 118/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.3431 - val_loss: 1.2959\n",
      "Epoch 119/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 1.3319 - val_loss: 1.2874\n",
      "Epoch 120/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.3191 - val_loss: 1.2810\n",
      "Epoch 121/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.3087 - val_loss: 1.2731\n",
      "Epoch 122/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.2963 - val_loss: 1.2654\n",
      "Epoch 123/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.2847 - val_loss: 1.2589\n",
      "Epoch 124/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.2749 - val_loss: 1.2540\n",
      "Epoch 125/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.2665 - val_loss: 1.2477\n",
      "Epoch 126/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.2566 - val_loss: 1.2403\n",
      "Epoch 127/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 1.2456 - val_loss: 1.2341\n",
      "Epoch 128/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.2361 - val_loss: 1.2288\n",
      "Epoch 129/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.2271 - val_loss: 1.2224\n",
      "Epoch 130/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 1.2172 - val_loss: 1.2164\n",
      "Epoch 131/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.2073 - val_loss: 1.2104\n",
      "Epoch 132/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 1.1975 - val_loss: 1.2039\n",
      "Epoch 133/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.1875 - val_loss: 1.1986\n",
      "Epoch 134/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 1.1781 - val_loss: 1.1921\n",
      "Epoch 135/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.1686 - val_loss: 1.1875\n",
      "Epoch 136/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1613 - val_loss: 1.1819\n",
      "Epoch 137/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1532 - val_loss: 1.1761\n",
      "Epoch 138/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.1451 - val_loss: 1.1702\n",
      "Epoch 139/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.1365 - val_loss: 1.1657\n",
      "Epoch 140/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 1.1288 - val_loss: 1.1602\n",
      "Epoch 141/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.1210 - val_loss: 1.1560\n",
      "Epoch 142/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.1141 - val_loss: 1.1512\n",
      "Epoch 143/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.1069 - val_loss: 1.1454\n",
      "Epoch 144/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 1.0985 - val_loss: 1.1407\n",
      "Epoch 145/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 1.0911 - val_loss: 1.1364\n",
      "Epoch 146/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.0840 - val_loss: 1.1322\n",
      "Epoch 147/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 1.0779 - val_loss: 1.1280\n",
      "Epoch 148/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 1.0714 - val_loss: 1.1232\n",
      "Epoch 149/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0649 - val_loss: 1.1195\n",
      "Epoch 150/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.0593 - val_loss: 1.1156\n",
      "Epoch 151/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 1.0534 - val_loss: 1.1113\n",
      "Epoch 152/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 1.0470 - val_loss: 1.1070\n",
      "Epoch 153/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 1.0411 - val_loss: 1.1041\n",
      "Epoch 154/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 1.0362 - val_loss: 1.1007\n",
      "Epoch 155/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 1.0307 - val_loss: 1.0971\n",
      "Epoch 156/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0256 - val_loss: 1.0937\n",
      "Epoch 157/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 1.0210 - val_loss: 1.0911\n",
      "Epoch 158/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0163 - val_loss: 1.0879\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105==============================] - 0s 40us/sample - loss: 1.0119 - val_loss: 1.0849\n",
      "Epoch 160/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 1.0076 - val_loss: 1.0822\n",
      "Epoch 161/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 1.0032 - val_loss: 1.0790\n",
      "Epoch 162/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.9984 - val_loss: 1.0766\n",
      "Epoch 163/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9944 - val_loss: 1.0731\n",
      "Epoch 164/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9897 - val_loss: 1.0707\n",
      "Epoch 165/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9858 - val_loss: 1.0691\n",
      "Epoch 166/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.9826 - val_loss: 1.0667\n",
      "Epoch 167/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9788 - val_loss: 1.0638\n",
      "Epoch 168/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9751 - val_loss: 1.0619\n",
      "Epoch 169/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9716 - val_loss: 1.0587\n",
      "Epoch 170/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.9672 - val_loss: 1.0559\n",
      "Epoch 171/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.9628 - val_loss: 1.0525\n",
      "Epoch 172/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9580 - val_loss: 1.0509\n",
      "Epoch 173/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9550 - val_loss: 1.0490\n",
      "Epoch 174/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9514 - val_loss: 1.0466\n",
      "Epoch 175/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9481 - val_loss: 1.0449\n",
      "Epoch 176/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9451 - val_loss: 1.0423\n",
      "Epoch 177/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9418 - val_loss: 1.0398\n",
      "Epoch 178/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.9377 - val_loss: 1.0372\n",
      "Epoch 179/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.9344 - val_loss: 1.0337\n",
      "Epoch 180/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.9296 - val_loss: 1.0313\n",
      "Epoch 181/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.9258 - val_loss: 1.0301\n",
      "Epoch 182/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9235 - val_loss: 1.0281\n",
      "Epoch 183/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.9203 - val_loss: 1.0258\n",
      "Epoch 184/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.9173 - val_loss: 1.0235\n",
      "Epoch 185/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.9139 - val_loss: 1.0210\n",
      "Epoch 186/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.9104 - val_loss: 1.0190\n",
      "Epoch 187/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.9077 - val_loss: 1.0170\n",
      "Epoch 188/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.9049 - val_loss: 1.0149\n",
      "Epoch 189/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.9020 - val_loss: 1.0134\n",
      "Epoch 190/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8995 - val_loss: 1.0122\n",
      "Epoch 191/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8974 - val_loss: 1.0092\n",
      "Epoch 192/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8938 - val_loss: 1.0075\n",
      "Epoch 193/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8913 - val_loss: 1.0055\n",
      "Epoch 194/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8887 - val_loss: 1.0041\n",
      "Epoch 195/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8866 - val_loss: 1.0022\n",
      "Epoch 196/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8839 - val_loss: 1.0000\n",
      "Epoch 197/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8815 - val_loss: 0.9991\n",
      "Epoch 198/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8796 - val_loss: 0.9977\n",
      "Epoch 199/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8775 - val_loss: 0.9964\n",
      "Epoch 200/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8749 - val_loss: 0.9947\n",
      "Epoch 201/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8726 - val_loss: 0.9938\n",
      "Epoch 202/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.8711 - val_loss: 0.9925\n",
      "Epoch 203/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8689 - val_loss: 0.9913\n",
      "Epoch 204/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8676 - val_loss: 0.9906\n",
      "Epoch 205/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8663 - val_loss: 0.9899\n",
      "Epoch 206/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8649 - val_loss: 0.9888\n",
      "Epoch 207/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8634 - val_loss: 0.9881\n",
      "Epoch 208/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8621 - val_loss: 0.9868\n",
      "Epoch 209/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8604 - val_loss: 0.9862\n",
      "Epoch 210/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8592 - val_loss: 0.9843\n",
      "Epoch 211/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8573 - val_loss: 0.9821\n",
      "Epoch 212/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8546 - val_loss: 0.9806\n",
      "Epoch 213/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.8525 - val_loss: 0.9793\n",
      "Epoch 214/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8507 - val_loss: 0.9783\n",
      "Epoch 215/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8493 - val_loss: 0.9773\n",
      "Epoch 216/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.8478 - val_loss: 0.9767\n",
      "Epoch 217/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8465 - val_loss: 0.9754\n",
      "Epoch 218/500\n",
      "105/105==============================] - 0s 63us/sample - loss: 0.8445 - val_loss: 0.9743\n",
      "Epoch 219/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.8429 - val_loss: 0.9730\n",
      "Epoch 220/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.8412 - val_loss: 0.9723\n",
      "Epoch 221/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8399 - val_loss: 0.9713\n",
      "Epoch 222/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8386 - val_loss: 0.9699\n",
      "Epoch 223/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8369 - val_loss: 0.9686\n",
      "Epoch 224/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8353 - val_loss: 0.9678\n",
      "Epoch 225/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8344 - val_loss: 0.9670\n",
      "Epoch 226/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8333 - val_loss: 0.9666\n",
      "Epoch 227/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8325 - val_loss: 0.9654\n",
      "Epoch 228/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.8312 - val_loss: 0.9652\n",
      "Epoch 229/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8302 - val_loss: 0.9646\n",
      "Epoch 230/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.8294 - val_loss: 0.9636\n",
      "Epoch 231/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8282 - val_loss: 0.9631\n",
      "Epoch 232/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8275 - val_loss: 0.9625\n",
      "Epoch 233/500\n",
      "105/105==============================] - 0s 64us/sample - loss: 0.8262 - val_loss: 0.9621\n",
      "Epoch 234/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8254 - val_loss: 0.9618\n",
      "Epoch 235/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8248 - val_loss: 0.9619\n",
      "Epoch 236/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8244 - val_loss: 0.9611\n",
      "Epoch 237/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8234 - val_loss: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8227 - val_loss: 0.9596\n",
      "Epoch 239/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8217 - val_loss: 0.9583\n",
      "Epoch 240/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8204 - val_loss: 0.9586\n",
      "Epoch 241/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8202 - val_loss: 0.9581\n",
      "Epoch 242/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8190 - val_loss: 0.9575\n",
      "Epoch 243/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8184 - val_loss: 0.9565\n",
      "Epoch 244/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8174 - val_loss: 0.9563\n",
      "Epoch 245/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8170 - val_loss: 0.9561\n",
      "Epoch 246/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8162 - val_loss: 0.9556\n",
      "Epoch 247/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8154 - val_loss: 0.9549\n",
      "Epoch 248/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8146 - val_loss: 0.9550\n",
      "Epoch 249/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.8140 - val_loss: 0.9538\n",
      "Epoch 250/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.8129 - val_loss: 0.9532\n",
      "Epoch 251/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.8120 - val_loss: 0.9530\n",
      "Epoch 252/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.8115 - val_loss: 0.9522\n",
      "Epoch 253/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8107 - val_loss: 0.9516\n",
      "Epoch 254/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8100 - val_loss: 0.9514\n",
      "Epoch 255/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.8094 - val_loss: 0.9510\n",
      "Epoch 256/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8089 - val_loss: 0.9508\n",
      "Epoch 257/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.8087 - val_loss: 0.9504\n",
      "Epoch 258/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.8080 - val_loss: 0.9497\n",
      "Epoch 259/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8076 - val_loss: 0.9489\n",
      "Epoch 260/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.8071 - val_loss: 0.9482\n",
      "Epoch 261/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8066 - val_loss: 0.9484\n",
      "Epoch 262/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.8064 - val_loss: 0.9479\n",
      "Epoch 263/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8061 - val_loss: 0.9471\n",
      "Epoch 264/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.8050 - val_loss: 0.9473\n",
      "Epoch 265/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.8048 - val_loss: 0.9467\n",
      "Epoch 266/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.8040 - val_loss: 0.9461\n",
      "Epoch 267/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.8033 - val_loss: 0.9463\n",
      "Epoch 268/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.8031 - val_loss: 0.9466\n",
      "Epoch 269/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.8027 - val_loss: 0.9461\n",
      "Epoch 270/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8021 - val_loss: 0.9458\n",
      "Epoch 271/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.8015 - val_loss: 0.9453\n",
      "Epoch 272/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.8010 - val_loss: 0.9450\n",
      "Epoch 273/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.8005 - val_loss: 0.9444\n",
      "Epoch 274/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7999 - val_loss: 0.9438\n",
      "Epoch 275/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7995 - val_loss: 0.9434\n",
      "Epoch 276/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7989 - val_loss: 0.9434\n",
      "Epoch 277/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7986 - val_loss: 0.9430\n",
      "Epoch 278/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7983 - val_loss: 0.9424\n",
      "Epoch 279/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7977 - val_loss: 0.9422\n",
      "Epoch 280/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7973 - val_loss: 0.9419\n",
      "Epoch 281/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7971 - val_loss: 0.9419\n",
      "Epoch 282/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7969 - val_loss: 0.9424\n",
      "Epoch 283/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7968 - val_loss: 0.9416\n",
      "Epoch 284/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7962 - val_loss: 0.9414\n",
      "Epoch 285/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7958 - val_loss: 0.9409\n",
      "Epoch 286/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7953 - val_loss: 0.9407\n",
      "Epoch 287/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7950 - val_loss: 0.9405\n",
      "Epoch 288/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7945 - val_loss: 0.9399\n",
      "Epoch 289/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7946 - val_loss: 0.9404\n",
      "Epoch 290/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7942 - val_loss: 0.9402\n",
      "Epoch 291/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7940 - val_loss: 0.9397\n",
      "Epoch 292/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7937 - val_loss: 0.9402\n",
      "Epoch 293/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7935 - val_loss: 0.9400\n",
      "Epoch 294/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7933 - val_loss: 0.9396\n",
      "Epoch 295/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7931 - val_loss: 0.9391\n",
      "Epoch 296/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7927 - val_loss: 0.9385\n",
      "Epoch 297/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7924 - val_loss: 0.9386\n",
      "Epoch 298/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7921 - val_loss: 0.9384\n",
      "Epoch 299/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7917 - val_loss: 0.9381\n",
      "Epoch 300/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7917 - val_loss: 0.9381\n",
      "Epoch 301/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7915 - val_loss: 0.9378\n",
      "Epoch 302/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7909 - val_loss: 0.9377\n",
      "Epoch 303/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7905 - val_loss: 0.9373\n",
      "Epoch 304/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7901 - val_loss: 0.9372\n",
      "Epoch 305/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7900 - val_loss: 0.9368\n",
      "Epoch 306/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7897 - val_loss: 0.9370\n",
      "Epoch 307/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7895 - val_loss: 0.9369\n",
      "Epoch 308/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7891 - val_loss: 0.9367\n",
      "Epoch 309/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7888 - val_loss: 0.9359\n",
      "Epoch 310/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7885 - val_loss: 0.9366\n",
      "Epoch 311/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7884 - val_loss: 0.9360\n",
      "Epoch 312/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7882 - val_loss: 0.9359\n",
      "Epoch 313/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7878 - val_loss: 0.9357\n",
      "Epoch 314/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7874 - val_loss: 0.9352\n",
      "Epoch 315/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7871 - val_loss: 0.9350\n",
      "Epoch 316/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7870 - val_loss: 0.9349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7869 - val_loss: 0.9348\n",
      "Epoch 318/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7868 - val_loss: 0.9344\n",
      "Epoch 319/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7866 - val_loss: 0.9347\n",
      "Epoch 320/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7867 - val_loss: 0.9351\n",
      "Epoch 321/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7864 - val_loss: 0.9351\n",
      "Epoch 322/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7863 - val_loss: 0.9351\n",
      "Epoch 323/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7861 - val_loss: 0.9351\n",
      "Epoch 324/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7864 - val_loss: 0.9349\n",
      "Epoch 325/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7857 - val_loss: 0.9347\n",
      "Epoch 326/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7855 - val_loss: 0.9343\n",
      "Epoch 327/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7852 - val_loss: 0.9342\n",
      "Epoch 328/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7851 - val_loss: 0.9340\n",
      "Epoch 329/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7849 - val_loss: 0.9340\n",
      "Epoch 330/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7850 - val_loss: 0.9339\n",
      "Epoch 331/500\n",
      "105/105==============================] - 0s 50us/sample - loss: 0.7848 - val_loss: 0.9337\n",
      "Epoch 332/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7847 - val_loss: 0.9339\n",
      "Epoch 333/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7847 - val_loss: 0.9340\n",
      "Epoch 334/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7848 - val_loss: 0.9337\n",
      "Epoch 335/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7845 - val_loss: 0.9338\n",
      "Epoch 336/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7842 - val_loss: 0.9340\n",
      "Epoch 337/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7841 - val_loss: 0.9339\n",
      "Epoch 338/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7839 - val_loss: 0.9336\n",
      "Epoch 339/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7837 - val_loss: 0.9333\n",
      "Epoch 340/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7836 - val_loss: 0.9332\n",
      "Epoch 341/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7837 - val_loss: 0.9335\n",
      "Epoch 342/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7837 - val_loss: 0.9334\n",
      "Epoch 343/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7838 - val_loss: 0.9341\n",
      "Epoch 344/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7836 - val_loss: 0.9339\n",
      "Epoch 345/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7835 - val_loss: 0.9336\n",
      "Epoch 346/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7835 - val_loss: 0.9336\n",
      "Epoch 347/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7834 - val_loss: 0.9337\n",
      "Epoch 348/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7832 - val_loss: 0.9338\n",
      "Epoch 349/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7832 - val_loss: 0.9341\n",
      "Epoch 350/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7832 - val_loss: 0.9341\n",
      "Epoch 351/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7831 - val_loss: 0.9341\n",
      "Epoch 352/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7830 - val_loss: 0.9340\n",
      "Epoch 353/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7832 - val_loss: 0.9336\n",
      "Epoch 354/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7829 - val_loss: 0.9334\n",
      "Epoch 355/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7828 - val_loss: 0.9334\n",
      "Epoch 356/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7828 - val_loss: 0.9333\n",
      "Epoch 357/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7826 - val_loss: 0.9330\n",
      "Epoch 358/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.7824 - val_loss: 0.9331\n",
      "Epoch 359/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7825 - val_loss: 0.9329\n",
      "Epoch 360/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7823 - val_loss: 0.9325\n",
      "Epoch 361/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7823 - val_loss: 0.9328\n",
      "Epoch 362/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7822 - val_loss: 0.9325\n",
      "Epoch 363/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7819 - val_loss: 0.9329\n",
      "Epoch 364/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7820 - val_loss: 0.9328\n",
      "Epoch 365/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7819 - val_loss: 0.9323\n",
      "Epoch 366/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7818 - val_loss: 0.9325\n",
      "Epoch 367/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7819 - val_loss: 0.9325\n",
      "Epoch 368/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7819 - val_loss: 0.9325\n",
      "Epoch 369/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7819 - val_loss: 0.9328\n",
      "Epoch 370/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7818 - val_loss: 0.9328\n",
      "Epoch 371/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7820 - val_loss: 0.9324\n",
      "Epoch 372/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7817 - val_loss: 0.9323\n",
      "Epoch 373/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7817 - val_loss: 0.9322\n",
      "Epoch 374/500\n",
      "105/105==============================] - 0s 59us/sample - loss: 0.7817 - val_loss: 0.9320\n",
      "Epoch 375/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7815 - val_loss: 0.9319\n",
      "Epoch 376/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7815 - val_loss: 0.9320\n",
      "Epoch 377/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7815 - val_loss: 0.9316\n",
      "Epoch 378/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7816 - val_loss: 0.9320\n",
      "Epoch 379/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7815 - val_loss: 0.9325\n",
      "Epoch 380/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7815 - val_loss: 0.9321\n",
      "Epoch 381/500\n",
      "105/105==============================] - 0s 60us/sample - loss: 0.7813 - val_loss: 0.9320\n",
      "Epoch 382/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7812 - val_loss: 0.9320\n",
      "Epoch 383/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7812 - val_loss: 0.9320\n",
      "Epoch 384/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7812 - val_loss: 0.9319\n",
      "Epoch 385/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7811 - val_loss: 0.9319\n",
      "Epoch 386/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7810 - val_loss: 0.9316\n",
      "Epoch 387/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7810 - val_loss: 0.9317\n",
      "Epoch 388/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7809 - val_loss: 0.9319\n",
      "Epoch 389/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7810 - val_loss: 0.9316\n",
      "Epoch 390/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7810 - val_loss: 0.9315\n",
      "Epoch 391/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7809 - val_loss: 0.9315\n",
      "Epoch 392/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7809 - val_loss: 0.9317\n",
      "Epoch 393/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7810 - val_loss: 0.9312\n",
      "Epoch 394/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7809 - val_loss: 0.9314\n",
      "Epoch 395/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7806 - val_loss: 0.9314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7807 - val_loss: 0.9310\n",
      "Epoch 397/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7805 - val_loss: 0.9308\n",
      "Epoch 398/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7803 - val_loss: 0.9311\n",
      "Epoch 399/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7804 - val_loss: 0.9313\n",
      "Epoch 400/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7803 - val_loss: 0.9315\n",
      "Epoch 401/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7804 - val_loss: 0.9317\n",
      "Epoch 402/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7805 - val_loss: 0.9318\n",
      "Epoch 403/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7804 - val_loss: 0.9315\n",
      "Epoch 404/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7803 - val_loss: 0.9310\n",
      "Epoch 405/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7802 - val_loss: 0.9310\n",
      "Epoch 406/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7802 - val_loss: 0.9308\n",
      "Epoch 407/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7801 - val_loss: 0.9309\n",
      "Epoch 408/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7802 - val_loss: 0.9307\n",
      "Epoch 409/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7804 - val_loss: 0.9306\n",
      "Epoch 410/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7801 - val_loss: 0.9308\n",
      "Epoch 411/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7801 - val_loss: 0.9311\n",
      "Epoch 412/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7802 - val_loss: 0.9313\n",
      "Epoch 413/500\n",
      "105/105==============================] - 0s 49us/sample - loss: 0.7802 - val_loss: 0.9315\n",
      "Epoch 414/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7801 - val_loss: 0.9314\n",
      "Epoch 415/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7801 - val_loss: 0.9311\n",
      "Epoch 416/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7802 - val_loss: 0.9309\n",
      "Epoch 417/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7801 - val_loss: 0.9308\n",
      "Epoch 418/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7800 - val_loss: 0.9309\n",
      "Epoch 419/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7800 - val_loss: 0.9309\n",
      "Epoch 420/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7800 - val_loss: 0.9305\n",
      "Epoch 421/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7800 - val_loss: 0.9308\n",
      "Epoch 422/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7800 - val_loss: 0.9307\n",
      "Epoch 423/500\n",
      "105/105==============================] - 0s 58us/sample - loss: 0.7801 - val_loss: 0.9306\n",
      "Epoch 424/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7799 - val_loss: 0.9303\n",
      "Epoch 425/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7799 - val_loss: 0.9303\n",
      "Epoch 426/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7799 - val_loss: 0.9302\n",
      "Epoch 427/500\n",
      "105/105==============================] - 0s 47us/sample - loss: 0.7798 - val_loss: 0.9303\n",
      "Epoch 428/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7799 - val_loss: 0.9300\n",
      "Epoch 429/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7798 - val_loss: 0.9302\n",
      "Epoch 430/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7798 - val_loss: 0.9306\n",
      "Epoch 431/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7797 - val_loss: 0.9305\n",
      "Epoch 432/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7797 - val_loss: 0.9304\n",
      "Epoch 433/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7797 - val_loss: 0.9304\n",
      "Epoch 434/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7799 - val_loss: 0.9306\n",
      "Epoch 435/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7799 - val_loss: 0.9303\n",
      "Epoch 436/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9306\n",
      "Epoch 437/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7796 - val_loss: 0.9305\n",
      "Epoch 438/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7797 - val_loss: 0.9305\n",
      "Epoch 439/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7797 - val_loss: 0.9306\n",
      "Epoch 440/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7796 - val_loss: 0.9304\n",
      "Epoch 441/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7796 - val_loss: 0.9306\n",
      "Epoch 442/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7797 - val_loss: 0.9304\n",
      "Epoch 443/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7796 - val_loss: 0.9304\n",
      "Epoch 444/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7796 - val_loss: 0.9303\n",
      "Epoch 445/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7797 - val_loss: 0.9308\n",
      "Epoch 446/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7796 - val_loss: 0.9309\n",
      "Epoch 447/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9311\n",
      "Epoch 448/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7797 - val_loss: 0.9311\n",
      "Epoch 449/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7796 - val_loss: 0.9313\n",
      "Epoch 450/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7797 - val_loss: 0.9311\n",
      "Epoch 451/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7796 - val_loss: 0.9316\n",
      "Epoch 452/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7796 - val_loss: 0.9317\n",
      "Epoch 453/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7796 - val_loss: 0.9318\n",
      "Epoch 454/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7798 - val_loss: 0.9322\n",
      "Epoch 455/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7796 - val_loss: 0.9324\n",
      "Epoch 456/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7796 - val_loss: 0.9329\n",
      "Epoch 457/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7796 - val_loss: 0.9328\n",
      "Epoch 458/500\n",
      "105/105==============================] - 0s 56us/sample - loss: 0.7797 - val_loss: 0.9325\n",
      "Epoch 459/500\n",
      "105/105==============================] - 0s 37us/sample - loss: 0.7795 - val_loss: 0.9325\n",
      "Epoch 460/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7795 - val_loss: 0.9323\n",
      "Epoch 461/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7795 - val_loss: 0.9322\n",
      "Epoch 462/500\n",
      "105/105==============================] - 0s 45us/sample - loss: 0.7796 - val_loss: 0.9321\n",
      "Epoch 463/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7795 - val_loss: 0.9322\n",
      "Epoch 464/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7797 - val_loss: 0.9328\n",
      "Epoch 465/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7795 - val_loss: 0.9329\n",
      "Epoch 466/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7795 - val_loss: 0.9330\n",
      "Epoch 467/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7795 - val_loss: 0.9328\n",
      "Epoch 468/500\n",
      "105/105==============================] - 0s 54us/sample - loss: 0.7795 - val_loss: 0.9328\n",
      "Epoch 469/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7796 - val_loss: 0.9327\n",
      "Epoch 470/500\n",
      "105/105==============================] - 0s 42us/sample - loss: 0.7795 - val_loss: 0.9327\n",
      "Epoch 471/500\n",
      "105/105==============================] - 0s 51us/sample - loss: 0.7796 - val_loss: 0.9326\n",
      "Epoch 472/500\n",
      "105/105==============================] - 0s 62us/sample - loss: 0.7796 - val_loss: 0.9332\n",
      "Epoch 473/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9334\n",
      "Epoch 474/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7796 - val_loss: 0.9334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9335\n",
      "Epoch 476/500\n",
      "105/105==============================] - 0s 61us/sample - loss: 0.7796 - val_loss: 0.9332\n",
      "Epoch 477/500\n",
      "105/105==============================] - 0s 48us/sample - loss: 0.7796 - val_loss: 0.9338\n",
      "Epoch 478/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7797 - val_loss: 0.9338\n",
      "Epoch 479/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7796 - val_loss: 0.9338\n",
      "Epoch 480/500\n",
      "105/105==============================] - 0s 36us/sample - loss: 0.7797 - val_loss: 0.9339\n",
      "Epoch 481/500\n",
      "105/105==============================] - 0s 53us/sample - loss: 0.7797 - val_loss: 0.9343\n",
      "Epoch 482/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7797 - val_loss: 0.9341\n",
      "Epoch 483/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7796 - val_loss: 0.9340\n",
      "Epoch 484/500\n",
      "105/105==============================] - 0s 44us/sample - loss: 0.7796 - val_loss: 0.9341\n",
      "Epoch 485/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7796 - val_loss: 0.9340\n",
      "Epoch 486/500\n",
      "105/105==============================] - 0s 57us/sample - loss: 0.7797 - val_loss: 0.9336\n",
      "Epoch 487/500\n",
      "105/105==============================] - 0s 55us/sample - loss: 0.7796 - val_loss: 0.9334\n",
      "Epoch 488/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7796 - val_loss: 0.9336\n",
      "Epoch 489/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7796 - val_loss: 0.9334\n",
      "Epoch 490/500\n",
      "105/105==============================] - 0s 38us/sample - loss: 0.7796 - val_loss: 0.9335\n",
      "Epoch 491/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7798 - val_loss: 0.9335\n",
      "Epoch 492/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7797 - val_loss: 0.9334\n",
      "Epoch 493/500\n",
      "105/105==============================] - 0s 40us/sample - loss: 0.7796 - val_loss: 0.9333\n",
      "Epoch 494/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7798 - val_loss: 0.9333\n",
      "Epoch 495/500\n",
      "105/105==============================] - 0s 52us/sample - loss: 0.7796 - val_loss: 0.9331\n",
      "Epoch 496/500\n",
      "105/105==============================] - 0s 41us/sample - loss: 0.7795 - val_loss: 0.9330\n",
      "Epoch 497/500\n",
      "105/105==============================] - 0s 39us/sample - loss: 0.7795 - val_loss: 0.9328\n",
      "Epoch 498/500\n",
      "105/105==============================] - 0s 43us/sample - loss: 0.7795 - val_loss: 0.9328\n",
      "Epoch 499/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7795 - val_loss: 0.9330\n",
      "Epoch 500/500\n",
      "105/105==============================] - 0s 46us/sample - loss: 0.7795 - val_loss: 0.9328\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "callback_list = [TensorBoard()]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=500, \n",
    "                    callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, len(history.history['loss'])+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(784,))\n",
    "hidden = Dense(100)(input)\n",
    "output = Dense(10)(hidden)\n",
    "\n",
    "model = Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](model_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='model_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](model_2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
