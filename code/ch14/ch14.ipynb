{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장. 텐서플로의 구조 자세히 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haesun/anaconda3/envs/python-ml/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2019-03-14 \n",
      "\n",
      "CPython 3.7.2\n",
      "IPython 7.3.0\n",
      "\n",
      "numpy 1.16.1\n",
      "tensorflow 2.0.0-alpha0\n",
      "matplotlib 3.0.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -v -p numpy,tensorflow,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로의 랭크와 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텐서의 랭크와 크기를 확인하는 방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크기: () (4,) (2, 2)\n",
      "랭크: 0 1 2\n"
     ]
    }
   ],
   "source": [
    "## t1, t2, t3 텐서를 정의합니다.\n",
    "t1 = tf.constant(np.pi)\n",
    "t2 = tf.constant([1, 2, 3, 4])\n",
    "t3 = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "## 랭크를 구합니다.\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)\n",
    "\n",
    "## 크기를 구합니다\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "print('크기:', s1, s2, s3)\n",
    "\n",
    "print('랭크:', \n",
    "      r1.numpy(), \n",
    "      r2.numpy(), \n",
    "      r3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로의 계산 그래프 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2) \n",
    "c = tf.constant(3) \n",
    "\n",
    "z = 2*(a-b) + c\n",
    "\n",
    "print('2*(a-b)+c => ', z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "## 텐서플로 1.x 방식\n",
    "g = tf.Graph()\n",
    " \n",
    "## 그래프에 노드를 추가합니다.\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    \n",
    "## 그래프를 실행합니다.\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c => ', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_func():\n",
    "    a = tf.constant(1)\n",
    "    b = tf.constant(2) \n",
    "    c = tf.constant(3) \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "print('2*(a-b)+c => ', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.eager.def_function.Function'>\n"
     ]
    }
   ],
   "source": [
    "print(simple_func.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "def simple_func():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    return z\n",
    "\n",
    "simple_func = tf.function(simple_func)\n",
    "\n",
    "print('2*(a-b)+c => ', simple_func().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func = simple_func.get_concrete_function()\n",
    "con_func.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"add\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_func.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로의 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w1:0' shape=(2, 4) dtype=int64>\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w1')\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'w1/Initializer/initial_value' type=Const>,\n",
       " <tf.Operation 'w1' type=VarHandleOp>,\n",
       " <tf.Operation 'w1/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'w1/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'w1/Read/ReadVariableOp' type=ReadVariableOp>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"init\"\n",
      "op: \"NoOp\"\n",
      "input: \"^w1/Assign\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    print(init.node_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2, 4), dtype=int64)\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "with g1.as_default():\n",
    "    w1 = w1 + 1\n",
    "    print(w1)\n",
    "    \n",
    "with tf.compat.v1.Session(graph=g1) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 8]]), name='w1')\n",
    "    w1 = w1.assign(w1 + 1)\n",
    "\n",
    "with tf.compat.v1.Session(graph=g2) as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])>\n"
     ]
    }
   ],
   "source": [
    "w2 = tf.Variable(np.array([[1, 2, 3, 4],\n",
    "                          [5, 6, 7, 8]]), name='w2')\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4 5]\n",
      " [6 7 8 9]]\n",
      "[[ 3  4  5  6]\n",
      " [ 7  8  9 10]]\n"
     ]
    }
   ],
   "source": [
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())\n",
    "w2.assign(w2 + 1)\n",
    "print(w2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w2:0' shape=(2, 4) dtype=int64, numpy=\n",
      "array([[ 3,  4,  5,  6],\n",
      "       [ 7,  8,  9, 10]])>\n"
     ]
    }
   ],
   "source": [
    "print(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 API 자세히 배우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 랜덤한 회귀용 예제 데이터셋을 만듭니다\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=2, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0, \n",
    "                             scale=(0.5 + t*t/3), \n",
    "                             size=None)\n",
    "        y.append(r)\n",
    "    return  x, 1.726*x -0.84 + np.array(y)\n",
    "\n",
    "\n",
    "x, y = make_random_data() \n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.savefig('../../gen_images/14_03.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[:150], y[:150]\n",
    "x_test, y_test = x[150:], y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=10, activation=\"relu\", input_dim=1))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/300\n",
      "105/105 [==============================] - 0s 2ms/sample - loss: 5.8134 - val_loss: 3.9157\n",
      "Epoch 2/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 5.6878 - val_loss: 3.8465\n",
      "Epoch 3/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 5.5651 - val_loss: 3.7792\n",
      "Epoch 4/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 5.4404 - val_loss: 3.7131\n",
      "Epoch 5/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 5.3222 - val_loss: 3.6517\n",
      "Epoch 6/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 5.2056 - val_loss: 3.5948\n",
      "Epoch 7/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 5.1016 - val_loss: 3.5375\n",
      "Epoch 8/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 4.9951 - val_loss: 3.4764\n",
      "Epoch 9/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 4.8895 - val_loss: 3.4237\n",
      "Epoch 10/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 4.7866 - val_loss: 3.3691\n",
      "Epoch 11/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 4.6850 - val_loss: 3.3140\n",
      "Epoch 12/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 4.5903 - val_loss: 3.2642\n",
      "Epoch 13/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 4.4944 - val_loss: 3.2148\n",
      "Epoch 14/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 4.3959 - val_loss: 3.1594\n",
      "Epoch 15/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 4.2935 - val_loss: 3.1070\n",
      "Epoch 16/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 4.1937 - val_loss: 3.0596\n",
      "Epoch 17/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 4.1131 - val_loss: 3.0140\n",
      "Epoch 18/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 4.0261 - val_loss: 2.9680\n",
      "Epoch 19/300\n",
      "105/105 [==============================] - 0s 61us/sample - loss: 3.9442 - val_loss: 2.9238\n",
      "Epoch 20/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 3.8607 - val_loss: 2.8788\n",
      "Epoch 21/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 3.7730 - val_loss: 2.8377\n",
      "Epoch 22/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 3.6922 - val_loss: 2.7958\n",
      "Epoch 23/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 3.6152 - val_loss: 2.7579\n",
      "Epoch 24/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 3.5502 - val_loss: 2.7154\n",
      "Epoch 25/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 3.4760 - val_loss: 2.6768\n",
      "Epoch 26/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 3.4005 - val_loss: 2.6371\n",
      "Epoch 27/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 3.3331 - val_loss: 2.5957\n",
      "Epoch 28/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 3.2650 - val_loss: 2.5607\n",
      "Epoch 29/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 3.2006 - val_loss: 2.5272\n",
      "Epoch 30/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 3.1381 - val_loss: 2.4883\n",
      "Epoch 31/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 3.0655 - val_loss: 2.4532\n",
      "Epoch 32/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 2.9958 - val_loss: 2.4140\n",
      "Epoch 33/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 2.9317 - val_loss: 2.3788\n",
      "Epoch 34/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 2.8759 - val_loss: 2.3496\n",
      "Epoch 35/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 2.8208 - val_loss: 2.3141\n",
      "Epoch 36/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 2.7641 - val_loss: 2.2817\n",
      "Epoch 37/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 2.7093 - val_loss: 2.2520\n",
      "Epoch 38/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 2.6562 - val_loss: 2.2248\n",
      "Epoch 39/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 2.6047 - val_loss: 2.1952\n",
      "Epoch 40/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 2.5525 - val_loss: 2.1639\n",
      "Epoch 41/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 2.4935 - val_loss: 2.1365\n",
      "Epoch 42/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 2.4413 - val_loss: 2.1077\n",
      "Epoch 43/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 2.3908 - val_loss: 2.0789\n",
      "Epoch 44/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 2.3424 - val_loss: 2.0516\n",
      "Epoch 45/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 2.2926 - val_loss: 2.0238\n",
      "Epoch 46/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 2.2438 - val_loss: 1.9938\n",
      "Epoch 47/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 2.1967 - val_loss: 1.9667\n",
      "Epoch 48/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 2.1496 - val_loss: 1.9396\n",
      "Epoch 49/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 2.1031 - val_loss: 1.9134\n",
      "Epoch 50/300\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 2.0553 - val_loss: 1.8870\n",
      "Epoch 51/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 2.0062 - val_loss: 1.8600\n",
      "Epoch 52/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.9621 - val_loss: 1.8360\n",
      "Epoch 53/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.9233 - val_loss: 1.8142\n",
      "Epoch 54/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.8849 - val_loss: 1.7916\n",
      "Epoch 55/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 1.8482 - val_loss: 1.7657\n",
      "Epoch 56/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.8058 - val_loss: 1.7444\n",
      "Epoch 57/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.7676 - val_loss: 1.7178\n",
      "Epoch 58/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.7308 - val_loss: 1.6993\n",
      "Epoch 59/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 1.6991 - val_loss: 1.6799\n",
      "Epoch 60/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.6652 - val_loss: 1.6610\n",
      "Epoch 61/300\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 1.6338 - val_loss: 1.6422\n",
      "Epoch 62/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.6019 - val_loss: 1.6205\n",
      "Epoch 63/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.5664 - val_loss: 1.6054\n",
      "Epoch 64/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 1.5401 - val_loss: 1.5826\n",
      "Epoch 65/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.5104 - val_loss: 1.5657\n",
      "Epoch 66/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.4834 - val_loss: 1.5484\n",
      "Epoch 67/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.4576 - val_loss: 1.5323\n",
      "Epoch 68/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.4305 - val_loss: 1.5135\n",
      "Epoch 69/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.4055 - val_loss: 1.4971\n",
      "Epoch 70/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.3810 - val_loss: 1.4834\n",
      "Epoch 71/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 1.3590 - val_loss: 1.4661\n",
      "Epoch 72/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.3359 - val_loss: 1.4506\n",
      "Epoch 73/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.3145 - val_loss: 1.4353\n",
      "Epoch 74/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.2916 - val_loss: 1.4178\n",
      "Epoch 75/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.2704 - val_loss: 1.4017\n",
      "Epoch 76/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.2501 - val_loss: 1.3894\n",
      "Epoch 77/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.2311 - val_loss: 1.3754\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 72us/sample - loss: 1.2122 - val_loss: 1.3605\n",
      "Epoch 79/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 1.1921 - val_loss: 1.3479\n",
      "Epoch 80/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.1747 - val_loss: 1.3362\n",
      "Epoch 81/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.1574 - val_loss: 1.3246\n",
      "Epoch 82/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.1423 - val_loss: 1.3140\n",
      "Epoch 83/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.1282 - val_loss: 1.3024\n",
      "Epoch 84/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 1.1142 - val_loss: 1.2937\n",
      "Epoch 85/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.1021 - val_loss: 1.2811\n",
      "Epoch 86/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 1.0858 - val_loss: 1.2677\n",
      "Epoch 87/300\n",
      "105/105 [==============================] - 0s 126us/sample - loss: 1.0724 - val_loss: 1.2592\n",
      "Epoch 88/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 1.0612 - val_loss: 1.2495\n",
      "Epoch 89/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 1.0497 - val_loss: 1.2372\n",
      "Epoch 90/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 1.0366 - val_loss: 1.2285\n",
      "Epoch 91/300\n",
      "105/105 [==============================] - 0s 105us/sample - loss: 1.0237 - val_loss: 1.2186\n",
      "Epoch 92/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.0124 - val_loss: 1.2115\n",
      "Epoch 93/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.0032 - val_loss: 1.2036\n",
      "Epoch 94/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.9930 - val_loss: 1.1941\n",
      "Epoch 95/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.9826 - val_loss: 1.1848\n",
      "Epoch 96/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.9724 - val_loss: 1.1745\n",
      "Epoch 97/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.9626 - val_loss: 1.1673\n",
      "Epoch 98/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.9526 - val_loss: 1.1593\n",
      "Epoch 99/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.9445 - val_loss: 1.1524\n",
      "Epoch 100/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.9367 - val_loss: 1.1440\n",
      "Epoch 101/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.9291 - val_loss: 1.1385\n",
      "Epoch 102/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.9224 - val_loss: 1.1310\n",
      "Epoch 103/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.9129 - val_loss: 1.1244\n",
      "Epoch 104/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.9068 - val_loss: 1.1187\n",
      "Epoch 105/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.9000 - val_loss: 1.1110\n",
      "Epoch 106/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8932 - val_loss: 1.1045\n",
      "Epoch 107/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8882 - val_loss: 1.1000\n",
      "Epoch 108/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8832 - val_loss: 1.0948\n",
      "Epoch 109/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8783 - val_loss: 1.0887\n",
      "Epoch 110/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8722 - val_loss: 1.0837\n",
      "Epoch 111/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8672 - val_loss: 1.0778\n",
      "Epoch 112/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.8620 - val_loss: 1.0723\n",
      "Epoch 113/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.8575 - val_loss: 1.0678\n",
      "Epoch 114/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.8526 - val_loss: 1.0659\n",
      "Epoch 115/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8501 - val_loss: 1.0599\n",
      "Epoch 116/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8457 - val_loss: 1.0560\n",
      "Epoch 117/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8413 - val_loss: 1.0523\n",
      "Epoch 118/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.8382 - val_loss: 1.0456\n",
      "Epoch 119/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8335 - val_loss: 1.0427\n",
      "Epoch 120/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.8303 - val_loss: 1.0390\n",
      "Epoch 121/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.8276 - val_loss: 1.0356\n",
      "Epoch 122/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8253 - val_loss: 1.0330\n",
      "Epoch 123/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.8235 - val_loss: 1.0290\n",
      "Epoch 124/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.8204 - val_loss: 1.0218\n",
      "Epoch 125/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8161 - val_loss: 1.0185\n",
      "Epoch 126/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.8138 - val_loss: 1.0146\n",
      "Epoch 127/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8110 - val_loss: 1.0126\n",
      "Epoch 128/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.8087 - val_loss: 1.0090\n",
      "Epoch 129/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.8061 - val_loss: 1.0060\n",
      "Epoch 130/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.8040 - val_loss: 1.0013\n",
      "Epoch 131/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.8015 - val_loss: 0.9983\n",
      "Epoch 132/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7998 - val_loss: 0.9955\n",
      "Epoch 133/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7981 - val_loss: 0.9930\n",
      "Epoch 134/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.7954 - val_loss: 0.9901\n",
      "Epoch 135/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7936 - val_loss: 0.9875\n",
      "Epoch 136/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7912 - val_loss: 0.9837\n",
      "Epoch 137/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7889 - val_loss: 0.9795\n",
      "Epoch 138/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7867 - val_loss: 0.9776\n",
      "Epoch 139/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7850 - val_loss: 0.9756\n",
      "Epoch 140/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7837 - val_loss: 0.9724\n",
      "Epoch 141/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7821 - val_loss: 0.9706\n",
      "Epoch 142/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7813 - val_loss: 0.9694\n",
      "Epoch 143/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7805 - val_loss: 0.9671\n",
      "Epoch 144/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.7788 - val_loss: 0.9654\n",
      "Epoch 145/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7772 - val_loss: 0.9638\n",
      "Epoch 146/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7761 - val_loss: 0.9617\n",
      "Epoch 147/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7752 - val_loss: 0.9613\n",
      "Epoch 148/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7749 - val_loss: 0.9595\n",
      "Epoch 149/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7740 - val_loss: 0.9577\n",
      "Epoch 150/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7728 - val_loss: 0.9558\n",
      "Epoch 151/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7717 - val_loss: 0.9559\n",
      "Epoch 152/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7713 - val_loss: 0.9546\n",
      "Epoch 153/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7702 - val_loss: 0.9520\n",
      "Epoch 154/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7688 - val_loss: 0.9510\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7684 - val_loss: 0.9483\n",
      "Epoch 156/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7673 - val_loss: 0.9471\n",
      "Epoch 157/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7669 - val_loss: 0.9459\n",
      "Epoch 158/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7660 - val_loss: 0.9451\n",
      "Epoch 159/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7655 - val_loss: 0.9431\n",
      "Epoch 160/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7643 - val_loss: 0.9406\n",
      "Epoch 161/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7634 - val_loss: 0.9402\n",
      "Epoch 162/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7631 - val_loss: 0.9396\n",
      "Epoch 163/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7624 - val_loss: 0.9379\n",
      "Epoch 164/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7614 - val_loss: 0.9355\n",
      "Epoch 165/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7606 - val_loss: 0.9350\n",
      "Epoch 166/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7600 - val_loss: 0.9333\n",
      "Epoch 167/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7599 - val_loss: 0.9307\n",
      "Epoch 168/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7586 - val_loss: 0.9306\n",
      "Epoch 169/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7589 - val_loss: 0.9298\n",
      "Epoch 170/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7584 - val_loss: 0.9291\n",
      "Epoch 171/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7580 - val_loss: 0.9278\n",
      "Epoch 172/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7573 - val_loss: 0.9268\n",
      "Epoch 173/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7568 - val_loss: 0.9253\n",
      "Epoch 174/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7564 - val_loss: 0.9245\n",
      "Epoch 175/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7560 - val_loss: 0.9228\n",
      "Epoch 176/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7554 - val_loss: 0.9220\n",
      "Epoch 177/300\n",
      "105/105 [==============================] - 0s 90us/sample - loss: 0.7552 - val_loss: 0.9225\n",
      "Epoch 178/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7553 - val_loss: 0.9215\n",
      "Epoch 179/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7550 - val_loss: 0.9203\n",
      "Epoch 180/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7545 - val_loss: 0.9202\n",
      "Epoch 181/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7546 - val_loss: 0.9197\n",
      "Epoch 182/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7543 - val_loss: 0.9186\n",
      "Epoch 183/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7538 - val_loss: 0.9182\n",
      "Epoch 184/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7538 - val_loss: 0.9188\n",
      "Epoch 185/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7536 - val_loss: 0.9178\n",
      "Epoch 186/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7536 - val_loss: 0.9167\n",
      "Epoch 187/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7532 - val_loss: 0.9140\n",
      "Epoch 188/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7523 - val_loss: 0.9121\n",
      "Epoch 189/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7517 - val_loss: 0.9111\n",
      "Epoch 190/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7513 - val_loss: 0.9111\n",
      "Epoch 191/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7512 - val_loss: 0.9114\n",
      "Epoch 192/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7512 - val_loss: 0.9116\n",
      "Epoch 193/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7513 - val_loss: 0.9106\n",
      "Epoch 194/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7509 - val_loss: 0.9097\n",
      "Epoch 195/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7509 - val_loss: 0.9088\n",
      "Epoch 196/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7504 - val_loss: 0.9084\n",
      "Epoch 197/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7502 - val_loss: 0.9063\n",
      "Epoch 198/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7495 - val_loss: 0.9052\n",
      "Epoch 199/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7491 - val_loss: 0.9030\n",
      "Epoch 200/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7487 - val_loss: 0.9027\n",
      "Epoch 201/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7486 - val_loss: 0.9010\n",
      "Epoch 202/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7483 - val_loss: 0.9009\n",
      "Epoch 203/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7482 - val_loss: 0.9007\n",
      "Epoch 204/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7484 - val_loss: 0.8991\n",
      "Epoch 205/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7477 - val_loss: 0.8991\n",
      "Epoch 206/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7476 - val_loss: 0.8977\n",
      "Epoch 207/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7472 - val_loss: 0.8978\n",
      "Epoch 208/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7475 - val_loss: 0.8974\n",
      "Epoch 209/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7471 - val_loss: 0.8968\n",
      "Epoch 210/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7470 - val_loss: 0.8965\n",
      "Epoch 211/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7469 - val_loss: 0.8980\n",
      "Epoch 212/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7470 - val_loss: 0.8979\n",
      "Epoch 213/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7469 - val_loss: 0.8976\n",
      "Epoch 214/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7471 - val_loss: 0.8969\n",
      "Epoch 215/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7469 - val_loss: 0.8966\n",
      "Epoch 216/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7471 - val_loss: 0.8964\n",
      "Epoch 217/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7466 - val_loss: 0.8953\n",
      "Epoch 218/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7463 - val_loss: 0.8950\n",
      "Epoch 219/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7463 - val_loss: 0.8946\n",
      "Epoch 220/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7463 - val_loss: 0.8941\n",
      "Epoch 221/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7462 - val_loss: 0.8934\n",
      "Epoch 222/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7459 - val_loss: 0.8937\n",
      "Epoch 223/300\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.7464 - val_loss: 0.8935\n",
      "Epoch 224/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7460 - val_loss: 0.8937\n",
      "Epoch 225/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7458 - val_loss: 0.8924\n",
      "Epoch 226/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7456 - val_loss: 0.8901\n",
      "Epoch 227/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.7451 - val_loss: 0.8901\n",
      "Epoch 228/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7450 - val_loss: 0.8898\n",
      "Epoch 229/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7450 - val_loss: 0.8891\n",
      "Epoch 230/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7453 - val_loss: 0.8886\n",
      "Epoch 231/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7447 - val_loss: 0.8883\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7448 - val_loss: 0.8887\n",
      "Epoch 233/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7447 - val_loss: 0.8881\n",
      "Epoch 234/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7452 - val_loss: 0.8894\n",
      "Epoch 235/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7445 - val_loss: 0.8889\n",
      "Epoch 236/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7445 - val_loss: 0.8888\n",
      "Epoch 237/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7445 - val_loss: 0.8890\n",
      "Epoch 238/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7445 - val_loss: 0.8896\n",
      "Epoch 239/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7444 - val_loss: 0.8899\n",
      "Epoch 240/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7443 - val_loss: 0.8895\n",
      "Epoch 241/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7440 - val_loss: 0.8900\n",
      "Epoch 242/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7442 - val_loss: 0.8897\n",
      "Epoch 243/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7441 - val_loss: 0.8899\n",
      "Epoch 244/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7441 - val_loss: 0.8901\n",
      "Epoch 245/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7442 - val_loss: 0.8889\n",
      "Epoch 246/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7444 - val_loss: 0.8891\n",
      "Epoch 247/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7439 - val_loss: 0.8880\n",
      "Epoch 248/300\n",
      "105/105 [==============================] - 0s 60us/sample - loss: 0.7438 - val_loss: 0.8878\n",
      "Epoch 249/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7436 - val_loss: 0.8876\n",
      "Epoch 250/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7440 - val_loss: 0.8887\n",
      "Epoch 251/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7435 - val_loss: 0.8878\n",
      "Epoch 252/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7434 - val_loss: 0.8877\n",
      "Epoch 253/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7433 - val_loss: 0.8870\n",
      "Epoch 254/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7435 - val_loss: 0.8866\n",
      "Epoch 255/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7437 - val_loss: 0.8861\n",
      "Epoch 256/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7431 - val_loss: 0.8873\n",
      "Epoch 257/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7434 - val_loss: 0.8873\n",
      "Epoch 258/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7433 - val_loss: 0.8875\n",
      "Epoch 259/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7432 - val_loss: 0.8881\n",
      "Epoch 260/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7431 - val_loss: 0.8867\n",
      "Epoch 261/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7431 - val_loss: 0.8864\n",
      "Epoch 262/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7428 - val_loss: 0.8866\n",
      "Epoch 263/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.7427 - val_loss: 0.8876\n",
      "Epoch 264/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7428 - val_loss: 0.8864\n",
      "Epoch 265/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7425 - val_loss: 0.8860\n",
      "Epoch 266/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7426 - val_loss: 0.8863\n",
      "Epoch 267/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7424 - val_loss: 0.8858\n",
      "Epoch 268/300\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.7425 - val_loss: 0.8858\n",
      "Epoch 269/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7427 - val_loss: 0.8865\n",
      "Epoch 270/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7426 - val_loss: 0.8865\n",
      "Epoch 271/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7423 - val_loss: 0.8860\n",
      "Epoch 272/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7425 - val_loss: 0.8859\n",
      "Epoch 273/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7423 - val_loss: 0.8853\n",
      "Epoch 274/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7422 - val_loss: 0.8859\n",
      "Epoch 275/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7421 - val_loss: 0.8863\n",
      "Epoch 276/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7420 - val_loss: 0.8870\n",
      "Epoch 277/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7427 - val_loss: 0.8864\n",
      "Epoch 278/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.7419 - val_loss: 0.8863\n",
      "Epoch 279/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7421 - val_loss: 0.8875\n",
      "Epoch 280/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7424 - val_loss: 0.8878\n",
      "Epoch 281/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7424 - val_loss: 0.8873\n",
      "Epoch 282/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7421 - val_loss: 0.8868\n",
      "Epoch 283/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7420 - val_loss: 0.8862\n",
      "Epoch 284/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7417 - val_loss: 0.8859\n",
      "Epoch 285/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7418 - val_loss: 0.8850\n",
      "Epoch 286/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7416 - val_loss: 0.8845\n",
      "Epoch 287/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7417 - val_loss: 0.8852\n",
      "Epoch 288/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7417 - val_loss: 0.8861\n",
      "Epoch 289/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7416 - val_loss: 0.8851\n",
      "Epoch 290/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7418 - val_loss: 0.8854\n",
      "Epoch 291/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.7413 - val_loss: 0.8850\n",
      "Epoch 292/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.7414 - val_loss: 0.8855\n",
      "Epoch 293/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7413 - val_loss: 0.8858\n",
      "Epoch 294/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7414 - val_loss: 0.8869\n",
      "Epoch 295/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7414 - val_loss: 0.8869\n",
      "Epoch 296/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7415 - val_loss: 0.8860\n",
      "Epoch 297/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7412 - val_loss: 0.8861\n",
      "Epoch 298/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7414 - val_loss: 0.8868\n",
      "Epoch 299/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7415 - val_loss: 0.8865\n",
      "Epoch 300/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7414 - val_loss: 0.8873\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=300, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1, 300+1)\n",
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('../../gen_images/14_04.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input = Input(shape=(1,))\n",
    "hidden = Dense(10, activation='relu')(input)\n",
    "output = Dense(1)(hidden)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/300\n",
      "105/105 [==============================] - 0s 1ms/sample - loss: 5.8730 - val_loss: 3.3948\n",
      "Epoch 2/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 5.7470 - val_loss: 3.3385\n",
      "Epoch 3/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 5.6171 - val_loss: 3.2804\n",
      "Epoch 4/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 5.4853 - val_loss: 3.2196\n",
      "Epoch 5/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 5.3485 - val_loss: 3.1666\n",
      "Epoch 6/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 5.2297 - val_loss: 3.1203\n",
      "Epoch 7/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 5.1246 - val_loss: 3.0681\n",
      "Epoch 8/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 5.0048 - val_loss: 3.0236\n",
      "Epoch 9/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 4.9057 - val_loss: 2.9799\n",
      "Epoch 10/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 4.8081 - val_loss: 2.9353\n",
      "Epoch 11/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 4.7079 - val_loss: 2.8917\n",
      "Epoch 12/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 4.6081 - val_loss: 2.8499\n",
      "Epoch 13/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 4.5135 - val_loss: 2.8104\n",
      "Epoch 14/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 4.4222 - val_loss: 2.7691\n",
      "Epoch 15/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 4.3302 - val_loss: 2.7285\n",
      "Epoch 16/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 4.2359 - val_loss: 2.6878\n",
      "Epoch 17/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 4.1439 - val_loss: 2.6558\n",
      "Epoch 18/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 4.0731 - val_loss: 2.6247\n",
      "Epoch 19/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 4.0005 - val_loss: 2.5889\n",
      "Epoch 20/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 3.9170 - val_loss: 2.5510\n",
      "Epoch 21/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 3.8296 - val_loss: 2.5161\n",
      "Epoch 22/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 3.7501 - val_loss: 2.4804\n",
      "Epoch 23/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 3.6666 - val_loss: 2.4458\n",
      "Epoch 24/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 3.5874 - val_loss: 2.4172\n",
      "Epoch 25/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 3.5222 - val_loss: 2.3887\n",
      "Epoch 26/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 3.4601 - val_loss: 2.3606\n",
      "Epoch 27/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 3.3974 - val_loss: 2.3342\n",
      "Epoch 28/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 3.3375 - val_loss: 2.3087\n",
      "Epoch 29/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 3.2794 - val_loss: 2.2812\n",
      "Epoch 30/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 3.2158 - val_loss: 2.2540\n",
      "Epoch 31/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 3.1570 - val_loss: 2.2295\n",
      "Epoch 32/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 3.1000 - val_loss: 2.2050\n",
      "Epoch 33/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 3.0446 - val_loss: 2.1790\n",
      "Epoch 34/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 2.9866 - val_loss: 2.1550\n",
      "Epoch 35/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 2.9336 - val_loss: 2.1250\n",
      "Epoch 36/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 2.8710 - val_loss: 2.1013\n",
      "Epoch 37/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 2.8219 - val_loss: 2.0760\n",
      "Epoch 38/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 2.7706 - val_loss: 2.0525\n",
      "Epoch 39/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 2.7174 - val_loss: 2.0267\n",
      "Epoch 40/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 2.6612 - val_loss: 2.0040\n",
      "Epoch 41/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 2.6103 - val_loss: 1.9813\n",
      "Epoch 42/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 2.5621 - val_loss: 1.9585\n",
      "Epoch 43/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 2.5129 - val_loss: 1.9328\n",
      "Epoch 44/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 2.4572 - val_loss: 1.9091\n",
      "Epoch 45/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 2.4077 - val_loss: 1.8869\n",
      "Epoch 46/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 2.3646 - val_loss: 1.8639\n",
      "Epoch 47/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 2.3143 - val_loss: 1.8411\n",
      "Epoch 48/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 2.2673 - val_loss: 1.8184\n",
      "Epoch 49/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 2.2249 - val_loss: 1.7998\n",
      "Epoch 50/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 2.1842 - val_loss: 1.7768\n",
      "Epoch 51/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 2.1335 - val_loss: 1.7565\n",
      "Epoch 52/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 2.0886 - val_loss: 1.7384\n",
      "Epoch 53/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 2.0504 - val_loss: 1.7181\n",
      "Epoch 54/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 2.0106 - val_loss: 1.6973\n",
      "Epoch 55/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 1.9664 - val_loss: 1.6788\n",
      "Epoch 56/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.9306 - val_loss: 1.6617\n",
      "Epoch 57/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.8953 - val_loss: 1.6420\n",
      "Epoch 58/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.8536 - val_loss: 1.6246\n",
      "Epoch 59/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.8176 - val_loss: 1.6082\n",
      "Epoch 60/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.7834 - val_loss: 1.5922\n",
      "Epoch 61/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 1.7508 - val_loss: 1.5740\n",
      "Epoch 62/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.7134 - val_loss: 1.5582\n",
      "Epoch 63/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.6797 - val_loss: 1.5444\n",
      "Epoch 64/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.6521 - val_loss: 1.5283\n",
      "Epoch 65/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.6208 - val_loss: 1.5125\n",
      "Epoch 66/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.5899 - val_loss: 1.4968\n",
      "Epoch 67/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 1.5608 - val_loss: 1.4798\n",
      "Epoch 68/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 1.5323 - val_loss: 1.4676\n",
      "Epoch 69/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.5073 - val_loss: 1.4558\n",
      "Epoch 70/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.4830 - val_loss: 1.4417\n",
      "Epoch 71/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.4552 - val_loss: 1.4285\n",
      "Epoch 72/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.4313 - val_loss: 1.4131\n",
      "Epoch 73/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 1.4049 - val_loss: 1.3996\n",
      "Epoch 74/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.3812 - val_loss: 1.3876\n",
      "Epoch 75/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.3594 - val_loss: 1.3750\n",
      "Epoch 76/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.3380 - val_loss: 1.3629\n",
      "Epoch 77/300\n",
      "105/105 [==============================] - 0s 61us/sample - loss: 1.3136 - val_loss: 1.3496\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 80us/sample - loss: 1.2906 - val_loss: 1.3386\n",
      "Epoch 79/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.2697 - val_loss: 1.3265\n",
      "Epoch 80/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.2475 - val_loss: 1.3164\n",
      "Epoch 81/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 1.2276 - val_loss: 1.3039\n",
      "Epoch 82/300\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 1.2083 - val_loss: 1.2949\n",
      "Epoch 83/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.1924 - val_loss: 1.2856\n",
      "Epoch 84/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.1764 - val_loss: 1.2764\n",
      "Epoch 85/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 1.1607 - val_loss: 1.2670\n",
      "Epoch 86/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.1414 - val_loss: 1.2565\n",
      "Epoch 87/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.1243 - val_loss: 1.2472\n",
      "Epoch 88/300\n",
      "105/105 [==============================] - 0s 61us/sample - loss: 1.1095 - val_loss: 1.2406\n",
      "Epoch 89/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 1.0967 - val_loss: 1.2314\n",
      "Epoch 90/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.0828 - val_loss: 1.2226\n",
      "Epoch 91/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.0707 - val_loss: 1.2142\n",
      "Epoch 92/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.0571 - val_loss: 1.2053\n",
      "Epoch 93/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 1.0460 - val_loss: 1.1981\n",
      "Epoch 94/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.0356 - val_loss: 1.1902\n",
      "Epoch 95/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.0221 - val_loss: 1.1823\n",
      "Epoch 96/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 1.0084 - val_loss: 1.1762\n",
      "Epoch 97/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.9993 - val_loss: 1.1680\n",
      "Epoch 98/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.9851 - val_loss: 1.1614\n",
      "Epoch 99/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.9752 - val_loss: 1.1548\n",
      "Epoch 100/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.9653 - val_loss: 1.1486\n",
      "Epoch 101/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.9562 - val_loss: 1.1412\n",
      "Epoch 102/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.9466 - val_loss: 1.1366\n",
      "Epoch 103/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.9393 - val_loss: 1.1309\n",
      "Epoch 104/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.9325 - val_loss: 1.1264\n",
      "Epoch 105/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.9269 - val_loss: 1.1207\n",
      "Epoch 106/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.9200 - val_loss: 1.1145\n",
      "Epoch 107/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.9124 - val_loss: 1.1089\n",
      "Epoch 108/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.9063 - val_loss: 1.1048\n",
      "Epoch 109/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.9008 - val_loss: 1.1009\n",
      "Epoch 110/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.8957 - val_loss: 1.0970\n",
      "Epoch 111/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8899 - val_loss: 1.0925\n",
      "Epoch 112/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.8838 - val_loss: 1.0892\n",
      "Epoch 113/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.8787 - val_loss: 1.0843\n",
      "Epoch 114/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.8739 - val_loss: 1.0805\n",
      "Epoch 115/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8673 - val_loss: 1.0743\n",
      "Epoch 116/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.8619 - val_loss: 1.0686\n",
      "Epoch 117/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.8569 - val_loss: 1.0644\n",
      "Epoch 118/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8526 - val_loss: 1.0608\n",
      "Epoch 119/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.8490 - val_loss: 1.0565\n",
      "Epoch 120/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.8453 - val_loss: 1.0538\n",
      "Epoch 121/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.8426 - val_loss: 1.0501\n",
      "Epoch 122/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8388 - val_loss: 1.0463\n",
      "Epoch 123/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.8352 - val_loss: 1.0434\n",
      "Epoch 124/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.8330 - val_loss: 1.0402\n",
      "Epoch 125/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.8297 - val_loss: 1.0357\n",
      "Epoch 126/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.8255 - val_loss: 1.0324\n",
      "Epoch 127/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8231 - val_loss: 1.0287\n",
      "Epoch 128/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.8200 - val_loss: 1.0245\n",
      "Epoch 129/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.8163 - val_loss: 1.0210\n",
      "Epoch 130/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8145 - val_loss: 1.0203\n",
      "Epoch 131/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8126 - val_loss: 1.0169\n",
      "Epoch 132/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8105 - val_loss: 1.0149\n",
      "Epoch 133/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.8084 - val_loss: 1.0119\n",
      "Epoch 134/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.8066 - val_loss: 1.0087\n",
      "Epoch 135/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.8043 - val_loss: 1.0059\n",
      "Epoch 136/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8025 - val_loss: 1.0041\n",
      "Epoch 137/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8010 - val_loss: 1.0014\n",
      "Epoch 138/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7989 - val_loss: 0.9993\n",
      "Epoch 139/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7972 - val_loss: 0.9984\n",
      "Epoch 140/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7964 - val_loss: 0.9947\n",
      "Epoch 141/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7947 - val_loss: 0.9904\n",
      "Epoch 142/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7919 - val_loss: 0.9884\n",
      "Epoch 143/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7909 - val_loss: 0.9863\n",
      "Epoch 144/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7902 - val_loss: 0.9844\n",
      "Epoch 145/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7880 - val_loss: 0.9815\n",
      "Epoch 146/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7867 - val_loss: 0.9785\n",
      "Epoch 147/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7843 - val_loss: 0.9757\n",
      "Epoch 148/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7831 - val_loss: 0.9736\n",
      "Epoch 149/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7813 - val_loss: 0.9721\n",
      "Epoch 150/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7804 - val_loss: 0.9701\n",
      "Epoch 151/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7788 - val_loss: 0.9662\n",
      "Epoch 152/300\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 0.7764 - val_loss: 0.9643\n",
      "Epoch 153/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7752 - val_loss: 0.9623\n",
      "Epoch 154/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7742 - val_loss: 0.9608\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 85us/sample - loss: 0.7733 - val_loss: 0.9591\n",
      "Epoch 156/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7724 - val_loss: 0.9589\n",
      "Epoch 157/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7723 - val_loss: 0.9580\n",
      "Epoch 158/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7722 - val_loss: 0.9568\n",
      "Epoch 159/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7710 - val_loss: 0.9553\n",
      "Epoch 160/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7700 - val_loss: 0.9540\n",
      "Epoch 161/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7696 - val_loss: 0.9521\n",
      "Epoch 162/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7683 - val_loss: 0.9496\n",
      "Epoch 163/300\n",
      "105/105 [==============================] - 0s 61us/sample - loss: 0.7673 - val_loss: 0.9477\n",
      "Epoch 164/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7663 - val_loss: 0.9471\n",
      "Epoch 165/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7665 - val_loss: 0.9461\n",
      "Epoch 166/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7655 - val_loss: 0.9449\n",
      "Epoch 167/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7653 - val_loss: 0.9430\n",
      "Epoch 168/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7642 - val_loss: 0.9408\n",
      "Epoch 169/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7635 - val_loss: 0.9401\n",
      "Epoch 170/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7629 - val_loss: 0.9404\n",
      "Epoch 171/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7627 - val_loss: 0.9382\n",
      "Epoch 172/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7618 - val_loss: 0.9370\n",
      "Epoch 173/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7610 - val_loss: 0.9343\n",
      "Epoch 174/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7601 - val_loss: 0.9324\n",
      "Epoch 175/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7594 - val_loss: 0.9305\n",
      "Epoch 176/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7586 - val_loss: 0.9302\n",
      "Epoch 177/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7585 - val_loss: 0.9278\n",
      "Epoch 178/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7580 - val_loss: 0.9269\n",
      "Epoch 179/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7569 - val_loss: 0.9262\n",
      "Epoch 180/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7565 - val_loss: 0.9267\n",
      "Epoch 181/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.7568 - val_loss: 0.9251\n",
      "Epoch 182/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7558 - val_loss: 0.9232\n",
      "Epoch 183/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7553 - val_loss: 0.9226\n",
      "Epoch 184/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7547 - val_loss: 0.9218\n",
      "Epoch 185/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7545 - val_loss: 0.9215\n",
      "Epoch 186/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7544 - val_loss: 0.9213\n",
      "Epoch 187/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7542 - val_loss: 0.9204\n",
      "Epoch 188/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7539 - val_loss: 0.9202\n",
      "Epoch 189/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7541 - val_loss: 0.9183\n",
      "Epoch 190/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7531 - val_loss: 0.9161\n",
      "Epoch 191/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7520 - val_loss: 0.9152\n",
      "Epoch 192/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7520 - val_loss: 0.9153\n",
      "Epoch 193/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7521 - val_loss: 0.9142\n",
      "Epoch 194/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7517 - val_loss: 0.9140\n",
      "Epoch 195/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7519 - val_loss: 0.9129\n",
      "Epoch 196/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7513 - val_loss: 0.9118\n",
      "Epoch 197/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7505 - val_loss: 0.9108\n",
      "Epoch 198/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7502 - val_loss: 0.9105\n",
      "Epoch 199/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7502 - val_loss: 0.9092\n",
      "Epoch 200/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7499 - val_loss: 0.9079\n",
      "Epoch 201/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7496 - val_loss: 0.9058\n",
      "Epoch 202/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7488 - val_loss: 0.9050\n",
      "Epoch 203/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7483 - val_loss: 0.9046\n",
      "Epoch 204/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7483 - val_loss: 0.9024\n",
      "Epoch 205/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7476 - val_loss: 0.9017\n",
      "Epoch 206/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7474 - val_loss: 0.9013\n",
      "Epoch 207/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7475 - val_loss: 0.9007\n",
      "Epoch 208/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7472 - val_loss: 0.9004\n",
      "Epoch 209/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7468 - val_loss: 0.9006\n",
      "Epoch 210/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7474 - val_loss: 0.9010\n",
      "Epoch 211/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7476 - val_loss: 0.9000\n",
      "Epoch 212/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.7464 - val_loss: 0.8987\n",
      "Epoch 213/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7464 - val_loss: 0.8974\n",
      "Epoch 214/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7460 - val_loss: 0.8985\n",
      "Epoch 215/300\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 0.7461 - val_loss: 0.8981\n",
      "Epoch 216/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.7460 - val_loss: 0.8974\n",
      "Epoch 217/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7459 - val_loss: 0.8973\n",
      "Epoch 218/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7458 - val_loss: 0.8960\n",
      "Epoch 219/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7456 - val_loss: 0.8957\n",
      "Epoch 220/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7455 - val_loss: 0.8950\n",
      "Epoch 221/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7451 - val_loss: 0.8943\n",
      "Epoch 222/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7452 - val_loss: 0.8944\n",
      "Epoch 223/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7451 - val_loss: 0.8943\n",
      "Epoch 224/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.7450 - val_loss: 0.8939\n",
      "Epoch 225/300\n",
      "105/105 [==============================] - 0s 61us/sample - loss: 0.7449 - val_loss: 0.8931\n",
      "Epoch 226/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7446 - val_loss: 0.8932\n",
      "Epoch 227/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7446 - val_loss: 0.8925\n",
      "Epoch 228/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7445 - val_loss: 0.8920\n",
      "Epoch 229/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7446 - val_loss: 0.8910\n",
      "Epoch 230/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7445 - val_loss: 0.8906\n",
      "Epoch 231/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7441 - val_loss: 0.8903\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7440 - val_loss: 0.8902\n",
      "Epoch 233/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7440 - val_loss: 0.8901\n",
      "Epoch 234/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7439 - val_loss: 0.8891\n",
      "Epoch 235/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7441 - val_loss: 0.8890\n",
      "Epoch 236/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7437 - val_loss: 0.8885\n",
      "Epoch 237/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7438 - val_loss: 0.8891\n",
      "Epoch 238/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7435 - val_loss: 0.8889\n",
      "Epoch 239/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.7439 - val_loss: 0.8885\n",
      "Epoch 240/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7435 - val_loss: 0.8881\n",
      "Epoch 241/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7433 - val_loss: 0.8887\n",
      "Epoch 242/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7437 - val_loss: 0.8890\n",
      "Epoch 243/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7435 - val_loss: 0.8887\n",
      "Epoch 244/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7432 - val_loss: 0.8886\n",
      "Epoch 245/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7434 - val_loss: 0.8873\n",
      "Epoch 246/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7434 - val_loss: 0.8873\n",
      "Epoch 247/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7431 - val_loss: 0.8870\n",
      "Epoch 248/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7433 - val_loss: 0.8869\n",
      "Epoch 249/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7433 - val_loss: 0.8870\n",
      "Epoch 250/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7428 - val_loss: 0.8868\n",
      "Epoch 251/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.7431 - val_loss: 0.8868\n",
      "Epoch 252/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7429 - val_loss: 0.8862\n",
      "Epoch 253/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.7427 - val_loss: 0.8864\n",
      "Epoch 254/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7430 - val_loss: 0.8855\n",
      "Epoch 255/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7426 - val_loss: 0.8850\n",
      "Epoch 256/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.7427 - val_loss: 0.8849\n",
      "Epoch 257/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.7424 - val_loss: 0.8857\n",
      "Epoch 258/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.7427 - val_loss: 0.8852\n",
      "Epoch 259/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7425 - val_loss: 0.8846\n",
      "Epoch 260/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7423 - val_loss: 0.8832\n",
      "Epoch 261/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7421 - val_loss: 0.8817\n",
      "Epoch 262/300\n",
      "105/105 [==============================] - 0s 60us/sample - loss: 0.7418 - val_loss: 0.8815\n",
      "Epoch 263/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7418 - val_loss: 0.8805\n",
      "Epoch 264/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7418 - val_loss: 0.8804\n",
      "Epoch 265/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7418 - val_loss: 0.8808\n",
      "Epoch 266/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7417 - val_loss: 0.8804\n",
      "Epoch 267/300\n",
      "105/105 [==============================] - 0s 64us/sample - loss: 0.7417 - val_loss: 0.8806\n",
      "Epoch 268/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7416 - val_loss: 0.8813\n",
      "Epoch 269/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7415 - val_loss: 0.8815\n",
      "Epoch 270/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7417 - val_loss: 0.8811\n",
      "Epoch 271/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7417 - val_loss: 0.8821\n",
      "Epoch 272/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.7416 - val_loss: 0.8817\n",
      "Epoch 273/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.7415 - val_loss: 0.8820\n",
      "Epoch 274/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7415 - val_loss: 0.8815\n",
      "Epoch 275/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7416 - val_loss: 0.8808\n",
      "Epoch 276/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.7417 - val_loss: 0.8809\n",
      "Epoch 277/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7418 - val_loss: 0.8805\n",
      "Epoch 278/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7414 - val_loss: 0.8798\n",
      "Epoch 279/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7414 - val_loss: 0.8795\n",
      "Epoch 280/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.7413 - val_loss: 0.8793\n",
      "Epoch 281/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7412 - val_loss: 0.8804\n",
      "Epoch 282/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7412 - val_loss: 0.8792\n",
      "Epoch 283/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.7412 - val_loss: 0.8795\n",
      "Epoch 284/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7410 - val_loss: 0.8784\n",
      "Epoch 285/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7411 - val_loss: 0.8789\n",
      "Epoch 286/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7409 - val_loss: 0.8779\n",
      "Epoch 287/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7410 - val_loss: 0.8768\n",
      "Epoch 288/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.7410 - val_loss: 0.8764\n",
      "Epoch 289/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.7405 - val_loss: 0.8766\n",
      "Epoch 290/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.7409 - val_loss: 0.8762\n",
      "Epoch 291/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.7407 - val_loss: 0.8758\n",
      "Epoch 292/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.7404 - val_loss: 0.8759\n",
      "Epoch 293/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.7405 - val_loss: 0.8767\n",
      "Epoch 294/300\n",
      "105/105 [==============================] - 0s 62us/sample - loss: 0.7406 - val_loss: 0.8765\n",
      "Epoch 295/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7406 - val_loss: 0.8766\n",
      "Epoch 296/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 0.7408 - val_loss: 0.8769\n",
      "Epoch 297/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.7407 - val_loss: 0.8766\n",
      "Epoch 298/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.7406 - val_loss: 0.8763\n",
      "Epoch 299/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.7405 - val_loss: 0.8763\n",
      "Epoch 300/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.7402 - val_loss: 0.8764\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=300, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('../../gen_images/14_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 케라스 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation=\"relu\", input_dim=1))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "model.load_weights('simple_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 653us/sample - loss: 1.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0062094020843506"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('simple_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 673us/sample - loss: 1.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0062094020843506"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('simple_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 988us/sample - loss: 4.0204 - val_loss: 2.4785\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 3.9376 - val_loss: 2.4285\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 3.8550 - val_loss: 2.3782\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 3.7746 - val_loss: 2.3306\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 3.6949 - val_loss: 2.2846\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 3.6201 - val_loss: 2.2395\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 3.5451 - val_loss: 2.1956\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 3.4721 - val_loss: 2.1519\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 3.4021 - val_loss: 2.1100\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 3.3343 - val_loss: 2.0695\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 3.2655 - val_loss: 2.0297\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 3.2006 - val_loss: 1.9906\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 3.1365 - val_loss: 1.9534\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 3.0757 - val_loss: 1.9179\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 3.0168 - val_loss: 1.8813\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 2.9589 - val_loss: 1.8465\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 2.9021 - val_loss: 1.8130\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 2.8482 - val_loss: 1.7800\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 2.7949 - val_loss: 1.7485\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 2.7454 - val_loss: 1.7177\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 2.6939 - val_loss: 1.6863\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 2.6436 - val_loss: 1.6568\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 2.5943 - val_loss: 1.6282\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 2.5473 - val_loss: 1.6004\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 2.5010 - val_loss: 1.5726\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 2.4565 - val_loss: 1.5455\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 2.4099 - val_loss: 1.5194\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 2.3668 - val_loss: 1.4942\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 2.3244 - val_loss: 1.4688\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 2.2827 - val_loss: 1.4441\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 2.2413 - val_loss: 1.4194\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 2.2008 - val_loss: 1.3960\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 2.1615 - val_loss: 1.3731\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 2.1232 - val_loss: 1.3499\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 2.0851 - val_loss: 1.3279\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 2.0481 - val_loss: 1.3059\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 2.0113 - val_loss: 1.2844\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 1.9754 - val_loss: 1.2641\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.9410 - val_loss: 1.2447\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 1.9083 - val_loss: 1.2255\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 1.8753 - val_loss: 1.2064\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.8433 - val_loss: 1.1879\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 1.8123 - val_loss: 1.1702\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 1.7821 - val_loss: 1.1529\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 1.7530 - val_loss: 1.1361\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 1.7247 - val_loss: 1.1197\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 1.6969 - val_loss: 1.1038\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 1.6696 - val_loss: 1.0883\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 1.6435 - val_loss: 1.0728\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 1.6175 - val_loss: 1.0586\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 1.5942 - val_loss: 1.0451\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.5705 - val_loss: 1.0313\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 1.5470 - val_loss: 1.0181\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.5245 - val_loss: 1.0053\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 1.5026 - val_loss: 0.9928\n",
      "Epoch 56/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 1.4813 - val_loss: 0.9807\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 1.4615 - val_loss: 0.9689\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 1.4406 - val_loss: 0.9574\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.4205 - val_loss: 0.9465\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 1.4019 - val_loss: 0.9361\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 1.3839 - val_loss: 0.9263\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 1.3665 - val_loss: 0.9166\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 1.3496 - val_loss: 0.9073\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.3339 - val_loss: 0.8982\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 1.3180 - val_loss: 0.8892\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.3026 - val_loss: 0.8803\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 1.2869 - val_loss: 0.8721\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.2727 - val_loss: 0.8641\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 1.2587 - val_loss: 0.8567\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 1.2452 - val_loss: 0.8493\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.2322 - val_loss: 0.8420\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 1.2193 - val_loss: 0.8351\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 1.2075 - val_loss: 0.8289\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.1959 - val_loss: 0.8227\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 1.1849 - val_loss: 0.8166\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 1.1739 - val_loss: 0.8107\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.1631 - val_loss: 0.8052\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 184us/sample - loss: 1.1529 - val_loss: 0.7996\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 1.1434 - val_loss: 0.7945\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 1.1333 - val_loss: 0.7896\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 1.1249 - val_loss: 0.7843\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 1.1153 - val_loss: 0.7794\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 1.1061 - val_loss: 0.7744\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 1.0972 - val_loss: 0.7701\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.0889 - val_loss: 0.7659\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.0810 - val_loss: 0.7620\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 1.0738 - val_loss: 0.7583\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 1.0663 - val_loss: 0.7546\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 1.0595 - val_loss: 0.7510\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.0526 - val_loss: 0.7475\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.0460 - val_loss: 0.7438\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 1.0396 - val_loss: 0.7406\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.0331 - val_loss: 0.7376\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 1.0275 - val_loss: 0.7347\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.0216 - val_loss: 0.7320\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 1.0162 - val_loss: 0.7291\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 1.0110 - val_loss: 0.7261\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 1.0060 - val_loss: 0.7236\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 1.0001 - val_loss: 0.7211\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.9950 - val_loss: 0.7184\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.9901 - val_loss: 0.7161\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.9857 - val_loss: 0.7140\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.9812 - val_loss: 0.7119\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.9768 - val_loss: 0.7099\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.9728 - val_loss: 0.7080\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9688 - val_loss: 0.7060\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.9648 - val_loss: 0.7041\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.9608 - val_loss: 0.7022\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.9570 - val_loss: 0.7004\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.9531 - val_loss: 0.6985\n",
      "Epoch 111/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.9493 - val_loss: 0.6967\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.9454 - val_loss: 0.6952\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.9422 - val_loss: 0.6938\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.9390 - val_loss: 0.6925\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.9361 - val_loss: 0.6912\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.9329 - val_loss: 0.6900\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.9299 - val_loss: 0.6888\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.9275 - val_loss: 0.6877\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.9246 - val_loss: 0.6866\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9222 - val_loss: 0.6855\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.9199 - val_loss: 0.6847\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9172 - val_loss: 0.6835\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.9144 - val_loss: 0.6827\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9118 - val_loss: 0.6818\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.9096 - val_loss: 0.6810\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.9071 - val_loss: 0.6802\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.9052 - val_loss: 0.6795\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9031 - val_loss: 0.6787\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.9007 - val_loss: 0.6780\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8988 - val_loss: 0.6774\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.8967 - val_loss: 0.6766\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.8950 - val_loss: 0.6759\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.8932 - val_loss: 0.6754\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8908 - val_loss: 0.6749\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.8890 - val_loss: 0.6743\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.8873 - val_loss: 0.6738\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.8854 - val_loss: 0.6733\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.8839 - val_loss: 0.6728\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.8824 - val_loss: 0.6723\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.8811 - val_loss: 0.6721\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.8793 - val_loss: 0.6717\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 0.8778 - val_loss: 0.6713\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8772 - val_loss: 0.6709\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.8749 - val_loss: 0.6705\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.8734 - val_loss: 0.6702\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8717 - val_loss: 0.6700\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.8707 - val_loss: 0.6698\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.8693 - val_loss: 0.6696\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.8681 - val_loss: 0.6695\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.8668 - val_loss: 0.6692\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.8653 - val_loss: 0.6691\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.8640 - val_loss: 0.6691\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.8630 - val_loss: 0.6690\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8618 - val_loss: 0.6689\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 65us/sample - loss: 0.8608 - val_loss: 0.6690\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.8597 - val_loss: 0.6689\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8588 - val_loss: 0.6690\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8579 - val_loss: 0.6690\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8566 - val_loss: 0.6691\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8557 - val_loss: 0.6691\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8547 - val_loss: 0.6690\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8537 - val_loss: 0.6691\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8531 - val_loss: 0.6692\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 68us/sample - loss: 0.8520 - val_loss: 0.6693\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8512 - val_loss: 0.6695\n",
      "Epoch 166/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8504 - val_loss: 0.6696\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 65us/sample - loss: 0.8496 - val_loss: 0.6697\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8485 - val_loss: 0.6698\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8479 - val_loss: 0.6700\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 66us/sample - loss: 0.8470 - val_loss: 0.6702\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8461 - val_loss: 0.6703\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8454 - val_loss: 0.6706\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8445 - val_loss: 0.6707\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8440 - val_loss: 0.6709\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 51us/sample - loss: 0.8435 - val_loss: 0.6712\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8425 - val_loss: 0.6715\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8421 - val_loss: 0.6717\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8413 - val_loss: 0.6719\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8410 - val_loss: 0.6722\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 68us/sample - loss: 0.8397 - val_loss: 0.6724\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8391 - val_loss: 0.6727\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 68us/sample - loss: 0.8387 - val_loss: 0.6729\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.8379 - val_loss: 0.6730\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 49us/sample - loss: 0.8375 - val_loss: 0.6732\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8365 - val_loss: 0.6734\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8363 - val_loss: 0.6737\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8355 - val_loss: 0.6739\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8354 - val_loss: 0.6742\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 49us/sample - loss: 0.8344 - val_loss: 0.6744\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8343 - val_loss: 0.6748\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8336 - val_loss: 0.6749\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 66us/sample - loss: 0.8332 - val_loss: 0.6752\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8325 - val_loss: 0.6755\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 49us/sample - loss: 0.8320 - val_loss: 0.6757\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8315 - val_loss: 0.6759\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8312 - val_loss: 0.6763\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8308 - val_loss: 0.6766\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 69us/sample - loss: 0.8300 - val_loss: 0.6769\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8295 - val_loss: 0.6773\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 65us/sample - loss: 0.8288 - val_loss: 0.6775\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8282 - val_loss: 0.6777\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8279 - val_loss: 0.6780\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8276 - val_loss: 0.6782\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8272 - val_loss: 0.6785\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8271 - val_loss: 0.6788\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 49us/sample - loss: 0.8269 - val_loss: 0.6791\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8258 - val_loss: 0.6794\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 53us/sample - loss: 0.8255 - val_loss: 0.6796\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8252 - val_loss: 0.6800\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8247 - val_loss: 0.6803\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8248 - val_loss: 0.6807\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8243 - val_loss: 0.6809\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8241 - val_loss: 0.6812\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8233 - val_loss: 0.6815\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 70us/sample - loss: 0.8238 - val_loss: 0.6818\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 53us/sample - loss: 0.8226 - val_loss: 0.6820\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8226 - val_loss: 0.6822\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8220 - val_loss: 0.6825\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8218 - val_loss: 0.6828\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 66us/sample - loss: 0.8216 - val_loss: 0.6831\n",
      "Epoch 221/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8213 - val_loss: 0.6833\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8211 - val_loss: 0.6837\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8207 - val_loss: 0.6840\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8201 - val_loss: 0.6842\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 70us/sample - loss: 0.8201 - val_loss: 0.6844\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8196 - val_loss: 0.6846\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8191 - val_loss: 0.6849\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8192 - val_loss: 0.6852\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8188 - val_loss: 0.6854\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8184 - val_loss: 0.6856\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8183 - val_loss: 0.6858\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8174 - val_loss: 0.6860\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.8178 - val_loss: 0.6862\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8169 - val_loss: 0.6865\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8164 - val_loss: 0.6867\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8162 - val_loss: 0.6869\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8158 - val_loss: 0.6872\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.8155 - val_loss: 0.6873\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 49us/sample - loss: 0.8153 - val_loss: 0.6877\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8149 - val_loss: 0.6880\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8145 - val_loss: 0.6883\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 60us/sample - loss: 0.8144 - val_loss: 0.6885\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 66us/sample - loss: 0.8144 - val_loss: 0.6886\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8138 - val_loss: 0.6889\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8137 - val_loss: 0.6892\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.8133 - val_loss: 0.6895\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8131 - val_loss: 0.6898\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8129 - val_loss: 0.6900\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8123 - val_loss: 0.6902\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8126 - val_loss: 0.6904\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8120 - val_loss: 0.6906\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8121 - val_loss: 0.6909\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 69us/sample - loss: 0.8114 - val_loss: 0.6911\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8112 - val_loss: 0.6914\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8111 - val_loss: 0.6917\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8109 - val_loss: 0.6919\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8105 - val_loss: 0.6921\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8106 - val_loss: 0.6924\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8101 - val_loss: 0.6927\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.8098 - val_loss: 0.6928\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8097 - val_loss: 0.6932\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8093 - val_loss: 0.6934\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8092 - val_loss: 0.6938\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8087 - val_loss: 0.6940\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8088 - val_loss: 0.6941\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8085 - val_loss: 0.6943\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8080 - val_loss: 0.6944\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8078 - val_loss: 0.6946\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 0.8077 - val_loss: 0.6948\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8073 - val_loss: 0.6950\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 57us/sample - loss: 0.8073 - val_loss: 0.6952\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 67us/sample - loss: 0.8070 - val_loss: 0.6955\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.8070 - val_loss: 0.6958\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8068 - val_loss: 0.6960\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 54us/sample - loss: 0.8063 - val_loss: 0.6962\n",
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8063 - val_loss: 0.6962\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8065 - val_loss: 0.6966\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8056 - val_loss: 0.6968\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8059 - val_loss: 0.6970\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8059 - val_loss: 0.6970\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 56us/sample - loss: 0.8055 - val_loss: 0.6973\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 52us/sample - loss: 0.8050 - val_loss: 0.6976\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 59us/sample - loss: 0.8050 - val_loss: 0.6977\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8047 - val_loss: 0.6977\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 55us/sample - loss: 0.8043 - val_loss: 0.6980\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8044 - val_loss: 0.6984\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8043 - val_loss: 0.6987\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8038 - val_loss: 0.6990\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 71us/sample - loss: 0.8038 - val_loss: 0.6993\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 58us/sample - loss: 0.8036 - val_loss: 0.6995\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.8039 - val_loss: 0.6995\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8031 - val_loss: 0.6997\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 63us/sample - loss: 0.8029 - val_loss: 0.6999\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 50us/sample - loss: 0.8027 - val_loss: 0.7000\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 53us/sample - loss: 0.8030 - val_loss: 0.7004\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8030 - val_loss: 0.7005\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 61us/sample - loss: 0.8022 - val_loss: 0.7007\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8020 - val_loss: 0.7010\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 64us/sample - loss: 0.8023 - val_loss: 0.7010\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 65us/sample - loss: 0.8019 - val_loss: 0.7012\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation=\"relu\", input_dim=1))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "callback_list = [ModelCheckpoint(filepath='my_model.h5', \n",
    "                                 monitor='val_loss', save_best_only=True)]\n",
    "history = model.fit(x_train, y_train, epochs=300, \n",
    "                    validation_split=0.2, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 모델 복원:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 656us/sample - loss: 1.0965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0964699649810792"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('simple_model.h5')\n",
    "model.load_weights('my_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_arr = np.arange(-2, 2, 0.1)\n",
    "y_arr = model.predict(x_arr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr, '-r', lw=3)\n",
    "plt.savefig('../../gen_images/14_08.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서를 다차원 배열로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.  2.  3.  3.5]\n",
      " [4.  5.  6.  6.5]\n",
      " [7.  8.  9.  9.5]], shape=(3, 4), dtype=float64)\n",
      "T1의 크기: (3, 4)\n",
      "T1의 크기: (3, 4)\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64, numpy=\n",
      "array([[ 0.22613483,  0.22330971, -1.16654888, -0.59371599],\n",
      "       [-1.40608288,  0.46867727,  0.09847034, -0.77515762],\n",
      "       [ 0.31413519,  0.8974029 , -0.13932577,  0.73768109]])>\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float64, numpy=array([-0.37963847,  0.7480918 ,  0.28543433])>\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1., 2., 3., 3.5],\n",
    "                [4., 5., 6., 6.5],\n",
    "                [7., 8., 9., 9.5]])\n",
    "T1 = tf.constant(arr)\n",
    "print(T1)\n",
    "s = T1.get_shape()\n",
    "print('T1의 크기:', s)\n",
    "print('T1의 크기:', T1.shape)\n",
    "T2 = tf.Variable(np.random.normal(size=s))\n",
    "print(T2)\n",
    "T3 = tf.Variable(np.random.normal(size=s[0]))\n",
    "print(T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[1.  2.  3.  3.5 4.  5.  6.  6.5 7.  8.  9.  9.5]]], shape=(1, 1, 12), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1.  2.  3.  3.5]\n",
      "  [4.  5.  6.  6.5]\n",
      "  [7.  8.  9.  9.5]]], shape=(1, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T4 = tf.reshape(T1, shape=[1, 1, -1])\n",
    "print(T4)\n",
    "T5 = tf.reshape(T1, shape=[1, 3, -1])\n",
    "print(T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. ]\n",
      "  [4. ]\n",
      "  [7. ]]\n",
      "\n",
      " [[2. ]\n",
      "  [5. ]\n",
      "  [8. ]]\n",
      "\n",
      " [[3. ]\n",
      "  [6. ]\n",
      "  [9. ]]\n",
      "\n",
      " [[3.5]\n",
      "  [6.5]\n",
      "  [9.5]]], shape=(4, 3, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[1.  4.  7. ]\n",
      "  [2.  5.  8. ]\n",
      "  [3.  6.  9. ]\n",
      "  [3.5 6.5 9.5]]], shape=(1, 4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "T6 = tf.transpose(T5, perm=[2, 1, 0])\n",
    "print(T6)\n",
    "T7 = tf.transpose(T5, perm=[0, 2, 1])\n",
    "print(T7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=34904, shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]]])>, <tf.Tensor: id=34905, shape=(1, 3, 2), dtype=float64, numpy=\n",
      "array([[[3. , 3.5],\n",
      "        [6. , 6.5],\n",
      "        [9. , 9.5]]])>]\n"
     ]
    }
   ],
   "source": [
    "t5_splt = tf.split(T5, \n",
    "                   num_or_size_splits=2, \n",
    "                   axis=2)\n",
    "print(t5_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(5, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(10, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.ones(shape=(5, 1), dtype=tf.float32)\n",
    "t2 = tf.zeros(shape=(5, 1), dtype=tf.float32)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "t3 = tf.concat([t1, t2], axis=0)\n",
    "print(t3)\n",
    "t4 = tf.concat([t1, t2], axis=1)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 계산 그래프 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=1, kernel_regularizer='l2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/300\n",
      "105/105 [==============================] - 0s 1ms/sample - loss: 15.0378 - val_loss: 10.2772\n",
      "Epoch 2/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 14.6887 - val_loss: 10.0860\n",
      "Epoch 3/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 14.4011 - val_loss: 9.9153\n",
      "Epoch 4/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 14.1347 - val_loss: 9.7228\n",
      "Epoch 5/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 13.8435 - val_loss: 9.5309\n",
      "Epoch 6/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 13.5501 - val_loss: 9.3403\n",
      "Epoch 7/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 13.2576 - val_loss: 9.1600\n",
      "Epoch 8/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 12.9765 - val_loss: 8.9789\n",
      "Epoch 9/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 12.6943 - val_loss: 8.8006\n",
      "Epoch 10/300\n",
      "105/105 [==============================] - 0s 183us/sample - loss: 12.4251 - val_loss: 8.6279\n",
      "Epoch 11/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 12.1581 - val_loss: 8.4814\n",
      "Epoch 12/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 11.9333 - val_loss: 8.3261\n",
      "Epoch 13/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 11.6984 - val_loss: 8.1872\n",
      "Epoch 14/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 11.4851 - val_loss: 8.0459\n",
      "Epoch 15/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 11.2653 - val_loss: 7.8947\n",
      "Epoch 16/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 11.0348 - val_loss: 7.7427\n",
      "Epoch 17/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 10.8048 - val_loss: 7.6033\n",
      "Epoch 18/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 10.5998 - val_loss: 7.4623\n",
      "Epoch 19/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 10.3864 - val_loss: 7.3282\n",
      "Epoch 20/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 10.1806 - val_loss: 7.1894\n",
      "Epoch 21/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 9.9688 - val_loss: 7.0569\n",
      "Epoch 22/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 9.7690 - val_loss: 6.9269\n",
      "Epoch 23/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 9.5744 - val_loss: 6.8075\n",
      "Epoch 24/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 9.3936 - val_loss: 6.6911\n",
      "Epoch 25/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 9.2218 - val_loss: 6.5684\n",
      "Epoch 26/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 9.0374 - val_loss: 6.4540\n",
      "Epoch 27/300\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 8.8645 - val_loss: 6.3305\n",
      "Epoch 28/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 8.6724 - val_loss: 6.2184\n",
      "Epoch 29/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 8.5012 - val_loss: 6.1057\n",
      "Epoch 30/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 8.3313 - val_loss: 5.9945\n",
      "Epoch 31/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 8.1626 - val_loss: 5.8876\n",
      "Epoch 32/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 8.0025 - val_loss: 5.7859\n",
      "Epoch 33/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 7.8469 - val_loss: 5.6783\n",
      "Epoch 34/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 7.6869 - val_loss: 5.5803\n",
      "Epoch 35/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 7.5392 - val_loss: 5.4838\n",
      "Epoch 36/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 7.3907 - val_loss: 5.3904\n",
      "Epoch 37/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 7.2520 - val_loss: 5.3042\n",
      "Epoch 38/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 7.1193 - val_loss: 5.2055\n",
      "Epoch 39/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 6.9753 - val_loss: 5.1088\n",
      "Epoch 40/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 6.8362 - val_loss: 5.0218\n",
      "Epoch 41/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 6.7105 - val_loss: 4.9457\n",
      "Epoch 42/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 6.5949 - val_loss: 4.8631\n",
      "Epoch 43/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 6.4724 - val_loss: 4.7775\n",
      "Epoch 44/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 6.3387 - val_loss: 4.6964\n",
      "Epoch 45/300\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 6.2181 - val_loss: 4.6249\n",
      "Epoch 46/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 6.1101 - val_loss: 4.5469\n",
      "Epoch 47/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 5.9906 - val_loss: 4.4663\n",
      "Epoch 48/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 5.8704 - val_loss: 4.3948\n",
      "Epoch 49/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 5.7640 - val_loss: 4.3252\n",
      "Epoch 50/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 5.6558 - val_loss: 4.2574\n",
      "Epoch 51/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 5.5529 - val_loss: 4.1872\n",
      "Epoch 52/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 5.4506 - val_loss: 4.1202\n",
      "Epoch 53/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 5.3498 - val_loss: 4.0590\n",
      "Epoch 54/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 5.2550 - val_loss: 3.9884\n",
      "Epoch 55/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 5.1475 - val_loss: 3.9215\n",
      "Epoch 56/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 5.0470 - val_loss: 3.8577\n",
      "Epoch 57/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 4.9509 - val_loss: 3.7952\n",
      "Epoch 58/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 4.8536 - val_loss: 3.7322\n",
      "Epoch 59/300\n",
      "105/105 [==============================] - 0s 63us/sample - loss: 4.7615 - val_loss: 3.6697\n",
      "Epoch 60/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 4.6719 - val_loss: 3.6142\n",
      "Epoch 61/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 4.5925 - val_loss: 3.5620\n",
      "Epoch 62/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 4.5151 - val_loss: 3.5074\n",
      "Epoch 63/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 4.4334 - val_loss: 3.4596\n",
      "Epoch 64/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 4.3618 - val_loss: 3.4118\n",
      "Epoch 65/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 4.2893 - val_loss: 3.3625\n",
      "Epoch 66/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 4.2150 - val_loss: 3.3113\n",
      "Epoch 67/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 4.1387 - val_loss: 3.2587\n",
      "Epoch 68/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 4.0626 - val_loss: 3.2154\n",
      "Epoch 69/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 3.9989 - val_loss: 3.1722\n",
      "Epoch 70/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 3.9345 - val_loss: 3.1269\n",
      "Epoch 71/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 3.8654 - val_loss: 3.0792\n",
      "Epoch 72/300\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 3.7957 - val_loss: 3.0329\n",
      "Epoch 73/300\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 3.7264 - val_loss: 2.9863\n",
      "Epoch 74/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 3.6563 - val_loss: 2.9473\n",
      "Epoch 75/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 3.5984 - val_loss: 2.9061\n",
      "Epoch 76/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 3.5373 - val_loss: 2.8632\n",
      "Epoch 77/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 3.4753 - val_loss: 2.8241\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 79us/sample - loss: 3.4174 - val_loss: 2.7830\n",
      "Epoch 79/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 3.3578 - val_loss: 2.7439\n",
      "Epoch 80/300\n",
      "105/105 [==============================] - 0s 153us/sample - loss: 3.3009 - val_loss: 2.7062\n",
      "Epoch 81/300\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 3.2468 - val_loss: 2.6693\n",
      "Epoch 82/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 3.1952 - val_loss: 2.6361\n",
      "Epoch 83/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 3.1449 - val_loss: 2.5984\n",
      "Epoch 84/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 3.0886 - val_loss: 2.5603\n",
      "Epoch 85/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 3.0322 - val_loss: 2.5251\n",
      "Epoch 86/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 2.9805 - val_loss: 2.4932\n",
      "Epoch 87/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 2.9337 - val_loss: 2.4572\n",
      "Epoch 88/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 2.8828 - val_loss: 2.4243\n",
      "Epoch 89/300\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 2.8338 - val_loss: 2.3936\n",
      "Epoch 90/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 2.7872 - val_loss: 2.3635\n",
      "Epoch 91/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 2.7431 - val_loss: 2.3322\n",
      "Epoch 92/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 2.6982 - val_loss: 2.3067\n",
      "Epoch 93/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 2.6596 - val_loss: 2.2776\n",
      "Epoch 94/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 2.6153 - val_loss: 2.2506\n",
      "Epoch 95/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 2.5754 - val_loss: 2.2243\n",
      "Epoch 96/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 2.5366 - val_loss: 2.1980\n",
      "Epoch 97/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 2.4981 - val_loss: 2.1726\n",
      "Epoch 98/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 2.4598 - val_loss: 2.1473\n",
      "Epoch 99/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 2.4228 - val_loss: 2.1237\n",
      "Epoch 100/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 2.3883 - val_loss: 2.0991\n",
      "Epoch 101/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 2.3531 - val_loss: 2.0780\n",
      "Epoch 102/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 2.3214 - val_loss: 2.0572\n",
      "Epoch 103/300\n",
      "105/105 [==============================] - 0s 87us/sample - loss: 2.2911 - val_loss: 2.0324\n",
      "Epoch 104/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 2.2547 - val_loss: 2.0108\n",
      "Epoch 105/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 2.2222 - val_loss: 1.9899\n",
      "Epoch 106/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 2.1912 - val_loss: 1.9692\n",
      "Epoch 107/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 2.1629 - val_loss: 1.9487\n",
      "Epoch 108/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 2.1348 - val_loss: 1.9294\n",
      "Epoch 109/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 2.1078 - val_loss: 1.9108\n",
      "Epoch 110/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 2.0800 - val_loss: 1.8903\n",
      "Epoch 111/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 2.0504 - val_loss: 1.8723\n",
      "Epoch 112/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 2.0232 - val_loss: 1.8487\n",
      "Epoch 113/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 1.9909 - val_loss: 1.8302\n",
      "Epoch 114/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.9656 - val_loss: 1.8134\n",
      "Epoch 115/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.9400 - val_loss: 1.7962\n",
      "Epoch 116/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.9157 - val_loss: 1.7795\n",
      "Epoch 117/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.8929 - val_loss: 1.7631\n",
      "Epoch 118/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.8687 - val_loss: 1.7454\n",
      "Epoch 119/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 1.8443 - val_loss: 1.7299\n",
      "Epoch 120/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.8217 - val_loss: 1.7149\n",
      "Epoch 121/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.7993 - val_loss: 1.7003\n",
      "Epoch 122/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.7786 - val_loss: 1.6857\n",
      "Epoch 123/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.7587 - val_loss: 1.6713\n",
      "Epoch 124/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 1.7389 - val_loss: 1.6580\n",
      "Epoch 125/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.7197 - val_loss: 1.6441\n",
      "Epoch 126/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.7001 - val_loss: 1.6303\n",
      "Epoch 127/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.6799 - val_loss: 1.6169\n",
      "Epoch 128/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.6604 - val_loss: 1.6035\n",
      "Epoch 129/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.6409 - val_loss: 1.5899\n",
      "Epoch 130/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.6222 - val_loss: 1.5752\n",
      "Epoch 131/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.6013 - val_loss: 1.5638\n",
      "Epoch 132/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.5848 - val_loss: 1.5519\n",
      "Epoch 133/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.5684 - val_loss: 1.5403\n",
      "Epoch 134/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.5526 - val_loss: 1.5298\n",
      "Epoch 135/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.5374 - val_loss: 1.5173\n",
      "Epoch 136/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.5208 - val_loss: 1.5041\n",
      "Epoch 137/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 1.5023 - val_loss: 1.4920\n",
      "Epoch 138/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.4857 - val_loss: 1.4802\n",
      "Epoch 139/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.4694 - val_loss: 1.4684\n",
      "Epoch 140/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.4545 - val_loss: 1.4598\n",
      "Epoch 141/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.4417 - val_loss: 1.4509\n",
      "Epoch 142/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.4289 - val_loss: 1.4414\n",
      "Epoch 143/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 1.4156 - val_loss: 1.4310\n",
      "Epoch 144/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.4023 - val_loss: 1.4213\n",
      "Epoch 145/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.3890 - val_loss: 1.4124\n",
      "Epoch 146/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 1.3767 - val_loss: 1.4035\n",
      "Epoch 147/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 1.3642 - val_loss: 1.3941\n",
      "Epoch 148/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.3518 - val_loss: 1.3870\n",
      "Epoch 149/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 1.3417 - val_loss: 1.3779\n",
      "Epoch 150/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.3288 - val_loss: 1.3696\n",
      "Epoch 151/300\n",
      "105/105 [==============================] - 0s 190us/sample - loss: 1.3169 - val_loss: 1.3613\n",
      "Epoch 152/300\n",
      "105/105 [==============================] - 0s 99us/sample - loss: 1.3050 - val_loss: 1.3518\n",
      "Epoch 153/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 1.2916 - val_loss: 1.3443\n",
      "Epoch 154/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 1.2809 - val_loss: 1.3363\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 71us/sample - loss: 1.2689 - val_loss: 1.3276\n",
      "Epoch 156/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.2577 - val_loss: 1.3189\n",
      "Epoch 157/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.2465 - val_loss: 1.3102\n",
      "Epoch 158/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 1.2343 - val_loss: 1.3036\n",
      "Epoch 159/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.2246 - val_loss: 1.2966\n",
      "Epoch 160/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.2154 - val_loss: 1.2891\n",
      "Epoch 161/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.2059 - val_loss: 1.2821\n",
      "Epoch 162/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.1966 - val_loss: 1.2757\n",
      "Epoch 163/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 1.1880 - val_loss: 1.2693\n",
      "Epoch 164/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.1793 - val_loss: 1.2635\n",
      "Epoch 165/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.1715 - val_loss: 1.2580\n",
      "Epoch 166/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.1639 - val_loss: 1.2519\n",
      "Epoch 167/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 1.1555 - val_loss: 1.2447\n",
      "Epoch 168/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.1468 - val_loss: 1.2395\n",
      "Epoch 169/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.1391 - val_loss: 1.2325\n",
      "Epoch 170/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.1297 - val_loss: 1.2276\n",
      "Epoch 171/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 1.1230 - val_loss: 1.2224\n",
      "Epoch 172/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.1163 - val_loss: 1.2161\n",
      "Epoch 173/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.1083 - val_loss: 1.2097\n",
      "Epoch 174/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 1.1005 - val_loss: 1.2046\n",
      "Epoch 175/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.0940 - val_loss: 1.1985\n",
      "Epoch 176/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 1.0860 - val_loss: 1.1938\n",
      "Epoch 177/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.0794 - val_loss: 1.1892\n",
      "Epoch 178/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.0726 - val_loss: 1.1832\n",
      "Epoch 179/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.0652 - val_loss: 1.1783\n",
      "Epoch 180/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 1.0591 - val_loss: 1.1746\n",
      "Epoch 181/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 1.0539 - val_loss: 1.1708\n",
      "Epoch 182/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 1.0490 - val_loss: 1.1664\n",
      "Epoch 183/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.0433 - val_loss: 1.1617\n",
      "Epoch 184/300\n",
      "105/105 [==============================] - 0s 88us/sample - loss: 1.0370 - val_loss: 1.1565\n",
      "Epoch 185/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 1.0301 - val_loss: 1.1528\n",
      "Epoch 186/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 1.0243 - val_loss: 1.1490\n",
      "Epoch 187/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 1.0189 - val_loss: 1.1445\n",
      "Epoch 188/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.0128 - val_loss: 1.1402\n",
      "Epoch 189/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 1.0074 - val_loss: 1.1369\n",
      "Epoch 190/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 1.0027 - val_loss: 1.1324\n",
      "Epoch 191/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.9973 - val_loss: 1.1287\n",
      "Epoch 192/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.9926 - val_loss: 1.1255\n",
      "Epoch 193/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.9883 - val_loss: 1.1217\n",
      "Epoch 194/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.9838 - val_loss: 1.1179\n",
      "Epoch 195/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.9788 - val_loss: 1.1139\n",
      "Epoch 196/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.9741 - val_loss: 1.1105\n",
      "Epoch 197/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.9697 - val_loss: 1.1072\n",
      "Epoch 198/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.9658 - val_loss: 1.1033\n",
      "Epoch 199/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.9618 - val_loss: 1.0993\n",
      "Epoch 200/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.9574 - val_loss: 1.0961\n",
      "Epoch 201/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.9529 - val_loss: 1.0925\n",
      "Epoch 202/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.9489 - val_loss: 1.0894\n",
      "Epoch 203/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.9452 - val_loss: 1.0872\n",
      "Epoch 204/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.9423 - val_loss: 1.0837\n",
      "Epoch 205/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.9388 - val_loss: 1.0811\n",
      "Epoch 206/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.9359 - val_loss: 1.0779\n",
      "Epoch 207/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.9324 - val_loss: 1.0751\n",
      "Epoch 208/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.9293 - val_loss: 1.0717\n",
      "Epoch 209/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.9253 - val_loss: 1.0681\n",
      "Epoch 210/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.9211 - val_loss: 1.0650\n",
      "Epoch 211/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.9178 - val_loss: 1.0629\n",
      "Epoch 212/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.9155 - val_loss: 1.0616\n",
      "Epoch 213/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.9134 - val_loss: 1.0594\n",
      "Epoch 214/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.9106 - val_loss: 1.0582\n",
      "Epoch 215/300\n",
      "105/105 [==============================] - 0s 69us/sample - loss: 0.9083 - val_loss: 1.0562\n",
      "Epoch 216/300\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.9055 - val_loss: 1.0537\n",
      "Epoch 217/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.9025 - val_loss: 1.0519\n",
      "Epoch 218/300\n",
      "105/105 [==============================] - 0s 93us/sample - loss: 0.8999 - val_loss: 1.0495\n",
      "Epoch 219/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.8973 - val_loss: 1.0471\n",
      "Epoch 220/300\n",
      "105/105 [==============================] - 0s 111us/sample - loss: 0.8948 - val_loss: 1.0455\n",
      "Epoch 221/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8926 - val_loss: 1.0439\n",
      "Epoch 222/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.8907 - val_loss: 1.0423\n",
      "Epoch 223/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8885 - val_loss: 1.0397\n",
      "Epoch 224/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.8855 - val_loss: 1.0378\n",
      "Epoch 225/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.8830 - val_loss: 1.0353\n",
      "Epoch 226/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8804 - val_loss: 1.0325\n",
      "Epoch 227/300\n",
      "105/105 [==============================] - 0s 92us/sample - loss: 0.8770 - val_loss: 1.0306\n",
      "Epoch 228/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.8746 - val_loss: 1.0285\n",
      "Epoch 229/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.8716 - val_loss: 1.0267\n",
      "Epoch 230/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8694 - val_loss: 1.0253\n",
      "Epoch 231/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.8673 - val_loss: 1.0231\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8652 - val_loss: 1.0206\n",
      "Epoch 233/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8627 - val_loss: 1.0178\n",
      "Epoch 234/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.8601 - val_loss: 1.0167\n",
      "Epoch 235/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8585 - val_loss: 1.0159\n",
      "Epoch 236/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8574 - val_loss: 1.0150\n",
      "Epoch 237/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8562 - val_loss: 1.0142\n",
      "Epoch 238/300\n",
      "105/105 [==============================] - 0s 89us/sample - loss: 0.8548 - val_loss: 1.0129\n",
      "Epoch 239/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8535 - val_loss: 1.0110\n",
      "Epoch 240/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.8518 - val_loss: 1.0097\n",
      "Epoch 241/300\n",
      "105/105 [==============================] - 0s 66us/sample - loss: 0.8504 - val_loss: 1.0094\n",
      "Epoch 242/300\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.8496 - val_loss: 1.0087\n",
      "Epoch 243/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8483 - val_loss: 1.0079\n",
      "Epoch 244/300\n",
      "105/105 [==============================] - 0s 82us/sample - loss: 0.8473 - val_loss: 1.0068\n",
      "Epoch 245/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.8457 - val_loss: 1.0059\n",
      "Epoch 246/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.8446 - val_loss: 1.0047\n",
      "Epoch 247/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8432 - val_loss: 1.0033\n",
      "Epoch 248/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8416 - val_loss: 1.0019\n",
      "Epoch 249/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.8403 - val_loss: 1.0007\n",
      "Epoch 250/300\n",
      "105/105 [==============================] - 0s 84us/sample - loss: 0.8392 - val_loss: 1.0005\n",
      "Epoch 251/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8384 - val_loss: 0.9998\n",
      "Epoch 252/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8373 - val_loss: 0.9976\n",
      "Epoch 253/300\n",
      "105/105 [==============================] - 0s 67us/sample - loss: 0.8356 - val_loss: 0.9959\n",
      "Epoch 254/300\n",
      "105/105 [==============================] - 0s 76us/sample - loss: 0.8343 - val_loss: 0.9953\n",
      "Epoch 255/300\n",
      "105/105 [==============================] - 0s 65us/sample - loss: 0.8337 - val_loss: 0.9942\n",
      "Epoch 256/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8324 - val_loss: 0.9935\n",
      "Epoch 257/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8312 - val_loss: 0.9921\n",
      "Epoch 258/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.8297 - val_loss: 0.9912\n",
      "Epoch 259/300\n",
      "105/105 [==============================] - 0s 74us/sample - loss: 0.8285 - val_loss: 0.9903\n",
      "Epoch 260/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8274 - val_loss: 0.9896\n",
      "Epoch 261/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8265 - val_loss: 0.9884\n",
      "Epoch 262/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8252 - val_loss: 0.9876\n",
      "Epoch 263/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.8243 - val_loss: 0.9869\n",
      "Epoch 264/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8234 - val_loss: 0.9867\n",
      "Epoch 265/300\n",
      "105/105 [==============================] - 0s 71us/sample - loss: 0.8229 - val_loss: 0.9865\n",
      "Epoch 266/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8221 - val_loss: 0.9854\n",
      "Epoch 267/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8210 - val_loss: 0.9845\n",
      "Epoch 268/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8203 - val_loss: 0.9836\n",
      "Epoch 269/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8193 - val_loss: 0.9823\n",
      "Epoch 270/300\n",
      "105/105 [==============================] - 0s 95us/sample - loss: 0.8183 - val_loss: 0.9813\n",
      "Epoch 271/300\n",
      "105/105 [==============================] - 0s 80us/sample - loss: 0.8176 - val_loss: 0.9804\n",
      "Epoch 272/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8166 - val_loss: 0.9794\n",
      "Epoch 273/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8158 - val_loss: 0.9782\n",
      "Epoch 274/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8148 - val_loss: 0.9773\n",
      "Epoch 275/300\n",
      "105/105 [==============================] - 0s 73us/sample - loss: 0.8141 - val_loss: 0.9763\n",
      "Epoch 276/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8132 - val_loss: 0.9765\n",
      "Epoch 277/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8130 - val_loss: 0.9753\n",
      "Epoch 278/300\n",
      "105/105 [==============================] - 0s 78us/sample - loss: 0.8119 - val_loss: 0.9754\n",
      "Epoch 279/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8114 - val_loss: 0.9745\n",
      "Epoch 280/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8106 - val_loss: 0.9736\n",
      "Epoch 281/300\n",
      "105/105 [==============================] - 0s 81us/sample - loss: 0.8097 - val_loss: 0.9728\n",
      "Epoch 282/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8090 - val_loss: 0.9730\n",
      "Epoch 283/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8086 - val_loss: 0.9725\n",
      "Epoch 284/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8082 - val_loss: 0.9718\n",
      "Epoch 285/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.8076 - val_loss: 0.9713\n",
      "Epoch 286/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8070 - val_loss: 0.9702\n",
      "Epoch 287/300\n",
      "105/105 [==============================] - 0s 72us/sample - loss: 0.8064 - val_loss: 0.9693\n",
      "Epoch 288/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8056 - val_loss: 0.9680\n",
      "Epoch 289/300\n",
      "105/105 [==============================] - 0s 102us/sample - loss: 0.8049 - val_loss: 0.9677\n",
      "Epoch 290/300\n",
      "105/105 [==============================] - 0s 91us/sample - loss: 0.8046 - val_loss: 0.9676\n",
      "Epoch 291/300\n",
      "105/105 [==============================] - 0s 70us/sample - loss: 0.8041 - val_loss: 0.9666\n",
      "Epoch 292/300\n",
      "105/105 [==============================] - 0s 77us/sample - loss: 0.8034 - val_loss: 0.9659\n",
      "Epoch 293/300\n",
      "105/105 [==============================] - 0s 75us/sample - loss: 0.8029 - val_loss: 0.9654\n",
      "Epoch 294/300\n",
      "105/105 [==============================] - 0s 79us/sample - loss: 0.8024 - val_loss: 0.9650\n",
      "Epoch 295/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8021 - val_loss: 0.9644\n",
      "Epoch 296/300\n",
      "105/105 [==============================] - 0s 68us/sample - loss: 0.8015 - val_loss: 0.9641\n",
      "Epoch 297/300\n",
      "105/105 [==============================] - 0s 83us/sample - loss: 0.8013 - val_loss: 0.9634\n",
      "Epoch 298/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.8008 - val_loss: 0.9632\n",
      "Epoch 299/300\n",
      "105/105 [==============================] - 0s 86us/sample - loss: 0.8005 - val_loss: 0.9631\n",
      "Epoch 300/300\n",
      "105/105 [==============================] - 0s 85us/sample - loss: 0.8003 - val_loss: 0.9625\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "callback_list = [TensorBoard()]\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "history = model.fit(x_train, y_train, epochs=300, \n",
    "                    callbacks=callback_list, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(784,))\n",
    "hidden = Dense(100)(input)\n",
    "output = Dense(10)(hidden)\n",
    "\n",
    "model = Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, to_file='model_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
